[
  {
    "objectID": "posts/DAGMM/2023-10-15-arrhythmia.html",
    "href": "posts/DAGMM/2023-10-15-arrhythmia.html",
    "title": "[DAGMM] DAGMM implementation of arrhythmia data set",
    "section": "",
    "text": "import torch\nfrom torch import nn\nimport numpy as np\nimport pandas as pd\nimport argparse\nimport sys\n\n\n\n\n\nfile_path = 'C:\\\\Users\\\\UOS\\\\Desktop\\\\연구\\\\5. 데이터\\\\data\\\\arrhythmia\\\\arrhythmia.data'\n\ndf = pd.read_csv(file_path, header=None)\ndf = df.replace('?', 0)\ndf = df.astype('float64')\n\ndata_array = df.values\ndata_array = torch.autograd.Variable(torch.from_numpy(data_array).float())\ndata_array.shape\n\ntorch.Size([452, 280])\n\n\n\n\n\n\nparser = argparse.ArgumentParser(description='parser for argparse test')\n\nparser.add_argument('--input_dim', type=int, default=data_array.shape[-1])\nparser.add_argument('--enc_hidden_dim', type=str, default='10,2')\nparser.add_argument('--dec_hidden_dim', type=str, default='10')\nparser.add_argument('--est_hidden_dim', type=str, default='4, 10, 2')\nparser.add_argument('--dropout', action='store_true', default=0.5)\nparser.add_argument('--learning_rate', type=float, default=0.001)\nparser.add_argument('--num_epoch', type=int, default=10)\n\nif 'ipykernel_launcher' in sys.argv[0]:\n    sys.argv = [sys.argv[0]]  \n\nargs = parser.parse_args()\n\nenc_hidden_dim = args.enc_hidden_dim.split(',')\ndec_hidden_dim = args.dec_hidden_dim.split(',')\nest_hidden_dim = args.est_hidden_dim.split(',')\n\nargs.enc_hidden_dim_list = []\nargs.dec_hidden_dim_list = []\nargs.est_hidden_dim_list = []\n\nargs.enc_hidden_dim_list.append(args.input_dim)\n\nfor i in enc_hidden_dim:\n    args.enc_hidden_dim_list.append(int(i))\n\nargs.enc_hidden_dim_list\n\nargs.dec_hidden_dim_list.append(args.enc_hidden_dim_list[-1])\n\nfor i in dec_hidden_dim:\n    args.dec_hidden_dim_list.append(int(i))\n\nargs.dec_hidden_dim_list.append(args.input_dim)\n\nargs.dec_hidden_dim_list\n\nfor i in est_hidden_dim:\n    args.est_hidden_dim_list.append(int(i))\n\nargs.est_hidden_dim_list\n\nargs\n\nNamespace(input_dim=280, enc_hidden_dim='10,2', dec_hidden_dim='10', est_hidden_dim='4, 10, 2', dropout=0.5, learning_rate=0.001, num_epoch=10, enc_hidden_dim_list=[280, 10, 2], dec_hidden_dim_list=[2, 10, 280], est_hidden_dim_list=[4, 10, 2])\n\n\n\n\n\n\nclass midlayer(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(midlayer, self).__init__()\n        self.fc_layer   = nn.Linear(input_dim, hidden_dim)\n        self.activation = nn.Tanh()\n    \n    def forward(self, input):\n        out = self.fc_layer(input)        \n        out = self.activation(out)\n        return out\n\n\nclass Encoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super(Encoder, self).__init__()\n        \n        layer_list = []\n        for i in range(len(hidden_dim_list)-2):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n        \n        layer_list.append(nn.Linear(hidden_dim_list[i+1], hidden_dim_list[i+2]))\n        self.layer = nn.Sequential(*layer_list)\n\n    def forward(self, input):\n        out = self.layer(input)\n        return out\n    \nclass Decoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super(Decoder, self).__init__()\n\n        layer_list = []\n        for i in range(len(hidden_dim_list)-2):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n        \n        layer_list.append(midlayer(hidden_dim_list[i+1], hidden_dim_list[i+2]))\n        self.layer = nn.Sequential(*layer_list)\n    \n    def forward(self, input):\n        out = self.layer(input)\n        return out\n\nclass CompressionNet(nn.Module):\n    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list):\n        super().__init__()\n        self.encoder = Encoder(enc_hidden_dim_list)\n        self.decoder = Decoder(dec_hidden_dim_list)\n\n        self._reconstruction_loss = nn.MSELoss()\n\n    def forward(self, input):\n        out = self.encoder(input)\n        out = self.decoder(out)\n        return out\n\n    def encode(self, input):\n        return self.encoder(input)\n\n    def decode(self, input):\n        return self.decoder(input)\n\n    def reconstuction_loss(self, input, input_target):\n        target_hat = self(input)\n        return self._reconstruction_loss(target_hat, input_target)\n\n\n\n\n\neps = torch.autograd.Variable(torch.FloatTensor([1.e-8]), requires_grad=False)\n\ndef relative_euclidean_distance(x1, x2, eps=eps):\n    num = torch.norm(x1 - x2, p=2, dim=1)\n    denom = torch.norm(x1, p=2, dim=1)\n    return num / torch.max(denom, eps)\n\ndef cosine_similarity(x1, x2, eps=eps):\n    dot_prod = torch.sum(x1 * x2, dim=1)\n    dist_x1 = torch.norm(x1, p=2, dim=1)\n    dist_x2 = torch.norm(x2, p=2, dim=1)\n    return dot_prod / torch.max(dist_x1*dist_x2, eps)\n\n\n\n\n\nclass Estimation(nn.Module):\n    def __init__(self, est_hidden_dim_list):\n        super().__init__()\n        \n        layer_list = []\n        for i in range(len(est_hidden_dim_list)-2):\n            layer_list.append(midlayer(est_hidden_dim_list[i], est_hidden_dim_list[i+1]))\n        \n        layer_list.append(nn.Dropout(p=0.5))\n        layer_list.append(nn.Linear(est_hidden_dim_list[-2], est_hidden_dim_list[-1]))\n        layer_list.append(nn.Softmax())\n        self.net = nn.Sequential(*layer_list)\n        \n    def forward(self, input):\n        out = self.net(input)\n        return out\n\n\n\n\n\nclass Mixture(nn.Module):\n    def __init__(self, latent_dimension):\n        super().__init__()\n        self.latent_dimension = latent_dimension\n\n        self.Phi    = np.random.random([1])\n        self.Phi    = torch.from_numpy(self.Phi).float()\n        self.Phi    = nn.Parameter(self.Phi, requires_grad = False)\n\n        self.mu     = 2.*np.random.random([latent_dimension]) - 0.5\n        self.mu     = torch.from_numpy(self.mu).float()\n        self.mu     = nn.Parameter(self.mu, requires_grad = False)\n\n        self.Sigma  = np.eye(latent_dimension, latent_dimension)\n        self.Sigma  = torch.from_numpy(self.Sigma).float()\n        self.Sigma  = nn.Parameter(self.Sigma, requires_grad = False)\n        \n        self.eps_Sigma  = torch.FloatTensor(np.diag([1.e-8 for _ in range(latent_dimension)]))\n\n    def forward(self, est_inputs, with_log = True):\n        batch_size, _   = est_inputs.shape\n        out_values  = []\n        inv_sigma   = torch.inverse(self.Sigma)\n        det_sigma   = np.linalg.det(self.Sigma.data.cpu().numpy())\n        det_sigma   = torch.from_numpy(det_sigma.reshape([1])).float()\n        det_sigma   = torch.autograd.Variable(det_sigma)\n        for est_input in est_inputs:\n            diff    = (est_input - self.mu).view(-1,1)\n            out     = -0.5 * torch.mm(torch.mm(diff.view(1,-1), inv_sigma), diff)\n            out     = (self.Phi * torch.exp(out)) / torch.sqrt(2. * np.pi * det_sigma)\n            if with_log:\n                out = -torch.log(out)\n            out_values.append(float(out.data.cpu().numpy()))\n\n        out = torch.autograd.Variable(torch.FloatTensor(out_values))\n        return out\n    \n    def _update_parameters(self, samples, affiliations):\n        if not self.training:\n            return\n\n        batch_size, _ = samples.shape\n\n        # Updating phi.\n        phi = torch.mean(affiliations)\n        self.Phi.data = phi.data\n\n        # Updating mu.\n        num = 0.\n        for i in range(batch_size):\n            z_i     = samples[i, :]\n            gamma_i = affiliations[i]\n            num     += gamma_i * z_i\n        \n        denom        = torch.sum(affiliations)\n        self.mu.data = (num / denom).data\n\n        # Updating Sigma.\n        mu  = self.mu\n        num = None\n        for i in range(batch_size):\n            z_i     = samples[i, :]\n            gamma_i = affiliations[i]\n            diff    = (z_i - mu).view(-1, 1)\n            to_add  = gamma_i * torch.mm(diff, diff.view(1, -1))\n            if num is None:\n                num = to_add\n            else:\n                num += to_add\n\n        denom           = torch.sum(affiliations)\n        self.Sigma.data = (num / denom).data + self.eps_Sigma\n\n\n\n\n\nclass GMM(nn.Module):\n    def __init__(self, num_mixtures, latent_dimension):\n        super().__init__()\n        self.num_mixtures       = num_mixtures\n        self.latent_dimension   = latent_dimension\n\n        mixtures        = [Mixture(latent_dimension) for _ in range(num_mixtures)]\n        self.mixtures   = nn.ModuleList(mixtures)\n    \n    def forward(self, est_inputs):\n        out = None\n        for mixture in self.mixtures:\n            to_add  = mixture(est_inputs, with_log = False)\n            if out is None:\n                out = to_add\n            else:\n                out += to_add\n        return -torch.log(out)\n    \n    def _update_mixtures_parameters(self, samples, mixtures_affiliations):\n        if not self.training:\n            return\n\n        for i, mixture in enumerate(self.mixtures):\n            affiliations = mixtures_affiliations[:, i]\n            mixture._update_parameters(samples, affiliations)\n\n\n\n\n\nclass DAGMM(nn.Module):\n    def __init__(self, compression_module, estimation_module, gmm_module):\n        super().__init__()\n\n        self.compressor = compression_module\n        self.estimator  = estimation_module\n        self.gmm        = gmm_module\n\n    def forward(self, input):\n        encoded = self.compressor.encode(input)\n        decoded = self.compressor.decode(encoded)\n\n        relative_ed     = relative_euclidean_distance(input, decoded)\n        cosine_sim      = cosine_similarity(input, decoded)\n\n        relative_ed     = relative_ed.view(-1, 1)\n        cosine_sim      = relative_ed.view(-1, 1)\n        latent_vectors  = torch.cat([encoded, relative_ed, cosine_sim], dim=1)\n\n        if self.training:\n            mixtures_affiliations = self.estimator(latent_vectors)\n            self.gmm._update_mixtures_parameters(latent_vectors,\n                                                 mixtures_affiliations)\n        return self.gmm(latent_vectors)\n\n\nclass DAGMMArrhythmia(DAGMM):\n    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list, est_hidden_dim_list):\n        compressor  = CompressionNet(enc_hidden_dim_list, dec_hidden_dim_list)\n        estimator   = Estimation(est_hidden_dim_list)\n        gmm = GMM(num_mixtures = est_hidden_dim_list[-1], latent_dimension = enc_hidden_dim_list[-1] + 2)\n\n        super().__init__(compression_module = compressor,\n                         estimation_module  = estimator,\n                         gmm_module         = gmm)\n\n\n\n\n\ndef test_dagmm():\n    net = DAGMMArrhythmia(args.enc_hidden_dim_list, args.dec_hidden_dim_list, args.est_hidden_dim_list)\n    out = net(data_array)\n    print(out)\n\ndef convert_to_var(input):\n    out = torch.from_numpy(input).float()\n    out = torch.autograd.Variable(out)\n    return out\n\ndef test_update_mixture():\n    batch_size       = 5\n    latent_dimension = 7\n    mix              = Mixture(latent_dimension)\n    latent_vectors   = np.random.random([batch_size, latent_dimension])\n    affiliations     = np.random.random([batch_size])\n    latent_vectors   = convert_to_var(latent_vectors)\n    affiliations     = convert_to_var(affiliations)\n\n    for param in mix.parameters():\n        print(param)\n\n    mix.train()\n    mix._update_parameters(latent_vectors, affiliations)\n\n    for param in mix.parameters():\n        print(param)\n\n\ndef test_forward_mixture():\n    batch_size       = 5\n    latent_dimension = 7\n\n    mix = Mixture(latent_dimension)\n    latent_vectors   = np.random.random([batch_size, latent_dimension])\n    latent_vectors   = convert_to_var(latent_vectors)\n\n    mix.train()\n    out = mix(latent_vectors)\n    print(out)\n\n\ndef test_update_gmm():\n    batch_size      = int(5)\n    latent_dimension= 7\n    num_mixtures    = 2\n\n    gmm = GMM(num_mixtures, latent_dimension)\n\n    latent_vectors  = np.random.random([batch_size, latent_dimension])\n    latent_vectors  = convert_to_var(latent_vectors)\n\n    affiliations    = np.random.random([batch_size, num_mixtures])\n    affiliations    = convert_to_var(affiliations)\n\n    for param in gmm.parameters():\n        print(param)\n\n    gmm.train()\n    gmm._update_mixtures_parameters(latent_vectors, affiliations)\n\n    for param in gmm.parameters():\n        print(param)\n\n\nif __name__ == '__main__':\n    test_update_mixture()\n    test_forward_mixture()\n    test_update_gmm()\n    test_dagmm()\n\nParameter containing:\ntensor([0.4108])\nParameter containing:\ntensor([-0.4930, -0.0609,  0.9678,  0.9646,  1.2854,  1.0585,  1.3091])\nParameter containing:\ntensor([[1., 0., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 1.]])\nParameter containing:\ntensor(0.5973)\nParameter containing:\ntensor([0.5404, 0.8328, 0.5408, 0.5690, 0.4687, 0.4590, 0.4463])\nParameter containing:\ntensor([[ 0.1052,  0.0173,  0.0185,  0.0464,  0.0382, -0.0627,  0.0843],\n        [ 0.0173,  0.0189,  0.0177,  0.0177,  0.0304, -0.0166, -0.0027],\n        [ 0.0185,  0.0177,  0.0652,  0.0079,  0.0596,  0.0047,  0.0050],\n        [ 0.0464,  0.0177,  0.0079,  0.0314,  0.0209, -0.0305,  0.0156],\n        [ 0.0382,  0.0304,  0.0596,  0.0209,  0.0789, -0.0282,  0.0273],\n        [-0.0627, -0.0166,  0.0047, -0.0305, -0.0282,  0.0593, -0.0604],\n        [ 0.0843, -0.0027,  0.0050,  0.0156,  0.0273, -0.0604,  0.1217]])\ntensor([2.7962, 2.6436, 3.1959, 2.9833, 3.1488])\nParameter containing:\ntensor([0.5244])\nParameter containing:\ntensor([0.4938, 0.6227, 0.2106, 1.2189, 0.7241, 0.8534, 0.2676])\nParameter containing:\ntensor([[1., 0., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 1.]])\nParameter containing:\ntensor([0.6656])\nParameter containing:\ntensor([0.3613, 0.0844, 0.4508, 0.3979, 0.4715, 0.0697, 0.0790])\nParameter containing:\ntensor([[1., 0., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 1.]])\nParameter containing:\ntensor(0.3362)\nParameter containing:\ntensor([0.5625, 0.1650, 0.5926, 0.5153, 0.7716, 0.5900, 0.4792])\nParameter containing:\ntensor([[ 0.0282,  0.0023,  0.0325, -0.0054,  0.0021, -0.0006,  0.0320],\n        [ 0.0023,  0.0092, -0.0011,  0.0094, -0.0057, -0.0117,  0.0225],\n        [ 0.0325, -0.0011,  0.0922, -0.0192,  0.0473,  0.0083,  0.0474],\n        [-0.0054,  0.0094, -0.0192,  0.0462, -0.0479,  0.0173,  0.0209],\n        [ 0.0021, -0.0057,  0.0473, -0.0479,  0.0729, -0.0206, -0.0045],\n        [-0.0006, -0.0117,  0.0083,  0.0173, -0.0206,  0.0437, -0.0172],\n        [ 0.0320,  0.0225,  0.0474,  0.0209, -0.0045, -0.0172,  0.0892]])\nParameter containing:\ntensor(0.3915)\nParameter containing:\ntensor([0.5520, 0.1997, 0.4993, 0.4864, 0.7780, 0.4641, 0.5020])\nParameter containing:\ntensor([[ 0.0396,  0.0077,  0.0342,  0.0191, -0.0283,  0.0112,  0.0568],\n        [ 0.0077,  0.0078,  0.0046,  0.0101, -0.0088, -0.0063,  0.0251],\n        [ 0.0342,  0.0046,  0.1013,  0.0129,  0.0225,  0.0277,  0.0719],\n        [ 0.0191,  0.0101,  0.0129,  0.0373, -0.0402,  0.0164,  0.0465],\n        [-0.0283, -0.0088,  0.0225, -0.0402,  0.0746, -0.0143, -0.0359],\n        [ 0.0112, -0.0063,  0.0277,  0.0164, -0.0143,  0.0364,  0.0081],\n        [ 0.0568,  0.0251,  0.0719,  0.0465, -0.0359,  0.0081,  0.1249]])\ntensor([-19.2564, -18.0547, -16.3949, -17.3645, -18.7643, -17.8371, -18.9319,\n        -17.3849, -19.0331, -18.5996, -18.8663, -19.0285, -19.3665, -17.3287,\n        -18.7925, -17.9085, -18.3725, -16.8432, -19.0094, -19.0351, -17.5516,\n        -18.6999, -19.0101, -19.0587, -18.6902, -16.6082, -17.8009, -19.3211,\n        -16.4337, -14.4446, -17.7824, -18.5536, -19.2948, -18.8873, -18.1048,\n        -18.8613, -18.8028, -17.7254, -17.8467, -17.8801, -17.5114, -18.7899,\n        -18.7854, -18.4335, -17.9540, -18.5277, -18.4958, -19.1059, -18.6475,\n        -19.0338, -19.3081, -18.6593, -17.3205, -17.4425, -16.4498, -19.1613,\n        -18.8155, -19.0773, -18.7134, -18.9291, -18.0730, -18.4230, -18.8852,\n        -18.7261, -18.7798, -18.9858, -17.5758, -18.7625, -18.0510, -15.8704,\n        -19.0205, -19.0118, -19.3139, -19.0564, -17.2290, -17.8323, -19.1797,\n        -18.7321, -18.2683, -17.9285, -18.8088, -17.6969, -19.0502, -18.4027,\n        -14.0781, -16.8003, -19.1769, -18.2311, -18.4472, -16.0477, -19.0438,\n        -17.5159, -18.0267, -18.5224, -18.4645, -19.3172, -18.2687, -18.6210,\n        -18.1220, -18.4591, -18.8159, -18.5173, -17.5662, -18.7601, -19.2286,\n        -19.0618, -16.1031, -17.5881, -17.3610, -18.7824, -17.7521, -18.1415,\n        -18.9739, -18.4967, -18.8139, -17.4159, -19.1722, -18.6194, -18.9447,\n        -18.0765, -19.2638, -17.8369, -18.0603, -17.4801, -17.9954, -17.5410,\n        -18.0189, -17.3560, -18.1195, -18.9525, -19.0643, -18.6243, -17.9777,\n        -17.0903, -19.3566, -18.5979, -18.8478, -18.3555, -17.4501, -18.2208,\n        -18.7513, -15.5237, -19.0146, -18.4070, -19.0495, -18.2230, -17.8902,\n        -18.4425, -18.8322, -17.8915, -18.8612, -17.7105, -19.0856, -19.4493,\n        -18.6984, -18.7255, -19.0555, -17.6645, -18.8864, -18.5403, -18.1607,\n        -17.9466, -18.6024, -17.6435, -18.2158, -19.3479, -19.2290, -18.5409,\n        -18.8731, -19.0171, -19.3246, -18.8465, -18.2816, -19.3152, -18.5592,\n        -18.4677, -18.3102, -18.8956, -18.7767, -17.8755, -17.4399, -19.0722,\n        -18.6370, -17.9408, -17.2431, -18.2954, -18.1857, -16.6689, -17.5154,\n        -17.0577, -17.2580, -17.3108, -19.0950, -18.6613, -18.0495, -19.0558,\n        -17.7375, -17.1572, -17.4150, -18.8458, -18.6497, -17.9805, -18.1902,\n        -18.7660, -15.8835, -18.7459, -18.6498, -17.8905, -15.9800, -17.3226,\n        -19.4193, -17.6966, -18.1932, -15.3249, -17.1338, -19.2474, -16.9423,\n        -16.6158, -15.0462, -18.6544, -18.8282, -18.0630, -17.2687, -18.8309,\n        -19.2707, -18.4543, -18.1300, -17.7864, -18.6297, -18.4028, -18.8658,\n        -18.9418, -18.6116, -18.9729, -17.0293, -15.1011, -18.5634, -15.8022,\n        -19.0415, -15.4348, -17.6778, -16.9394, -19.3467, -17.6310, -18.2665,\n        -19.1546, -19.2717, -18.1000, -18.9345, -19.3095, -18.3156, -17.0592,\n        -16.4144, -15.8596, -17.2900, -17.6649, -17.5640, -17.1291, -17.5856,\n        -18.8441, -17.9905, -18.2374, -19.0501, -17.4113, -18.6796, -17.8788,\n        -17.7550, -17.0484, -18.1735, -18.8908, -17.7271, -19.3673, -18.7071,\n        -19.2400, -17.4982, -18.7901, -19.0618, -19.2101, -18.9515, -17.7362,\n        -18.8028, -18.1069, -18.6178, -18.1941, -17.9602, -17.4824, -18.9062,\n        -19.2635, -17.8047, -19.0641, -18.8086,  -5.6501, -17.8593, -18.3549,\n        -17.9025, -17.8254, -18.1989, -18.5610, -18.8534, -19.0492, -16.7777,\n        -18.6564, -18.9140, -16.0198, -17.6024, -17.1364, -19.0579, -19.0956,\n        -13.0102, -18.8278, -18.8491, -19.0167, -19.3264, -17.9205, -17.3035,\n        -18.9889, -16.1662, -19.0933, -16.8775, -17.3989, -16.0942, -19.1201,\n        -16.6062, -17.5932, -19.0607, -19.1193, -17.8199, -19.2134, -19.2459,\n        -18.4750, -18.6372, -17.2914, -16.9354, -16.4155, -18.6404, -18.6237,\n        -13.6548, -17.8241, -17.7731, -18.9976, -16.6893, -18.7639, -19.0192,\n        -17.3781, -17.7284, -18.4769, -18.6544, -18.6396, -10.5233, -18.9755,\n        -16.2146, -18.3850, -18.8836, -18.0061, -12.4405, -18.1728, -16.0776,\n        -18.8860, -17.7030, -17.1750, -18.8864, -16.2724, -18.0929, -17.7909,\n        -19.3795, -18.2792, -11.6489, -16.9437, -19.3996, -18.7899, -18.8189,\n        -16.4978, -18.9292, -16.5404, -18.1338, -18.5574, -13.8486, -18.1189,\n        -18.7550, -17.5262, -17.1936, -11.0568, -18.9244, -18.6801, -18.5698,\n        -18.8630, -18.6425, -18.0110, -16.3563, -16.7062, -18.7585, -18.6717,\n        -18.0642, -14.7988, -19.3447, -18.4847, -17.6401, -17.0492, -16.6872,\n        -18.1093, -19.1730, -17.8896, -18.2686, -15.0559, -18.7812, -17.8376,\n        -19.0735, -19.0174, -17.5638, -19.2497, -18.5173, -18.4271, -18.2227,\n        -18.6454, -18.4256, -17.6640, -17.9564, -19.0723, -18.4326, -17.5340,\n        -15.9750, -19.0241, -18.5688, -17.6339, -18.6477, -19.3596, -17.8437,\n        -18.5472, -18.7933, -18.0868, -17.8253, -18.8675, -19.3256, -17.0121,\n        -18.9690, -18.8272, -18.9232, -18.9247, -17.0758, -18.1514, -18.4496,\n        -17.3666, -17.7035, -18.6327, -19.0636, -19.3950, -18.8716, -17.5528,\n        -17.5704, -16.1035, -18.6533, -18.8194])\n\n\nC:\\Users\\UOS\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217: UserWarning:\n\nImplicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n\n\n\n\n\n\n\n{https://openreview.net/forum?id=BJJLHbb0-}"
  },
  {
    "objectID": "posts/DAGMM/2023-10-15-arrhythmia.html#deep-autoencoding-gaussian-mixture-model-for-arrhythmia-dataset",
    "href": "posts/DAGMM/2023-10-15-arrhythmia.html#deep-autoencoding-gaussian-mixture-model-for-arrhythmia-dataset",
    "title": "[DAGMM] DAGMM implementation of arrhythmia data set",
    "section": "",
    "text": "import torch\nfrom torch import nn\nimport numpy as np\nimport pandas as pd\nimport argparse\nimport sys\n\n\n\n\n\nfile_path = 'C:\\\\Users\\\\UOS\\\\Desktop\\\\연구\\\\5. 데이터\\\\data\\\\arrhythmia\\\\arrhythmia.data'\n\ndf = pd.read_csv(file_path, header=None)\ndf = df.replace('?', 0)\ndf = df.astype('float64')\n\ndata_array = df.values\ndata_array = torch.autograd.Variable(torch.from_numpy(data_array).float())\ndata_array.shape\n\ntorch.Size([452, 280])\n\n\n\n\n\n\nparser = argparse.ArgumentParser(description='parser for argparse test')\n\nparser.add_argument('--input_dim', type=int, default=data_array.shape[-1])\nparser.add_argument('--enc_hidden_dim', type=str, default='10,2')\nparser.add_argument('--dec_hidden_dim', type=str, default='10')\nparser.add_argument('--est_hidden_dim', type=str, default='4, 10, 2')\nparser.add_argument('--dropout', action='store_true', default=0.5)\nparser.add_argument('--learning_rate', type=float, default=0.001)\nparser.add_argument('--num_epoch', type=int, default=10)\n\nif 'ipykernel_launcher' in sys.argv[0]:\n    sys.argv = [sys.argv[0]]  \n\nargs = parser.parse_args()\n\nenc_hidden_dim = args.enc_hidden_dim.split(',')\ndec_hidden_dim = args.dec_hidden_dim.split(',')\nest_hidden_dim = args.est_hidden_dim.split(',')\n\nargs.enc_hidden_dim_list = []\nargs.dec_hidden_dim_list = []\nargs.est_hidden_dim_list = []\n\nargs.enc_hidden_dim_list.append(args.input_dim)\n\nfor i in enc_hidden_dim:\n    args.enc_hidden_dim_list.append(int(i))\n\nargs.enc_hidden_dim_list\n\nargs.dec_hidden_dim_list.append(args.enc_hidden_dim_list[-1])\n\nfor i in dec_hidden_dim:\n    args.dec_hidden_dim_list.append(int(i))\n\nargs.dec_hidden_dim_list.append(args.input_dim)\n\nargs.dec_hidden_dim_list\n\nfor i in est_hidden_dim:\n    args.est_hidden_dim_list.append(int(i))\n\nargs.est_hidden_dim_list\n\nargs\n\nNamespace(input_dim=280, enc_hidden_dim='10,2', dec_hidden_dim='10', est_hidden_dim='4, 10, 2', dropout=0.5, learning_rate=0.001, num_epoch=10, enc_hidden_dim_list=[280, 10, 2], dec_hidden_dim_list=[2, 10, 280], est_hidden_dim_list=[4, 10, 2])\n\n\n\n\n\n\nclass midlayer(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(midlayer, self).__init__()\n        self.fc_layer   = nn.Linear(input_dim, hidden_dim)\n        self.activation = nn.Tanh()\n    \n    def forward(self, input):\n        out = self.fc_layer(input)        \n        out = self.activation(out)\n        return out\n\n\nclass Encoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super(Encoder, self).__init__()\n        \n        layer_list = []\n        for i in range(len(hidden_dim_list)-2):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n        \n        layer_list.append(nn.Linear(hidden_dim_list[i+1], hidden_dim_list[i+2]))\n        self.layer = nn.Sequential(*layer_list)\n\n    def forward(self, input):\n        out = self.layer(input)\n        return out\n    \nclass Decoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super(Decoder, self).__init__()\n\n        layer_list = []\n        for i in range(len(hidden_dim_list)-2):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n        \n        layer_list.append(midlayer(hidden_dim_list[i+1], hidden_dim_list[i+2]))\n        self.layer = nn.Sequential(*layer_list)\n    \n    def forward(self, input):\n        out = self.layer(input)\n        return out\n\nclass CompressionNet(nn.Module):\n    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list):\n        super().__init__()\n        self.encoder = Encoder(enc_hidden_dim_list)\n        self.decoder = Decoder(dec_hidden_dim_list)\n\n        self._reconstruction_loss = nn.MSELoss()\n\n    def forward(self, input):\n        out = self.encoder(input)\n        out = self.decoder(out)\n        return out\n\n    def encode(self, input):\n        return self.encoder(input)\n\n    def decode(self, input):\n        return self.decoder(input)\n\n    def reconstuction_loss(self, input, input_target):\n        target_hat = self(input)\n        return self._reconstruction_loss(target_hat, input_target)\n\n\n\n\n\neps = torch.autograd.Variable(torch.FloatTensor([1.e-8]), requires_grad=False)\n\ndef relative_euclidean_distance(x1, x2, eps=eps):\n    num = torch.norm(x1 - x2, p=2, dim=1)\n    denom = torch.norm(x1, p=2, dim=1)\n    return num / torch.max(denom, eps)\n\ndef cosine_similarity(x1, x2, eps=eps):\n    dot_prod = torch.sum(x1 * x2, dim=1)\n    dist_x1 = torch.norm(x1, p=2, dim=1)\n    dist_x2 = torch.norm(x2, p=2, dim=1)\n    return dot_prod / torch.max(dist_x1*dist_x2, eps)\n\n\n\n\n\nclass Estimation(nn.Module):\n    def __init__(self, est_hidden_dim_list):\n        super().__init__()\n        \n        layer_list = []\n        for i in range(len(est_hidden_dim_list)-2):\n            layer_list.append(midlayer(est_hidden_dim_list[i], est_hidden_dim_list[i+1]))\n        \n        layer_list.append(nn.Dropout(p=0.5))\n        layer_list.append(nn.Linear(est_hidden_dim_list[-2], est_hidden_dim_list[-1]))\n        layer_list.append(nn.Softmax())\n        self.net = nn.Sequential(*layer_list)\n        \n    def forward(self, input):\n        out = self.net(input)\n        return out\n\n\n\n\n\nclass Mixture(nn.Module):\n    def __init__(self, latent_dimension):\n        super().__init__()\n        self.latent_dimension = latent_dimension\n\n        self.Phi    = np.random.random([1])\n        self.Phi    = torch.from_numpy(self.Phi).float()\n        self.Phi    = nn.Parameter(self.Phi, requires_grad = False)\n\n        self.mu     = 2.*np.random.random([latent_dimension]) - 0.5\n        self.mu     = torch.from_numpy(self.mu).float()\n        self.mu     = nn.Parameter(self.mu, requires_grad = False)\n\n        self.Sigma  = np.eye(latent_dimension, latent_dimension)\n        self.Sigma  = torch.from_numpy(self.Sigma).float()\n        self.Sigma  = nn.Parameter(self.Sigma, requires_grad = False)\n        \n        self.eps_Sigma  = torch.FloatTensor(np.diag([1.e-8 for _ in range(latent_dimension)]))\n\n    def forward(self, est_inputs, with_log = True):\n        batch_size, _   = est_inputs.shape\n        out_values  = []\n        inv_sigma   = torch.inverse(self.Sigma)\n        det_sigma   = np.linalg.det(self.Sigma.data.cpu().numpy())\n        det_sigma   = torch.from_numpy(det_sigma.reshape([1])).float()\n        det_sigma   = torch.autograd.Variable(det_sigma)\n        for est_input in est_inputs:\n            diff    = (est_input - self.mu).view(-1,1)\n            out     = -0.5 * torch.mm(torch.mm(diff.view(1,-1), inv_sigma), diff)\n            out     = (self.Phi * torch.exp(out)) / torch.sqrt(2. * np.pi * det_sigma)\n            if with_log:\n                out = -torch.log(out)\n            out_values.append(float(out.data.cpu().numpy()))\n\n        out = torch.autograd.Variable(torch.FloatTensor(out_values))\n        return out\n    \n    def _update_parameters(self, samples, affiliations):\n        if not self.training:\n            return\n\n        batch_size, _ = samples.shape\n\n        # Updating phi.\n        phi = torch.mean(affiliations)\n        self.Phi.data = phi.data\n\n        # Updating mu.\n        num = 0.\n        for i in range(batch_size):\n            z_i     = samples[i, :]\n            gamma_i = affiliations[i]\n            num     += gamma_i * z_i\n        \n        denom        = torch.sum(affiliations)\n        self.mu.data = (num / denom).data\n\n        # Updating Sigma.\n        mu  = self.mu\n        num = None\n        for i in range(batch_size):\n            z_i     = samples[i, :]\n            gamma_i = affiliations[i]\n            diff    = (z_i - mu).view(-1, 1)\n            to_add  = gamma_i * torch.mm(diff, diff.view(1, -1))\n            if num is None:\n                num = to_add\n            else:\n                num += to_add\n\n        denom           = torch.sum(affiliations)\n        self.Sigma.data = (num / denom).data + self.eps_Sigma\n\n\n\n\n\nclass GMM(nn.Module):\n    def __init__(self, num_mixtures, latent_dimension):\n        super().__init__()\n        self.num_mixtures       = num_mixtures\n        self.latent_dimension   = latent_dimension\n\n        mixtures        = [Mixture(latent_dimension) for _ in range(num_mixtures)]\n        self.mixtures   = nn.ModuleList(mixtures)\n    \n    def forward(self, est_inputs):\n        out = None\n        for mixture in self.mixtures:\n            to_add  = mixture(est_inputs, with_log = False)\n            if out is None:\n                out = to_add\n            else:\n                out += to_add\n        return -torch.log(out)\n    \n    def _update_mixtures_parameters(self, samples, mixtures_affiliations):\n        if not self.training:\n            return\n\n        for i, mixture in enumerate(self.mixtures):\n            affiliations = mixtures_affiliations[:, i]\n            mixture._update_parameters(samples, affiliations)\n\n\n\n\n\nclass DAGMM(nn.Module):\n    def __init__(self, compression_module, estimation_module, gmm_module):\n        super().__init__()\n\n        self.compressor = compression_module\n        self.estimator  = estimation_module\n        self.gmm        = gmm_module\n\n    def forward(self, input):\n        encoded = self.compressor.encode(input)\n        decoded = self.compressor.decode(encoded)\n\n        relative_ed     = relative_euclidean_distance(input, decoded)\n        cosine_sim      = cosine_similarity(input, decoded)\n\n        relative_ed     = relative_ed.view(-1, 1)\n        cosine_sim      = relative_ed.view(-1, 1)\n        latent_vectors  = torch.cat([encoded, relative_ed, cosine_sim], dim=1)\n\n        if self.training:\n            mixtures_affiliations = self.estimator(latent_vectors)\n            self.gmm._update_mixtures_parameters(latent_vectors,\n                                                 mixtures_affiliations)\n        return self.gmm(latent_vectors)\n\n\nclass DAGMMArrhythmia(DAGMM):\n    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list, est_hidden_dim_list):\n        compressor  = CompressionNet(enc_hidden_dim_list, dec_hidden_dim_list)\n        estimator   = Estimation(est_hidden_dim_list)\n        gmm = GMM(num_mixtures = est_hidden_dim_list[-1], latent_dimension = enc_hidden_dim_list[-1] + 2)\n\n        super().__init__(compression_module = compressor,\n                         estimation_module  = estimator,\n                         gmm_module         = gmm)\n\n\n\n\n\ndef test_dagmm():\n    net = DAGMMArrhythmia(args.enc_hidden_dim_list, args.dec_hidden_dim_list, args.est_hidden_dim_list)\n    out = net(data_array)\n    print(out)\n\ndef convert_to_var(input):\n    out = torch.from_numpy(input).float()\n    out = torch.autograd.Variable(out)\n    return out\n\ndef test_update_mixture():\n    batch_size       = 5\n    latent_dimension = 7\n    mix              = Mixture(latent_dimension)\n    latent_vectors   = np.random.random([batch_size, latent_dimension])\n    affiliations     = np.random.random([batch_size])\n    latent_vectors   = convert_to_var(latent_vectors)\n    affiliations     = convert_to_var(affiliations)\n\n    for param in mix.parameters():\n        print(param)\n\n    mix.train()\n    mix._update_parameters(latent_vectors, affiliations)\n\n    for param in mix.parameters():\n        print(param)\n\n\ndef test_forward_mixture():\n    batch_size       = 5\n    latent_dimension = 7\n\n    mix = Mixture(latent_dimension)\n    latent_vectors   = np.random.random([batch_size, latent_dimension])\n    latent_vectors   = convert_to_var(latent_vectors)\n\n    mix.train()\n    out = mix(latent_vectors)\n    print(out)\n\n\ndef test_update_gmm():\n    batch_size      = int(5)\n    latent_dimension= 7\n    num_mixtures    = 2\n\n    gmm = GMM(num_mixtures, latent_dimension)\n\n    latent_vectors  = np.random.random([batch_size, latent_dimension])\n    latent_vectors  = convert_to_var(latent_vectors)\n\n    affiliations    = np.random.random([batch_size, num_mixtures])\n    affiliations    = convert_to_var(affiliations)\n\n    for param in gmm.parameters():\n        print(param)\n\n    gmm.train()\n    gmm._update_mixtures_parameters(latent_vectors, affiliations)\n\n    for param in gmm.parameters():\n        print(param)\n\n\nif __name__ == '__main__':\n    test_update_mixture()\n    test_forward_mixture()\n    test_update_gmm()\n    test_dagmm()\n\nParameter containing:\ntensor([0.4108])\nParameter containing:\ntensor([-0.4930, -0.0609,  0.9678,  0.9646,  1.2854,  1.0585,  1.3091])\nParameter containing:\ntensor([[1., 0., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 1.]])\nParameter containing:\ntensor(0.5973)\nParameter containing:\ntensor([0.5404, 0.8328, 0.5408, 0.5690, 0.4687, 0.4590, 0.4463])\nParameter containing:\ntensor([[ 0.1052,  0.0173,  0.0185,  0.0464,  0.0382, -0.0627,  0.0843],\n        [ 0.0173,  0.0189,  0.0177,  0.0177,  0.0304, -0.0166, -0.0027],\n        [ 0.0185,  0.0177,  0.0652,  0.0079,  0.0596,  0.0047,  0.0050],\n        [ 0.0464,  0.0177,  0.0079,  0.0314,  0.0209, -0.0305,  0.0156],\n        [ 0.0382,  0.0304,  0.0596,  0.0209,  0.0789, -0.0282,  0.0273],\n        [-0.0627, -0.0166,  0.0047, -0.0305, -0.0282,  0.0593, -0.0604],\n        [ 0.0843, -0.0027,  0.0050,  0.0156,  0.0273, -0.0604,  0.1217]])\ntensor([2.7962, 2.6436, 3.1959, 2.9833, 3.1488])\nParameter containing:\ntensor([0.5244])\nParameter containing:\ntensor([0.4938, 0.6227, 0.2106, 1.2189, 0.7241, 0.8534, 0.2676])\nParameter containing:\ntensor([[1., 0., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 1.]])\nParameter containing:\ntensor([0.6656])\nParameter containing:\ntensor([0.3613, 0.0844, 0.4508, 0.3979, 0.4715, 0.0697, 0.0790])\nParameter containing:\ntensor([[1., 0., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 1.]])\nParameter containing:\ntensor(0.3362)\nParameter containing:\ntensor([0.5625, 0.1650, 0.5926, 0.5153, 0.7716, 0.5900, 0.4792])\nParameter containing:\ntensor([[ 0.0282,  0.0023,  0.0325, -0.0054,  0.0021, -0.0006,  0.0320],\n        [ 0.0023,  0.0092, -0.0011,  0.0094, -0.0057, -0.0117,  0.0225],\n        [ 0.0325, -0.0011,  0.0922, -0.0192,  0.0473,  0.0083,  0.0474],\n        [-0.0054,  0.0094, -0.0192,  0.0462, -0.0479,  0.0173,  0.0209],\n        [ 0.0021, -0.0057,  0.0473, -0.0479,  0.0729, -0.0206, -0.0045],\n        [-0.0006, -0.0117,  0.0083,  0.0173, -0.0206,  0.0437, -0.0172],\n        [ 0.0320,  0.0225,  0.0474,  0.0209, -0.0045, -0.0172,  0.0892]])\nParameter containing:\ntensor(0.3915)\nParameter containing:\ntensor([0.5520, 0.1997, 0.4993, 0.4864, 0.7780, 0.4641, 0.5020])\nParameter containing:\ntensor([[ 0.0396,  0.0077,  0.0342,  0.0191, -0.0283,  0.0112,  0.0568],\n        [ 0.0077,  0.0078,  0.0046,  0.0101, -0.0088, -0.0063,  0.0251],\n        [ 0.0342,  0.0046,  0.1013,  0.0129,  0.0225,  0.0277,  0.0719],\n        [ 0.0191,  0.0101,  0.0129,  0.0373, -0.0402,  0.0164,  0.0465],\n        [-0.0283, -0.0088,  0.0225, -0.0402,  0.0746, -0.0143, -0.0359],\n        [ 0.0112, -0.0063,  0.0277,  0.0164, -0.0143,  0.0364,  0.0081],\n        [ 0.0568,  0.0251,  0.0719,  0.0465, -0.0359,  0.0081,  0.1249]])\ntensor([-19.2564, -18.0547, -16.3949, -17.3645, -18.7643, -17.8371, -18.9319,\n        -17.3849, -19.0331, -18.5996, -18.8663, -19.0285, -19.3665, -17.3287,\n        -18.7925, -17.9085, -18.3725, -16.8432, -19.0094, -19.0351, -17.5516,\n        -18.6999, -19.0101, -19.0587, -18.6902, -16.6082, -17.8009, -19.3211,\n        -16.4337, -14.4446, -17.7824, -18.5536, -19.2948, -18.8873, -18.1048,\n        -18.8613, -18.8028, -17.7254, -17.8467, -17.8801, -17.5114, -18.7899,\n        -18.7854, -18.4335, -17.9540, -18.5277, -18.4958, -19.1059, -18.6475,\n        -19.0338, -19.3081, -18.6593, -17.3205, -17.4425, -16.4498, -19.1613,\n        -18.8155, -19.0773, -18.7134, -18.9291, -18.0730, -18.4230, -18.8852,\n        -18.7261, -18.7798, -18.9858, -17.5758, -18.7625, -18.0510, -15.8704,\n        -19.0205, -19.0118, -19.3139, -19.0564, -17.2290, -17.8323, -19.1797,\n        -18.7321, -18.2683, -17.9285, -18.8088, -17.6969, -19.0502, -18.4027,\n        -14.0781, -16.8003, -19.1769, -18.2311, -18.4472, -16.0477, -19.0438,\n        -17.5159, -18.0267, -18.5224, -18.4645, -19.3172, -18.2687, -18.6210,\n        -18.1220, -18.4591, -18.8159, -18.5173, -17.5662, -18.7601, -19.2286,\n        -19.0618, -16.1031, -17.5881, -17.3610, -18.7824, -17.7521, -18.1415,\n        -18.9739, -18.4967, -18.8139, -17.4159, -19.1722, -18.6194, -18.9447,\n        -18.0765, -19.2638, -17.8369, -18.0603, -17.4801, -17.9954, -17.5410,\n        -18.0189, -17.3560, -18.1195, -18.9525, -19.0643, -18.6243, -17.9777,\n        -17.0903, -19.3566, -18.5979, -18.8478, -18.3555, -17.4501, -18.2208,\n        -18.7513, -15.5237, -19.0146, -18.4070, -19.0495, -18.2230, -17.8902,\n        -18.4425, -18.8322, -17.8915, -18.8612, -17.7105, -19.0856, -19.4493,\n        -18.6984, -18.7255, -19.0555, -17.6645, -18.8864, -18.5403, -18.1607,\n        -17.9466, -18.6024, -17.6435, -18.2158, -19.3479, -19.2290, -18.5409,\n        -18.8731, -19.0171, -19.3246, -18.8465, -18.2816, -19.3152, -18.5592,\n        -18.4677, -18.3102, -18.8956, -18.7767, -17.8755, -17.4399, -19.0722,\n        -18.6370, -17.9408, -17.2431, -18.2954, -18.1857, -16.6689, -17.5154,\n        -17.0577, -17.2580, -17.3108, -19.0950, -18.6613, -18.0495, -19.0558,\n        -17.7375, -17.1572, -17.4150, -18.8458, -18.6497, -17.9805, -18.1902,\n        -18.7660, -15.8835, -18.7459, -18.6498, -17.8905, -15.9800, -17.3226,\n        -19.4193, -17.6966, -18.1932, -15.3249, -17.1338, -19.2474, -16.9423,\n        -16.6158, -15.0462, -18.6544, -18.8282, -18.0630, -17.2687, -18.8309,\n        -19.2707, -18.4543, -18.1300, -17.7864, -18.6297, -18.4028, -18.8658,\n        -18.9418, -18.6116, -18.9729, -17.0293, -15.1011, -18.5634, -15.8022,\n        -19.0415, -15.4348, -17.6778, -16.9394, -19.3467, -17.6310, -18.2665,\n        -19.1546, -19.2717, -18.1000, -18.9345, -19.3095, -18.3156, -17.0592,\n        -16.4144, -15.8596, -17.2900, -17.6649, -17.5640, -17.1291, -17.5856,\n        -18.8441, -17.9905, -18.2374, -19.0501, -17.4113, -18.6796, -17.8788,\n        -17.7550, -17.0484, -18.1735, -18.8908, -17.7271, -19.3673, -18.7071,\n        -19.2400, -17.4982, -18.7901, -19.0618, -19.2101, -18.9515, -17.7362,\n        -18.8028, -18.1069, -18.6178, -18.1941, -17.9602, -17.4824, -18.9062,\n        -19.2635, -17.8047, -19.0641, -18.8086,  -5.6501, -17.8593, -18.3549,\n        -17.9025, -17.8254, -18.1989, -18.5610, -18.8534, -19.0492, -16.7777,\n        -18.6564, -18.9140, -16.0198, -17.6024, -17.1364, -19.0579, -19.0956,\n        -13.0102, -18.8278, -18.8491, -19.0167, -19.3264, -17.9205, -17.3035,\n        -18.9889, -16.1662, -19.0933, -16.8775, -17.3989, -16.0942, -19.1201,\n        -16.6062, -17.5932, -19.0607, -19.1193, -17.8199, -19.2134, -19.2459,\n        -18.4750, -18.6372, -17.2914, -16.9354, -16.4155, -18.6404, -18.6237,\n        -13.6548, -17.8241, -17.7731, -18.9976, -16.6893, -18.7639, -19.0192,\n        -17.3781, -17.7284, -18.4769, -18.6544, -18.6396, -10.5233, -18.9755,\n        -16.2146, -18.3850, -18.8836, -18.0061, -12.4405, -18.1728, -16.0776,\n        -18.8860, -17.7030, -17.1750, -18.8864, -16.2724, -18.0929, -17.7909,\n        -19.3795, -18.2792, -11.6489, -16.9437, -19.3996, -18.7899, -18.8189,\n        -16.4978, -18.9292, -16.5404, -18.1338, -18.5574, -13.8486, -18.1189,\n        -18.7550, -17.5262, -17.1936, -11.0568, -18.9244, -18.6801, -18.5698,\n        -18.8630, -18.6425, -18.0110, -16.3563, -16.7062, -18.7585, -18.6717,\n        -18.0642, -14.7988, -19.3447, -18.4847, -17.6401, -17.0492, -16.6872,\n        -18.1093, -19.1730, -17.8896, -18.2686, -15.0559, -18.7812, -17.8376,\n        -19.0735, -19.0174, -17.5638, -19.2497, -18.5173, -18.4271, -18.2227,\n        -18.6454, -18.4256, -17.6640, -17.9564, -19.0723, -18.4326, -17.5340,\n        -15.9750, -19.0241, -18.5688, -17.6339, -18.6477, -19.3596, -17.8437,\n        -18.5472, -18.7933, -18.0868, -17.8253, -18.8675, -19.3256, -17.0121,\n        -18.9690, -18.8272, -18.9232, -18.9247, -17.0758, -18.1514, -18.4496,\n        -17.3666, -17.7035, -18.6327, -19.0636, -19.3950, -18.8716, -17.5528,\n        -17.5704, -16.1035, -18.6533, -18.8194])\n\n\nC:\\Users\\UOS\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217: UserWarning:\n\nImplicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n\n\n\n\n\n\n\n{https://openreview.net/forum?id=BJJLHbb0-}"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "irumae",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nOct 19, 2023\n\n\n[DAGMM] DAGMM implementation of arrhythmia data set\n\n\nkione kim\n\n\n\n\nOct 6, 2023\n\n\n[Autoencoder] Autoencoder implementation of MNIST data set\n\n\nkione kim\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog\nThis blog was created for my personal research, study.\n\nTip\n\npreview: To render and preview, execute the Quarto: Render command. You can alternatively use the Ctrl+Shift+K keyboard shortcut, or the Render button at the top right of the editor\nupload: To upload posts on a blog, enter “quarto publish gh-pages” in the terminal."
  },
  {
    "objectID": "posts/Autoencoder/2023-10-11-autoencoder.html",
    "href": "posts/Autoencoder/2023-10-11-autoencoder.html",
    "title": "[Autoencoder] Autoencoder implementation of MNIST data set",
    "section": "",
    "text": "- imports\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport argparse\nimport sys\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torchinfo import summary\nfrom mpl_toolkits.mplot3d import Axes3D\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\n- data set\n\ndata_root = './data'\n\nbatch_size = 32\n\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(0.5, 0.5),\n    transforms.Lambda(lambda x: x.view(-1)),\n])\n\ntrainset = datasets.MNIST(\n    root        = data_root, \n    train       = True, \n    download    = True,\n    transform   = transform\n)\n\ntestset = datasets.MNIST(\n    root        = data_root, \n    train       = False, \n    download    = False,\n    transform   = transform\n)\n\ntrain_loader = torch.utils.data.DataLoader(\n    dataset     = trainset,\n    batch_size  = batch_size,\n    shuffle     = True\n)\n\ntest_loader = torch.utils.data.DataLoader(\n    dataset     = testset,\n    batch_size  = batch_size,\n    shuffle     = False\n)\n\n- argparse\n\nparser = argparse.ArgumentParser(description='parser for argparse test')\n\nparser.add_argument('--input_dim', type=int, default=28*28)\nparser.add_argument('--learning_rate', type=float, default=0.001)\nparser.add_argument('--num_epoch', type=int, default=10)\nparser.add_argument('--enc_hidden_dim', type=str, default='256,128,64,32,3')\nparser.add_argument('--dec_hidden_dim', type=str, default='32,64,128,256')\n\n\nif 'ipykernel_launcher' in sys.argv[0]:\n    sys.argv = [sys.argv[0]]\n\nargs = parser.parse_args()\n\nenc_hidden_dim = args.enc_hidden_dim.split(',')\ndec_hidden_dim = args.dec_hidden_dim.split(',')\nargs.enc_hidden_dim_list = []\nargs.dec_hidden_dim_list = []\n\nargs.enc_hidden_dim_list.append(args.input_dim)\n\nfor i in enc_hidden_dim:\n    args.enc_hidden_dim_list.append(int(i))\n\nargs.enc_hidden_dim_list\n\nargs.dec_hidden_dim_list.append(args.enc_hidden_dim_list[-1])\n\nfor i in dec_hidden_dim:\n    args.dec_hidden_dim_list.append(int(i))\n\nargs.dec_hidden_dim_list.append(args.input_dim)\n\nargs.dec_hidden_dim_list\n\nargs\n\n- model\n\nclass midlayer(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(midlayer, self).__init__()\n        self.fc_layer   = nn.Linear(input_dim, hidden_dim)\n        self.activation = nn.LeakyReLU()\n    \n    def forward(self, x):\n        out = self.fc_layer(x)\n        out = self.activation(out)\n        return out\n\n\nclass Encoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super(Encoder, self).__init__()\n        \n        layer_list = []\n        for i in range(len(hidden_dim_list)-1):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n        \n        self.fc_layer = nn.Sequential(*layer_list)\n        \n    def forward(self, x):\n        out = self.fc_layer(x)\n\n        return out\n\n\nclass Decoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super().__init__()\n        \n        layer_list = []\n        for i in range(len(hidden_dim_list)-2):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n        \n        layer_list.append(nn.Sequential(nn.Linear(hidden_dim_list[i+1], hidden_dim_list[i+2]), nn.Sigmoid()))\n        self.fc_layer = nn.Sequential(*layer_list)\n    \n    def forward(self, x):\n        out = self.fc_layer(x)\n\n        return out\n\n\nclass Autoencoder(nn.Module):\n    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list):\n        super().__init__()\n\n        self.encoder = Encoder(enc_hidden_dim_list)\n        self.decoder = Decoder(dec_hidden_dim_list)\n\n    def forward(self, x):\n        out = self.encoder(x)\n        out = self.decoder(out)\n\n        return out\n\n\nautoencoder = Autoencoder(args.enc_hidden_dim_list, args.dec_hidden_dim_list)\nautoencoder = autoencoder.to(device)\n\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n\n- train & visualization function\n\ndef train_autoencoder(autoencoder, criterion, optimizer, num_epochs):\n    train_loss_arr  = []\n    test_loss_arr   = []\n\n    best_test_loss  = 99999999\n    early_stop, early_stop_max = 0., 3.\n    for epoch in range(num_epochs):\n        autoencoder.train()\n        epoch_loss  = 0.\n        for data in train_loader:\n            inputs, _   = data\n            inputs      = inputs.to(device)\n            optimizer.zero_grad()\n            outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n            train_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n            epoch_loss += train_loss.data\n            train_loss.backward()\n            optimizer.step()\n\n        train_loss_arr.append(epoch_loss / len(train_loader.dataset))\n        \n        if epoch != 99:\n            autoencoder.eval()\n\n            test_loss   = 0.\n\n            for data in test_loader:\n                inputs, _   = data\n                inputs      = inputs.to(device)\n\n                outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n                batch_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n                test_loss  += batch_loss.data\n\n            test_loss   = test_loss\n            test_loss_arr.append(test_loss)\n\n            if best_test_loss   &gt; test_loss:\n                best_test_loss  = test_loss\n                early_stop      = 0\n\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f} *')\n            else:\n                early_stop      += 1\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f}') \n\n        if early_stop   &gt;= early_stop_max:\n            break\n\ndef visualize_images(original, reconstructed, n=10):\n    plt.figure(figsize=(20, 4))\n    for i in range(n):\n        ax = plt.subplot(2, n, i + 1)\n        plt.imshow(original[i].reshape(28, 28), cmap='gray')\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n\n        ax = plt.subplot(2, n, i + 1 + n)\n        plt.imshow(reconstructed[i].reshape(28, 28), cmap='gray')\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n    plt.show()\n\n- train & visualization\n\ntrain_autoencoder(autoencoder, criterion, optimizer, num_epochs=args.num_epoch)\n\ndata_iter = iter(test_loader)\nimages, _ = next(data_iter)\nreconstructed = autoencoder(images)\nvisualize_images(images, reconstructed.detach().numpy())\n\n\n\n\n\nparser = argparse.ArgumentParser(description='parser for argparse test')\n\nparser.add_argument('--input_dim', type=int, default=28*28)\nparser.add_argument('--enc_hidden_dim', type=str, default='128,32')\nparser.add_argument('--dec_hidden_dim', type=str, default='128')\nparser.add_argument('--lr_rate', type=float, default=0.001)\nparser.add_argument('--num_epoch', type=int, default=10)\n\nif 'ipykernel_launcher' in sys.argv[0]:\n    sys.argv = [sys.argv[0]]  \n\nargs = parser.parse_args()\n\nenc_hidden_dim = args.enc_hidden_dim.split(',')\ndec_hidden_dim = args.dec_hidden_dim.split(',')\n\nargs.enc_hidden_dim_list = []\nargs.dec_hidden_dim_list = []\n\nargs.enc_hidden_dim_list.append(args.input_dim)\n\nfor i in enc_hidden_dim:\n    args.enc_hidden_dim_list.append(int(i))\n\nargs.dec_hidden_dim_list.append(args.enc_hidden_dim_list[-1])\n\nfor i in dec_hidden_dim:\n    args.dec_hidden_dim_list.append(int(i))\n\nargs.dec_hidden_dim_list.append(args.input_dim)\n\nargs\n\n\nclass midlayer(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(midlayer, self).__init__()\n        self.fc_layer   = nn.Linear(input_dim, hidden_dim)\n        self.activation = nn.LeakyReLU()\n   \n    def forward(self, x):\n        out = self.fc_layer(x)\n        out = self.activation(out)\n        return out\n\n\nclass Encoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super(Encoder, self).__init__()\n       \n        layer_list      = []\n        for i in range(len(hidden_dim_list)-1):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n        \n        self.fc_layer   = nn.Sequential(*layer_list)\n        \n    def forward(self, x):\n        out = self.fc_layer(x)\n        return out\n\n\nclass Decoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super().__init__()\n        \n        layer_list = []\n        for i in range(len(hidden_dim_list)-2):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n    \n        layer_list.append(nn.Sequential(nn.Linear(hidden_dim_list[i+1], hidden_dim_list[i+2])))\n        self.fc_layer = nn.Sequential(*layer_list)\n    \n    def forward(self, x):\n        out = self.fc_layer(x)\n        return out\n\n\nclass Autoencoder(nn.Module):\n    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list):\n        super().__init__()\n        self.encoder = Encoder(enc_hidden_dim_list)\n        self.decoder = Decoder(dec_hidden_dim_list)\n\n    def forward(self, x):\n        out = self.encoder(x)\n        out = self.decoder(out)\n        return out\n\n\nautoencoder = Autoencoder(args.enc_hidden_dim_list, args.dec_hidden_dim_list)\nautoencoder = autoencoder.to(device)\n\ncriterion = nn.MSELoss() \noptimizer = optim.Adam(autoencoder.parameters(), lr=args.lr_rate)\n\n\ndef train_autoencoder(autoencoder, criterion, optimizer, num_epochs):\n    train_loss_arr  = []\n    test_loss_arr   = []\n\n    best_test_loss  = 99999999\n    early_stop, early_stop_max = 0., 3.\n    for epoch in range(num_epochs):\n        autoencoder.train()\n        epoch_loss  = 0.\n        for data in train_loader:\n            inputs, _   = data\n            inputs      = inputs.to(device)\n            optimizer.zero_grad()\n            outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n            train_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n            epoch_loss += train_loss.data\n            train_loss.backward()\n            optimizer.step()\n\n        train_loss_arr.append(epoch_loss / len(train_loader.dataset))\n        \n        if epoch != -1:\n            autoencoder.eval()\n\n            test_loss = 0.\n\n            for data in test_loader:\n                inputs, _   = data\n                inputs      = inputs.to(device)\n\n                outputs = autoencoder(inputs.view(inputs.size(0), -1))\n                batch_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n                test_loss  += batch_loss.data\n\n            test_loss = test_loss\n            test_loss_arr.append(test_loss)\n\n            if best_test_loss   &gt; test_loss:\n                best_test_loss  = test_loss\n                early_stop      = 0\n\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f} *')\n            else:\n                early_stop += 1\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f}') \n\n        if early_stop &gt;= early_stop_max:\n            break\n\n\ntrain_autoencoder(autoencoder, criterion, optimizer, num_epochs=args.num_epoch)\n\ndata_iter       = iter(test_loader)\nimages, _       = next(data_iter)\nreconstructed   = autoencoder(images)\nvisualize_images(images, reconstructed.detach().numpy())\n\n\n\n\n\nparser = argparse.ArgumentParser(description='parser for argparse test')\n\nparser.add_argument('--enc_hidden_dim', type=str, default='784,128,32')\nparser.add_argument('--dec_hidden_dim', type=str, default='128,784')\nparser.add_argument('--lr_rate', type=float, default=0.001)\nparser.add_argument('--num_epoch', type=int, default=10)\n\nif 'ipykernel_launcher' in sys.argv[0]:\n    sys.argv = [sys.argv[0]]  \n\nargs = parser.parse_args()\n\nenc_hidden_dim = args.enc_hidden_dim.split(',')\ndec_hidden_dim = args.dec_hidden_dim.split(',')\n\nargs.enc_hidden_dim_list = []\nargs.dec_hidden_dim_list = []\n\nfor i in enc_hidden_dim:\n    args.enc_hidden_dim_list.append(int(i))\n\nargs.enc_hidden_dim_list\n\nargs.dec_hidden_dim_list.append(args.enc_hidden_dim_list[-1])\n\nfor i in dec_hidden_dim:\n    args.dec_hidden_dim_list.append(int(i))\n\nargs.dec_hidden_dim_list\n\nargs\n\n\nclass midlayer(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(midlayer, self).__init__()\n        self.fc_layer   = nn.Linear(input_dim, hidden_dim)\n        self.activation = nn.LeakyReLU()\n   \n    def forward(self, x):\n        out = self.fc_layer(x)\n        out = self.activation(out)\n        return out\n\n\nclass Encoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super(Encoder, self).__init__()\n       \n        layer_list      = []\n        for i in range(len(hidden_dim_list)-1):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n        \n        self.fc_layer   = nn.Sequential(*layer_list)\n        \n    def forward(self, x):\n        out = self.fc_layer(x)\n        return out\n\n\nclass Decoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super().__init__()\n        \n        layer_list      = []\n        for i in range(len(hidden_dim_list)-2):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n    \n        layer_list.append(nn.Sequential(nn.Linear(hidden_dim_list[i+1], hidden_dim_list[i+2])))\n        self.fc_layer   = nn.Sequential(*layer_list)\n    \n    def forward(self, x):\n        out = self.fc_layer(x)\n        return out\n\n\nclass Autoencoder(nn.Module):\n    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list):\n        super().__init__()\n        self.encoder = Encoder(enc_hidden_dim_list)\n        self.decoder = Decoder(dec_hidden_dim_list)\n\n    def forward(self, x):\n        out = self.encoder(x)\n        out = self.decoder(out)\n        return out\n\n\nautoencoder = Autoencoder(args.enc_hidden_dim_list, args.dec_hidden_dim_list)\nautoencoder = autoencoder.to(device)\n\ncriterion = nn.MSELoss() \noptimizer = optim.Adam(autoencoder.parameters(), lr=args.lr_rate)\n\n\ndef train_autoencoder(autoencoder, criterion, optimizer, num_epochs):\n    train_loss_arr  = []\n    test_loss_arr   = []\n\n    best_test_loss  = 99999999\n    early_stop, early_stop_max = 0., 3.\n    for epoch in range(num_epochs):\n        autoencoder.train()\n        epoch_loss  = 0.\n        for data in train_loader:\n            inputs, _   = data\n            inputs      = inputs.to(device)\n            optimizer.zero_grad()\n            outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n            train_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n            epoch_loss += train_loss.data\n            train_loss.backward()\n            optimizer.step()\n\n        train_loss_arr.append(epoch_loss / len(train_loader.dataset))\n        \n        if epoch != -1:\n            autoencoder.eval()\n\n            test_loss = 0.\n\n            for data in test_loader:\n                inputs, _   = data\n                inputs      = inputs.to(device)\n\n                outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n                batch_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n                test_loss  += batch_loss.data\n\n            test_loss = test_loss\n            test_loss_arr.append(test_loss)\n\n            if best_test_loss   &gt; test_loss:\n                best_test_loss  = test_loss\n                early_stop      = 0\n\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f} *')\n            else:\n                early_stop += 1\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f}') \n\n        if early_stop &gt;= early_stop_max:\n            break\n\n\ntrain_autoencoder(autoencoder, criterion, optimizer, num_epochs=args.num_epoch)\n\ndata_iter       = iter(test_loader)\nimages, _       = next(data_iter)\nreconstructed   = autoencoder(images)\nvisualize_images(images, reconstructed.detach().numpy())\n\n\n\n\n\narser = argparse.ArgumentParser(description='parser for argparse test')\n\nparser.add_argument('--enc_hidden_dim', type=str, default='784,128,32')\nparser.add_argument('--lr_rate', type=float, default=0.001)\nparser.add_argument('--num_epoch', type=int, default=10)\n\nif 'ipykernel_launcher' in sys.argv[0]:\n    sys.argv = [sys.argv[0]]  \n\nargs = parser.parse_args()\n\nenc_hidden_dim = args.enc_hidden_dim.split(',') ### key point\ndec_hidden_dim = args.enc_hidden_dim.split(',')\n\nargs.enc_hidden_dim_list = []\nargs.dec_hidden_dim_list = []\n\nfor i in enc_hidden_dim:\n    args.enc_hidden_dim_list.append(int(i))\n\nargs.enc_hidden_dim_list\n\nfor i in enc_hidden_dim[::-1]:\n    args.dec_hidden_dim_list.append(int(i))\n\nargs.dec_hidden_dim_list\n\nargs\n\n\nclass midlayer(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(midlayer, self).__init__()\n        self.fc_layer   = nn.Linear(input_dim, hidden_dim)\n        self.activation = nn.LeakyReLU()\n   \n    def forward(self, x):\n        out = self.fc_layer(x)\n        out = self.activation(out)\n        return out\n\nclass Encoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super(Encoder, self).__init__()\n       \n        layer_list      = []\n        for i in range(len(hidden_dim_list)-1):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n        \n        self.fc_layer   = nn.Sequential(*layer_list)\n        \n    def forward(self, x):\n        out = self.fc_layer(x)\n        return out\n\nclass Decoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super().__init__()\n        \n        layer_list      = []\n        for i in range(len(hidden_dim_list)-2):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n    \n        layer_list.append(nn.Sequential(nn.Linear(hidden_dim_list[i+1], hidden_dim_list[i+2])))\n        self.fc_layer   = nn.Sequential(*layer_list)\n    \n    def forward(self, x):\n        out = self.fc_layer(x)\n        return out\n\nclass Autoencoder(nn.Module):\n    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list):\n        super().__init__()\n        self.encoder = Encoder(enc_hidden_dim_list)\n        self.decoder = Decoder(dec_hidden_dim_list)\n\n    def forward(self, x):\n        out = self.encoder(x)\n        out = self.decoder(out)\n        return out\n\n\nautoencoder = Autoencoder(args.enc_hidden_dim_list, args.dec_hidden_dim_list)\nautoencoder = autoencoder.to(device)\n\ncriterion = nn.MSELoss() \noptimizer = optim.Adam(autoencoder.parameters(), lr=args.lr_rate)\n\n\ndef train_autoencoder(autoencoder, criterion, optimizer, num_epochs):\n    train_loss_arr  = []\n    test_loss_arr   = []\n\n    best_test_loss  = 99999999\n    early_stop, early_stop_max = 0., 3.\n    for epoch in range(num_epochs):\n        autoencoder.train()\n        epoch_loss  = 0.\n        for data in train_loader:\n            inputs, _   = data\n            inputs      = inputs.to(device)\n            optimizer.zero_grad()\n            outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n            train_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n            epoch_loss += train_loss.data\n            train_loss.backward()\n            optimizer.step()\n\n        train_loss_arr.append(epoch_loss / len(train_loader.dataset))\n        \n        if epoch != -1:\n            autoencoder.eval()\n\n            test_loss = 0.\n\n            for data in test_loader:\n                inputs, _   = data\n                inputs      = inputs.to(device)\n\n                outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n                batch_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n                test_loss  += batch_loss.data\n\n            test_loss = test_loss\n            test_loss_arr.append(test_loss)\n\n            if best_test_loss   &gt; test_loss:\n                best_test_loss  = test_loss\n                early_stop      = 0\n\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f} *')\n            else:\n                early_stop += 1\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f}') \n\n        if early_stop &gt;= early_stop_max:\n            break\n\n\ntrain_autoencoder(autoencoder, criterion, optimizer, num_epochs=args.num_epoch)\n\ndata_iter       = iter(test_loader)\nimages, _       = next(data_iter)\nreconstructed   = autoencoder(images)\nvisualize_images(images, reconstructed.detach().numpy())\n\n\n\n\n\nparser = argparse.ArgumentParser(description='parser for argparse test')\n\nparser.add_argument('--enc_hidden_dim', type=str, default='784,256,128,64,32')\nparser.add_argument('--lr_rate', type=float, default=0.001)\nparser.add_argument('--num_epoch', type=int, default=10)\n\nif 'ipykernel_launcher' in sys.argv[0]:\n    sys.argv = [sys.argv[0]]  \n\nargs = parser.parse_args()\n\nenc_hidden_dim = args.enc_hidden_dim.split(',') ### key point(dec_hidden_dim을 따로 정의하지 않았음)\n\nargs.enc_hidden_dim_list = []\n\nfor i in enc_hidden_dim:\n    args.enc_hidden_dim_list.append(int(i))\n\nargs.enc_hidden_dim_list\n\nargs.enc_hidden_dim_list[::-1]\n\nargs\n\n\nclass midlayer(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(midlayer, self).__init__()\n        self.fc_layer   = nn.Linear(input_dim, hidden_dim)\n        self.activation = nn.LeakyReLU()\n   \n    def forward(self, x):\n        out = self.fc_layer(x)\n        out = self.activation(out)\n        return out\n\nclass Encoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super(Encoder, self).__init__()\n       \n        layer_list      = []\n        for i in range(len(hidden_dim_list)-1):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n        \n        self.fc_layer   = nn.Sequential(*layer_list)\n        \n    def forward(self, x):\n        out = self.fc_layer(x)\n        return out\n\nclass Decoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super().__init__()\n        \n        layer_list = []\n        for i in range(len(hidden_dim_list)-2):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n    \n        layer_list.append(nn.Sequential(nn.Linear(hidden_dim_list[i+1], hidden_dim_list[i+2])))\n        self.fc_layer = nn.Sequential(*layer_list)\n    \n    def forward(self, x):\n        out = self.fc_layer(x)\n        return out\n\nclass Autoencoder(nn.Module):\n    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list):\n        super().__init__()\n        self.encoder = Encoder(enc_hidden_dim_list)\n        self.decoder = Decoder(dec_hidden_dim_list)\n\n    def forward(self, x):\n        out = self.encoder(x)\n        out = self.decoder(out)\n        return out\n\n\nautoencoder = Autoencoder(args.enc_hidden_dim_list, args.enc_hidden_dim_list[::-1]) ### key point(dec_hidden_dim_list를 enc_hiffen_dim_list[::-1]을 이용해서 정의함)\nautoencoder = autoencoder.to(device)\n\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(autoencoder.parameters(), lr=args.lr_rate)\n\n\ndef train_autoencoder(autoencoder, criterion, optimizer, num_epochs):\n    train_loss_arr  = []\n    test_loss_arr   = []\n\n    best_test_loss  = 99999999\n    early_stop, early_stop_max = 0., 3.\n    for epoch in range(num_epochs):\n        autoencoder.train()\n        epoch_loss  = 0.\n        for data in train_loader:\n            inputs, _   = data\n            inputs      = inputs.to(device)\n            optimizer.zero_grad()\n            outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n            train_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n            epoch_loss += train_loss.data\n            train_loss.backward()\n            optimizer.step()\n\n        train_loss_arr.append(epoch_loss / len(train_loader.dataset))\n        \n        if epoch != -1:\n            autoencoder.eval()\n\n            test_loss = 0.\n\n            for data in test_loader:\n                inputs, _   = data\n                inputs      = inputs.to(device)\n\n                outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n                batch_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n                test_loss  += batch_loss.data\n\n            test_loss = test_loss\n            test_loss_arr.append(test_loss)\n\n            if best_test_loss   &gt; test_loss:\n                best_test_loss  = test_loss\n                early_stop      = 0\n\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f} *')\n            else:\n                early_stop += 1\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f}') \n\n        if early_stop &gt;= early_stop_max:\n            break\n\n\ntrain_autoencoder(autoencoder, criterion, optimizer, num_epochs=args.num_epoch)\n\ndata_iter       = iter(test_loader)\nimages, _       = next(data_iter)\nreconstructed   = autoencoder(images)\nvisualize_images(images, reconstructed.detach().numpy())"
  },
  {
    "objectID": "posts/Autoencoder/2023-10-11-autoencoder.html#autoencoder-for-mnist-data-set",
    "href": "posts/Autoencoder/2023-10-11-autoencoder.html#autoencoder-for-mnist-data-set",
    "title": "[Autoencoder] Autoencoder implementation of MNIST data set",
    "section": "",
    "text": "- imports\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport argparse\nimport sys\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torchinfo import summary\nfrom mpl_toolkits.mplot3d import Axes3D\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\n- data set\n\ndata_root = './data'\n\nbatch_size = 32\n\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(0.5, 0.5),\n    transforms.Lambda(lambda x: x.view(-1)),\n])\n\ntrainset = datasets.MNIST(\n    root        = data_root, \n    train       = True, \n    download    = True,\n    transform   = transform\n)\n\ntestset = datasets.MNIST(\n    root        = data_root, \n    train       = False, \n    download    = False,\n    transform   = transform\n)\n\ntrain_loader = torch.utils.data.DataLoader(\n    dataset     = trainset,\n    batch_size  = batch_size,\n    shuffle     = True\n)\n\ntest_loader = torch.utils.data.DataLoader(\n    dataset     = testset,\n    batch_size  = batch_size,\n    shuffle     = False\n)\n\n- argparse\n\nparser = argparse.ArgumentParser(description='parser for argparse test')\n\nparser.add_argument('--input_dim', type=int, default=28*28)\nparser.add_argument('--learning_rate', type=float, default=0.001)\nparser.add_argument('--num_epoch', type=int, default=10)\nparser.add_argument('--enc_hidden_dim', type=str, default='256,128,64,32,3')\nparser.add_argument('--dec_hidden_dim', type=str, default='32,64,128,256')\n\n\nif 'ipykernel_launcher' in sys.argv[0]:\n    sys.argv = [sys.argv[0]]\n\nargs = parser.parse_args()\n\nenc_hidden_dim = args.enc_hidden_dim.split(',')\ndec_hidden_dim = args.dec_hidden_dim.split(',')\nargs.enc_hidden_dim_list = []\nargs.dec_hidden_dim_list = []\n\nargs.enc_hidden_dim_list.append(args.input_dim)\n\nfor i in enc_hidden_dim:\n    args.enc_hidden_dim_list.append(int(i))\n\nargs.enc_hidden_dim_list\n\nargs.dec_hidden_dim_list.append(args.enc_hidden_dim_list[-1])\n\nfor i in dec_hidden_dim:\n    args.dec_hidden_dim_list.append(int(i))\n\nargs.dec_hidden_dim_list.append(args.input_dim)\n\nargs.dec_hidden_dim_list\n\nargs\n\n- model\n\nclass midlayer(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(midlayer, self).__init__()\n        self.fc_layer   = nn.Linear(input_dim, hidden_dim)\n        self.activation = nn.LeakyReLU()\n    \n    def forward(self, x):\n        out = self.fc_layer(x)\n        out = self.activation(out)\n        return out\n\n\nclass Encoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super(Encoder, self).__init__()\n        \n        layer_list = []\n        for i in range(len(hidden_dim_list)-1):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n        \n        self.fc_layer = nn.Sequential(*layer_list)\n        \n    def forward(self, x):\n        out = self.fc_layer(x)\n\n        return out\n\n\nclass Decoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super().__init__()\n        \n        layer_list = []\n        for i in range(len(hidden_dim_list)-2):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n        \n        layer_list.append(nn.Sequential(nn.Linear(hidden_dim_list[i+1], hidden_dim_list[i+2]), nn.Sigmoid()))\n        self.fc_layer = nn.Sequential(*layer_list)\n    \n    def forward(self, x):\n        out = self.fc_layer(x)\n\n        return out\n\n\nclass Autoencoder(nn.Module):\n    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list):\n        super().__init__()\n\n        self.encoder = Encoder(enc_hidden_dim_list)\n        self.decoder = Decoder(dec_hidden_dim_list)\n\n    def forward(self, x):\n        out = self.encoder(x)\n        out = self.decoder(out)\n\n        return out\n\n\nautoencoder = Autoencoder(args.enc_hidden_dim_list, args.dec_hidden_dim_list)\nautoencoder = autoencoder.to(device)\n\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n\n- train & visualization function\n\ndef train_autoencoder(autoencoder, criterion, optimizer, num_epochs):\n    train_loss_arr  = []\n    test_loss_arr   = []\n\n    best_test_loss  = 99999999\n    early_stop, early_stop_max = 0., 3.\n    for epoch in range(num_epochs):\n        autoencoder.train()\n        epoch_loss  = 0.\n        for data in train_loader:\n            inputs, _   = data\n            inputs      = inputs.to(device)\n            optimizer.zero_grad()\n            outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n            train_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n            epoch_loss += train_loss.data\n            train_loss.backward()\n            optimizer.step()\n\n        train_loss_arr.append(epoch_loss / len(train_loader.dataset))\n        \n        if epoch != 99:\n            autoencoder.eval()\n\n            test_loss   = 0.\n\n            for data in test_loader:\n                inputs, _   = data\n                inputs      = inputs.to(device)\n\n                outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n                batch_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n                test_loss  += batch_loss.data\n\n            test_loss   = test_loss\n            test_loss_arr.append(test_loss)\n\n            if best_test_loss   &gt; test_loss:\n                best_test_loss  = test_loss\n                early_stop      = 0\n\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f} *')\n            else:\n                early_stop      += 1\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f}') \n\n        if early_stop   &gt;= early_stop_max:\n            break\n\ndef visualize_images(original, reconstructed, n=10):\n    plt.figure(figsize=(20, 4))\n    for i in range(n):\n        ax = plt.subplot(2, n, i + 1)\n        plt.imshow(original[i].reshape(28, 28), cmap='gray')\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n\n        ax = plt.subplot(2, n, i + 1 + n)\n        plt.imshow(reconstructed[i].reshape(28, 28), cmap='gray')\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n    plt.show()\n\n- train & visualization\n\ntrain_autoencoder(autoencoder, criterion, optimizer, num_epochs=args.num_epoch)\n\ndata_iter = iter(test_loader)\nimages, _ = next(data_iter)\nreconstructed = autoencoder(images)\nvisualize_images(images, reconstructed.detach().numpy())\n\n\n\n\n\nparser = argparse.ArgumentParser(description='parser for argparse test')\n\nparser.add_argument('--input_dim', type=int, default=28*28)\nparser.add_argument('--enc_hidden_dim', type=str, default='128,32')\nparser.add_argument('--dec_hidden_dim', type=str, default='128')\nparser.add_argument('--lr_rate', type=float, default=0.001)\nparser.add_argument('--num_epoch', type=int, default=10)\n\nif 'ipykernel_launcher' in sys.argv[0]:\n    sys.argv = [sys.argv[0]]  \n\nargs = parser.parse_args()\n\nenc_hidden_dim = args.enc_hidden_dim.split(',')\ndec_hidden_dim = args.dec_hidden_dim.split(',')\n\nargs.enc_hidden_dim_list = []\nargs.dec_hidden_dim_list = []\n\nargs.enc_hidden_dim_list.append(args.input_dim)\n\nfor i in enc_hidden_dim:\n    args.enc_hidden_dim_list.append(int(i))\n\nargs.dec_hidden_dim_list.append(args.enc_hidden_dim_list[-1])\n\nfor i in dec_hidden_dim:\n    args.dec_hidden_dim_list.append(int(i))\n\nargs.dec_hidden_dim_list.append(args.input_dim)\n\nargs\n\n\nclass midlayer(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(midlayer, self).__init__()\n        self.fc_layer   = nn.Linear(input_dim, hidden_dim)\n        self.activation = nn.LeakyReLU()\n   \n    def forward(self, x):\n        out = self.fc_layer(x)\n        out = self.activation(out)\n        return out\n\n\nclass Encoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super(Encoder, self).__init__()\n       \n        layer_list      = []\n        for i in range(len(hidden_dim_list)-1):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n        \n        self.fc_layer   = nn.Sequential(*layer_list)\n        \n    def forward(self, x):\n        out = self.fc_layer(x)\n        return out\n\n\nclass Decoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super().__init__()\n        \n        layer_list = []\n        for i in range(len(hidden_dim_list)-2):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n    \n        layer_list.append(nn.Sequential(nn.Linear(hidden_dim_list[i+1], hidden_dim_list[i+2])))\n        self.fc_layer = nn.Sequential(*layer_list)\n    \n    def forward(self, x):\n        out = self.fc_layer(x)\n        return out\n\n\nclass Autoencoder(nn.Module):\n    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list):\n        super().__init__()\n        self.encoder = Encoder(enc_hidden_dim_list)\n        self.decoder = Decoder(dec_hidden_dim_list)\n\n    def forward(self, x):\n        out = self.encoder(x)\n        out = self.decoder(out)\n        return out\n\n\nautoencoder = Autoencoder(args.enc_hidden_dim_list, args.dec_hidden_dim_list)\nautoencoder = autoencoder.to(device)\n\ncriterion = nn.MSELoss() \noptimizer = optim.Adam(autoencoder.parameters(), lr=args.lr_rate)\n\n\ndef train_autoencoder(autoencoder, criterion, optimizer, num_epochs):\n    train_loss_arr  = []\n    test_loss_arr   = []\n\n    best_test_loss  = 99999999\n    early_stop, early_stop_max = 0., 3.\n    for epoch in range(num_epochs):\n        autoencoder.train()\n        epoch_loss  = 0.\n        for data in train_loader:\n            inputs, _   = data\n            inputs      = inputs.to(device)\n            optimizer.zero_grad()\n            outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n            train_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n            epoch_loss += train_loss.data\n            train_loss.backward()\n            optimizer.step()\n\n        train_loss_arr.append(epoch_loss / len(train_loader.dataset))\n        \n        if epoch != -1:\n            autoencoder.eval()\n\n            test_loss = 0.\n\n            for data in test_loader:\n                inputs, _   = data\n                inputs      = inputs.to(device)\n\n                outputs = autoencoder(inputs.view(inputs.size(0), -1))\n                batch_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n                test_loss  += batch_loss.data\n\n            test_loss = test_loss\n            test_loss_arr.append(test_loss)\n\n            if best_test_loss   &gt; test_loss:\n                best_test_loss  = test_loss\n                early_stop      = 0\n\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f} *')\n            else:\n                early_stop += 1\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f}') \n\n        if early_stop &gt;= early_stop_max:\n            break\n\n\ntrain_autoencoder(autoencoder, criterion, optimizer, num_epochs=args.num_epoch)\n\ndata_iter       = iter(test_loader)\nimages, _       = next(data_iter)\nreconstructed   = autoencoder(images)\nvisualize_images(images, reconstructed.detach().numpy())\n\n\n\n\n\nparser = argparse.ArgumentParser(description='parser for argparse test')\n\nparser.add_argument('--enc_hidden_dim', type=str, default='784,128,32')\nparser.add_argument('--dec_hidden_dim', type=str, default='128,784')\nparser.add_argument('--lr_rate', type=float, default=0.001)\nparser.add_argument('--num_epoch', type=int, default=10)\n\nif 'ipykernel_launcher' in sys.argv[0]:\n    sys.argv = [sys.argv[0]]  \n\nargs = parser.parse_args()\n\nenc_hidden_dim = args.enc_hidden_dim.split(',')\ndec_hidden_dim = args.dec_hidden_dim.split(',')\n\nargs.enc_hidden_dim_list = []\nargs.dec_hidden_dim_list = []\n\nfor i in enc_hidden_dim:\n    args.enc_hidden_dim_list.append(int(i))\n\nargs.enc_hidden_dim_list\n\nargs.dec_hidden_dim_list.append(args.enc_hidden_dim_list[-1])\n\nfor i in dec_hidden_dim:\n    args.dec_hidden_dim_list.append(int(i))\n\nargs.dec_hidden_dim_list\n\nargs\n\n\nclass midlayer(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(midlayer, self).__init__()\n        self.fc_layer   = nn.Linear(input_dim, hidden_dim)\n        self.activation = nn.LeakyReLU()\n   \n    def forward(self, x):\n        out = self.fc_layer(x)\n        out = self.activation(out)\n        return out\n\n\nclass Encoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super(Encoder, self).__init__()\n       \n        layer_list      = []\n        for i in range(len(hidden_dim_list)-1):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n        \n        self.fc_layer   = nn.Sequential(*layer_list)\n        \n    def forward(self, x):\n        out = self.fc_layer(x)\n        return out\n\n\nclass Decoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super().__init__()\n        \n        layer_list      = []\n        for i in range(len(hidden_dim_list)-2):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n    \n        layer_list.append(nn.Sequential(nn.Linear(hidden_dim_list[i+1], hidden_dim_list[i+2])))\n        self.fc_layer   = nn.Sequential(*layer_list)\n    \n    def forward(self, x):\n        out = self.fc_layer(x)\n        return out\n\n\nclass Autoencoder(nn.Module):\n    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list):\n        super().__init__()\n        self.encoder = Encoder(enc_hidden_dim_list)\n        self.decoder = Decoder(dec_hidden_dim_list)\n\n    def forward(self, x):\n        out = self.encoder(x)\n        out = self.decoder(out)\n        return out\n\n\nautoencoder = Autoencoder(args.enc_hidden_dim_list, args.dec_hidden_dim_list)\nautoencoder = autoencoder.to(device)\n\ncriterion = nn.MSELoss() \noptimizer = optim.Adam(autoencoder.parameters(), lr=args.lr_rate)\n\n\ndef train_autoencoder(autoencoder, criterion, optimizer, num_epochs):\n    train_loss_arr  = []\n    test_loss_arr   = []\n\n    best_test_loss  = 99999999\n    early_stop, early_stop_max = 0., 3.\n    for epoch in range(num_epochs):\n        autoencoder.train()\n        epoch_loss  = 0.\n        for data in train_loader:\n            inputs, _   = data\n            inputs      = inputs.to(device)\n            optimizer.zero_grad()\n            outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n            train_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n            epoch_loss += train_loss.data\n            train_loss.backward()\n            optimizer.step()\n\n        train_loss_arr.append(epoch_loss / len(train_loader.dataset))\n        \n        if epoch != -1:\n            autoencoder.eval()\n\n            test_loss = 0.\n\n            for data in test_loader:\n                inputs, _   = data\n                inputs      = inputs.to(device)\n\n                outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n                batch_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n                test_loss  += batch_loss.data\n\n            test_loss = test_loss\n            test_loss_arr.append(test_loss)\n\n            if best_test_loss   &gt; test_loss:\n                best_test_loss  = test_loss\n                early_stop      = 0\n\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f} *')\n            else:\n                early_stop += 1\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f}') \n\n        if early_stop &gt;= early_stop_max:\n            break\n\n\ntrain_autoencoder(autoencoder, criterion, optimizer, num_epochs=args.num_epoch)\n\ndata_iter       = iter(test_loader)\nimages, _       = next(data_iter)\nreconstructed   = autoencoder(images)\nvisualize_images(images, reconstructed.detach().numpy())\n\n\n\n\n\narser = argparse.ArgumentParser(description='parser for argparse test')\n\nparser.add_argument('--enc_hidden_dim', type=str, default='784,128,32')\nparser.add_argument('--lr_rate', type=float, default=0.001)\nparser.add_argument('--num_epoch', type=int, default=10)\n\nif 'ipykernel_launcher' in sys.argv[0]:\n    sys.argv = [sys.argv[0]]  \n\nargs = parser.parse_args()\n\nenc_hidden_dim = args.enc_hidden_dim.split(',') ### key point\ndec_hidden_dim = args.enc_hidden_dim.split(',')\n\nargs.enc_hidden_dim_list = []\nargs.dec_hidden_dim_list = []\n\nfor i in enc_hidden_dim:\n    args.enc_hidden_dim_list.append(int(i))\n\nargs.enc_hidden_dim_list\n\nfor i in enc_hidden_dim[::-1]:\n    args.dec_hidden_dim_list.append(int(i))\n\nargs.dec_hidden_dim_list\n\nargs\n\n\nclass midlayer(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(midlayer, self).__init__()\n        self.fc_layer   = nn.Linear(input_dim, hidden_dim)\n        self.activation = nn.LeakyReLU()\n   \n    def forward(self, x):\n        out = self.fc_layer(x)\n        out = self.activation(out)\n        return out\n\nclass Encoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super(Encoder, self).__init__()\n       \n        layer_list      = []\n        for i in range(len(hidden_dim_list)-1):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n        \n        self.fc_layer   = nn.Sequential(*layer_list)\n        \n    def forward(self, x):\n        out = self.fc_layer(x)\n        return out\n\nclass Decoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super().__init__()\n        \n        layer_list      = []\n        for i in range(len(hidden_dim_list)-2):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n    \n        layer_list.append(nn.Sequential(nn.Linear(hidden_dim_list[i+1], hidden_dim_list[i+2])))\n        self.fc_layer   = nn.Sequential(*layer_list)\n    \n    def forward(self, x):\n        out = self.fc_layer(x)\n        return out\n\nclass Autoencoder(nn.Module):\n    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list):\n        super().__init__()\n        self.encoder = Encoder(enc_hidden_dim_list)\n        self.decoder = Decoder(dec_hidden_dim_list)\n\n    def forward(self, x):\n        out = self.encoder(x)\n        out = self.decoder(out)\n        return out\n\n\nautoencoder = Autoencoder(args.enc_hidden_dim_list, args.dec_hidden_dim_list)\nautoencoder = autoencoder.to(device)\n\ncriterion = nn.MSELoss() \noptimizer = optim.Adam(autoencoder.parameters(), lr=args.lr_rate)\n\n\ndef train_autoencoder(autoencoder, criterion, optimizer, num_epochs):\n    train_loss_arr  = []\n    test_loss_arr   = []\n\n    best_test_loss  = 99999999\n    early_stop, early_stop_max = 0., 3.\n    for epoch in range(num_epochs):\n        autoencoder.train()\n        epoch_loss  = 0.\n        for data in train_loader:\n            inputs, _   = data\n            inputs      = inputs.to(device)\n            optimizer.zero_grad()\n            outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n            train_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n            epoch_loss += train_loss.data\n            train_loss.backward()\n            optimizer.step()\n\n        train_loss_arr.append(epoch_loss / len(train_loader.dataset))\n        \n        if epoch != -1:\n            autoencoder.eval()\n\n            test_loss = 0.\n\n            for data in test_loader:\n                inputs, _   = data\n                inputs      = inputs.to(device)\n\n                outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n                batch_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n                test_loss  += batch_loss.data\n\n            test_loss = test_loss\n            test_loss_arr.append(test_loss)\n\n            if best_test_loss   &gt; test_loss:\n                best_test_loss  = test_loss\n                early_stop      = 0\n\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f} *')\n            else:\n                early_stop += 1\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f}') \n\n        if early_stop &gt;= early_stop_max:\n            break\n\n\ntrain_autoencoder(autoencoder, criterion, optimizer, num_epochs=args.num_epoch)\n\ndata_iter       = iter(test_loader)\nimages, _       = next(data_iter)\nreconstructed   = autoencoder(images)\nvisualize_images(images, reconstructed.detach().numpy())\n\n\n\n\n\nparser = argparse.ArgumentParser(description='parser for argparse test')\n\nparser.add_argument('--enc_hidden_dim', type=str, default='784,256,128,64,32')\nparser.add_argument('--lr_rate', type=float, default=0.001)\nparser.add_argument('--num_epoch', type=int, default=10)\n\nif 'ipykernel_launcher' in sys.argv[0]:\n    sys.argv = [sys.argv[0]]  \n\nargs = parser.parse_args()\n\nenc_hidden_dim = args.enc_hidden_dim.split(',') ### key point(dec_hidden_dim을 따로 정의하지 않았음)\n\nargs.enc_hidden_dim_list = []\n\nfor i in enc_hidden_dim:\n    args.enc_hidden_dim_list.append(int(i))\n\nargs.enc_hidden_dim_list\n\nargs.enc_hidden_dim_list[::-1]\n\nargs\n\n\nclass midlayer(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(midlayer, self).__init__()\n        self.fc_layer   = nn.Linear(input_dim, hidden_dim)\n        self.activation = nn.LeakyReLU()\n   \n    def forward(self, x):\n        out = self.fc_layer(x)\n        out = self.activation(out)\n        return out\n\nclass Encoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super(Encoder, self).__init__()\n       \n        layer_list      = []\n        for i in range(len(hidden_dim_list)-1):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n        \n        self.fc_layer   = nn.Sequential(*layer_list)\n        \n    def forward(self, x):\n        out = self.fc_layer(x)\n        return out\n\nclass Decoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super().__init__()\n        \n        layer_list = []\n        for i in range(len(hidden_dim_list)-2):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n    \n        layer_list.append(nn.Sequential(nn.Linear(hidden_dim_list[i+1], hidden_dim_list[i+2])))\n        self.fc_layer = nn.Sequential(*layer_list)\n    \n    def forward(self, x):\n        out = self.fc_layer(x)\n        return out\n\nclass Autoencoder(nn.Module):\n    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list):\n        super().__init__()\n        self.encoder = Encoder(enc_hidden_dim_list)\n        self.decoder = Decoder(dec_hidden_dim_list)\n\n    def forward(self, x):\n        out = self.encoder(x)\n        out = self.decoder(out)\n        return out\n\n\nautoencoder = Autoencoder(args.enc_hidden_dim_list, args.enc_hidden_dim_list[::-1]) ### key point(dec_hidden_dim_list를 enc_hiffen_dim_list[::-1]을 이용해서 정의함)\nautoencoder = autoencoder.to(device)\n\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(autoencoder.parameters(), lr=args.lr_rate)\n\n\ndef train_autoencoder(autoencoder, criterion, optimizer, num_epochs):\n    train_loss_arr  = []\n    test_loss_arr   = []\n\n    best_test_loss  = 99999999\n    early_stop, early_stop_max = 0., 3.\n    for epoch in range(num_epochs):\n        autoencoder.train()\n        epoch_loss  = 0.\n        for data in train_loader:\n            inputs, _   = data\n            inputs      = inputs.to(device)\n            optimizer.zero_grad()\n            outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n            train_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n            epoch_loss += train_loss.data\n            train_loss.backward()\n            optimizer.step()\n\n        train_loss_arr.append(epoch_loss / len(train_loader.dataset))\n        \n        if epoch != -1:\n            autoencoder.eval()\n\n            test_loss = 0.\n\n            for data in test_loader:\n                inputs, _   = data\n                inputs      = inputs.to(device)\n\n                outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n                batch_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n                test_loss  += batch_loss.data\n\n            test_loss = test_loss\n            test_loss_arr.append(test_loss)\n\n            if best_test_loss   &gt; test_loss:\n                best_test_loss  = test_loss\n                early_stop      = 0\n\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f} *')\n            else:\n                early_stop += 1\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f}') \n\n        if early_stop &gt;= early_stop_max:\n            break\n\n\ntrain_autoencoder(autoencoder, criterion, optimizer, num_epochs=args.num_epoch)\n\ndata_iter       = iter(test_loader)\nimages, _       = next(data_iter)\nreconstructed   = autoencoder(images)\nvisualize_images(images, reconstructed.detach().numpy())"
  }
]