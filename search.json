[
  {
    "objectID": "posts/DAGMM/2023-10-15-arrhythmia.html",
    "href": "posts/DAGMM/2023-10-15-arrhythmia.html",
    "title": "[DAGMM] DAGMM implementation of arrhythmia data set",
    "section": "",
    "text": "import torch\nfrom torch import nn\nimport numpy as np\nimport pandas as pd\nimport argparse\nimport sys\n\n\n\n\n\nfile_path = 'C:\\\\Users\\\\UOS\\\\Desktop\\\\연구\\\\5. 데이터\\\\data\\\\arrhythmia\\\\arrhythmia.data'\n\ndf = pd.read_csv(file_path, header=None)\ndf = df.replace('?', 0)\ndf = df.astype('float64')\n\ndata_array = df.values\ndata_array = torch.autograd.Variable(torch.from_numpy(data_array).float())\ndata_array.shape\n\ntorch.Size([452, 280])\n\n\n\n\n\n\nparser = argparse.ArgumentParser(description='parser for argparse test')\n\nparser.add_argument('--input_dim', type=int, default=data_array.shape[-1])\nparser.add_argument('--enc_hidden_dim', type=str, default='10,2')\nparser.add_argument('--dec_hidden_dim', type=str, default='10')\nparser.add_argument('--est_hidden_dim', type=str, default='4, 10, 2')\nparser.add_argument('--dropout', action='store_true', default=0.5)\nparser.add_argument('--learning_rate', type=float, default=0.001)\nparser.add_argument('--num_epoch', type=int, default=10)\n\nif 'ipykernel_launcher' in sys.argv[0]:\n    sys.argv = [sys.argv[0]]  \n\nargs = parser.parse_args()\n\nenc_hidden_dim = args.enc_hidden_dim.split(',')\ndec_hidden_dim = args.dec_hidden_dim.split(',')\nest_hidden_dim = args.est_hidden_dim.split(',')\n\nargs.enc_hidden_dim_list = []\nargs.dec_hidden_dim_list = []\nargs.est_hidden_dim_list = []\n\nargs.enc_hidden_dim_list.append(args.input_dim)\n\nfor i in enc_hidden_dim:\n    args.enc_hidden_dim_list.append(int(i))\n\nargs.enc_hidden_dim_list\n\nargs.dec_hidden_dim_list.append(args.enc_hidden_dim_list[-1])\n\nfor i in dec_hidden_dim:\n    args.dec_hidden_dim_list.append(int(i))\n\nargs.dec_hidden_dim_list.append(args.input_dim)\n\nargs.dec_hidden_dim_list\n\nfor i in est_hidden_dim:\n    args.est_hidden_dim_list.append(int(i))\n\nargs.est_hidden_dim_list\n\nargs\n\nNamespace(input_dim=280, enc_hidden_dim='10,2', dec_hidden_dim='10', est_hidden_dim='4, 10, 2', dropout=0.5, learning_rate=0.001, num_epoch=10, enc_hidden_dim_list=[280, 10, 2], dec_hidden_dim_list=[2, 10, 280], est_hidden_dim_list=[4, 10, 2])\n\n\n\n\n\n- midlayer\n\nclass midlayer(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(midlayer, self).__init__()\n        self.fc_layer   = nn.Linear(input_dim, hidden_dim)\n        self.activation = nn.Tanh()\n    \n    def forward(self, input):\n        out = self.fc_layer(input)        \n        out = self.activation(out)\n        return out\n\n- Encoder of Autoencoder\n\nclass Encoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super(Encoder, self).__init__()\n        \n        layer_list = []\n        for i in range(len(hidden_dim_list)-2):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n        \n        layer_list.append(nn.Linear(hidden_dim_list[i+1], hidden_dim_list[i+2]))\n        self.layer = nn.Sequential(*layer_list)\n\n    def forward(self, input):\n        out = self.layer(input)\n        return out\n\n- Decoder of Autoencoder\n\nclass Decoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super(Decoder, self).__init__()\n\n        layer_list = []\n        for i in range(len(hidden_dim_list)-2):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n        \n        layer_list.append(midlayer(hidden_dim_list[i+1], hidden_dim_list[i+2]))\n        self.layer = nn.Sequential(*layer_list)\n    \n    def forward(self, input):\n        out = self.layer(input)\n        return out\n\n- CompressionNet(Autoencoder)\n\nclass CompressionNet(nn.Module):\n    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list):\n        super().__init__()\n        self.encoder = Encoder(enc_hidden_dim_list)\n        self.decoder = Decoder(dec_hidden_dim_list)\n\n        self._reconstruction_loss = nn.MSELoss()\n\n    def forward(self, input):\n        out = self.encoder(input)\n        out = self.decoder(out)\n        return out\n\n    def encode(self, input):\n        return self.encoder(input)\n\n    def decode(self, input):\n        return self.decoder(input)\n\n    def reconstuction_loss(self, input, input_target):\n        target_hat = self(input)\n        return self._reconstruction_loss(target_hat, input_target)\n\n\n\n\n\neps = torch.autograd.Variable(torch.FloatTensor([1.e-8]), requires_grad=False)\n\ndef relative_euclidean_distance(x1, x2, eps=eps):\n    num   = torch.norm(x1 - x2, p=2, dim=1)\n    denom = torch.norm(x1, p=2, dim=1)\n    return num / torch.max(denom, eps)\n\ndef cosine_similarity(x1, x2, eps=eps):\n    dot_prod = torch.sum(x1 * x2, dim=1)\n    dist_x1  = torch.norm(x1, p=2, dim=1)\n    dist_x2  = torch.norm(x2, p=2, dim=1)\n    return dot_prod / torch.max(dist_x1*dist_x2, eps)\n\n\n\n\n\nclass Estimation(nn.Module):\n    def __init__(self, est_hidden_dim_list):\n        super().__init__()\n        \n        layer_list = []\n        for i in range(len(est_hidden_dim_list)-2):\n            layer_list.append(midlayer(est_hidden_dim_list[i], est_hidden_dim_list[i+1]))\n        \n        layer_list.append(nn.Dropout(p=0.5))\n        layer_list.append(nn.Linear(est_hidden_dim_list[-2], est_hidden_dim_list[-1]))\n        layer_list.append(nn.Softmax())\n        self.net   = nn.Sequential(*layer_list)\n        \n    def forward(self, input):\n        out = self.net(input)\n        return out\n\n\n\n\n\nclass Mixture(nn.Module):\n    def __init__(self, latent_dimension):\n        super().__init__()\n        self.latent_dimension = latent_dimension\n\n        self.Phi    = np.random.random([1])\n        self.Phi    = torch.from_numpy(self.Phi).float()\n        self.Phi    = nn.Parameter(self.Phi, requires_grad = False)\n\n        self.mu     = 2.*np.random.random([latent_dimension]) - 0.5\n        self.mu     = torch.from_numpy(self.mu).float()\n        self.mu     = nn.Parameter(self.mu, requires_grad = False)\n\n        self.Sigma  = np.eye(latent_dimension, latent_dimension)\n        self.Sigma  = torch.from_numpy(self.Sigma).float()\n        self.Sigma  = nn.Parameter(self.Sigma, requires_grad = False)\n        \n        self.eps_Sigma  = torch.FloatTensor(np.diag([1.e-8 for _ in range(latent_dimension)]))\n\n    def forward(self, est_inputs, with_log = True):\n        batch_size, _   = est_inputs.shape\n        out_values  = []\n        inv_sigma   = torch.inverse(self.Sigma)\n        det_sigma   = np.linalg.det(self.Sigma.data.cpu().numpy())\n        det_sigma   = torch.from_numpy(det_sigma.reshape([1])).float()\n        det_sigma   = torch.autograd.Variable(det_sigma)\n        for est_input in est_inputs:\n            diff    = (est_input - self.mu).view(-1,1)\n            out     = -0.5 * torch.mm(torch.mm(diff.view(1,-1), inv_sigma), diff)\n            out     = (self.Phi * torch.exp(out)) / torch.sqrt(2. * np.pi * det_sigma)\n            if with_log:\n                out = -torch.log(out)\n            out_values.append(float(out.data.cpu().numpy()))\n\n        out = torch.autograd.Variable(torch.FloatTensor(out_values))\n        return out\n    \n    def _update_parameters(self, samples, affiliations):\n        if not self.training:\n            return\n\n        batch_size, _ = samples.shape\n\n        # Updating phi.\n        phi = torch.mean(affiliations)\n        self.Phi.data = phi.data\n\n        # Updating mu.\n        num = 0.\n        for i in range(batch_size):\n            z_i      = samples[i, :]\n            gamma_i  = affiliations[i]\n            num     += gamma_i * z_i\n        \n        denom        = torch.sum(affiliations)\n        self.mu.data = (num / denom).data\n\n        # Updating Sigma.\n        mu  = self.mu\n        num = None\n        for i in range(batch_size):\n            z_i      = samples[i, :]\n            gamma_i  = affiliations[i]\n            diff     = (z_i - mu).view(-1, 1)\n            to_add   = gamma_i * torch.mm(diff, diff.view(1, -1))\n            if num is None:\n                num  = to_add\n            else:\n                num += to_add\n\n        denom           = torch.sum(affiliations)\n        self.Sigma.data = (num / denom).data + self.eps_Sigma\n\n\n\n\n\nclass GMM(nn.Module):\n    def __init__(self, num_mixtures, latent_dimension):\n        super().__init__()\n        self.num_mixtures       = num_mixtures\n        self.latent_dimension   = latent_dimension\n\n        mixtures        = [Mixture(latent_dimension) for _ in range(num_mixtures)]\n        self.mixtures   = nn.ModuleList(mixtures)\n    \n    def forward(self, est_inputs):\n        out = None\n        for mixture in self.mixtures:\n            to_add   = mixture(est_inputs, with_log = False)\n            if out is None:\n                out  = to_add\n            else:\n                out += to_add\n        return -torch.log(out)\n    \n    def _update_mixtures_parameters(self, samples, mixtures_affiliations):\n        if not self.training:\n            return\n\n        for i, mixture in enumerate(self.mixtures):\n            affiliations = mixtures_affiliations[:, i]\n            mixture._update_parameters(samples, affiliations)\n\n\n\n\n\nclass DAGMM(nn.Module):\n    def __init__(self, compression_module, estimation_module, gmm_module):\n        super().__init__()\n\n        self.compressor = compression_module\n        self.estimator  = estimation_module\n        self.gmm        = gmm_module\n\n    def forward(self, input):\n        encoded = self.compressor.encode(input)\n        decoded = self.compressor.decode(encoded)\n\n        relative_ed     = relative_euclidean_distance(input, decoded)\n        cosine_sim      = cosine_similarity(input, decoded)\n\n        relative_ed     = relative_ed.view(-1, 1)\n        cosine_sim      = relative_ed.view(-1, 1)\n        latent_vectors  = torch.cat([encoded, relative_ed, cosine_sim], dim=1)\n\n        if self.training:\n            mixtures_affiliations = self.estimator(latent_vectors)\n            self.gmm._update_mixtures_parameters(latent_vectors,\n                                                 mixtures_affiliations)\n        return self.gmm(latent_vectors)\n\n- model for Arrhythmia\n\nclass DAGMMArrhythmia(DAGMM):\n    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list, est_hidden_dim_list):\n        compressor  = CompressionNet(enc_hidden_dim_list, dec_hidden_dim_list)\n        estimator   = Estimation(est_hidden_dim_list)\n        gmm = GMM(num_mixtures = est_hidden_dim_list[-1], latent_dimension = enc_hidden_dim_list[-1] + 2)\n\n        super().__init__(compression_module = compressor,\n                         estimation_module  = estimator,\n                         gmm_module         = gmm)\n\n\n\n\n\ndef test_dagmm():\n    net = DAGMMArrhythmia(args.enc_hidden_dim_list, args.dec_hidden_dim_list, args.est_hidden_dim_list)\n    out = net(data_array)\n    print(out)\n\ndef convert_to_var(input):\n    out = torch.from_numpy(input).float()\n    out = torch.autograd.Variable(out)\n    return out\n\ndef test_update_mixture():\n    batch_size       = 5\n    latent_dimension = 7\n    mix              = Mixture(latent_dimension)\n    latent_vectors   = np.random.random([batch_size, latent_dimension])\n    affiliations     = np.random.random([batch_size])\n    latent_vectors   = convert_to_var(latent_vectors)\n    affiliations     = convert_to_var(affiliations)\n\n    for param in mix.parameters():\n        print(param)\n\n    mix.train()\n    mix._update_parameters(latent_vectors, affiliations)\n\n    for param in mix.parameters():\n        print(param)\n\n\ndef test_forward_mixture():\n    batch_size       = 5\n    latent_dimension = 7\n\n    mix = Mixture(latent_dimension)\n    latent_vectors   = np.random.random([batch_size, latent_dimension])\n    latent_vectors   = convert_to_var(latent_vectors)\n\n    mix.train()\n    out = mix(latent_vectors)\n    print(out)\n\n\ndef test_update_gmm():\n    batch_size       = int(5)\n    latent_dimension = 7\n    num_mixtures     = 2\n\n    gmm = GMM(num_mixtures, latent_dimension)\n\n    latent_vectors   = np.random.random([batch_size, latent_dimension])\n    latent_vectors   = convert_to_var(latent_vectors)\n\n    affiliations     = np.random.random([batch_size, num_mixtures])\n    affiliations     = convert_to_var(affiliations)\n\n    for param in gmm.parameters():\n        print(param)\n\n    gmm.train()\n    gmm._update_mixtures_parameters(latent_vectors, affiliations)\n\n    for param in gmm.parameters():\n        print(param)\n\n\nif __name__ == '__main__':\n    test_update_mixture()\n    test_forward_mixture()\n    test_update_gmm()\n    test_dagmm()\n\nParameter containing:\ntensor([0.9576])\nParameter containing:\ntensor([ 0.0729,  0.1068,  0.8933,  1.0980, -0.1885, -0.0942,  0.3771])\nParameter containing:\ntensor([[1., 0., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 1.]])\nParameter containing:\ntensor(0.5896)\nParameter containing:\ntensor([0.5026, 0.6028, 0.5872, 0.6446, 0.6301, 0.6866, 0.6834])\nParameter containing:\ntensor([[ 1.1438e-01,  4.1086e-02, -5.4896e-02,  6.1599e-02,  8.4433e-03,\n         -7.2918e-02, -6.6051e-02],\n        [ 4.1086e-02,  7.3201e-02, -6.9920e-03,  3.5277e-02,  5.1846e-03,\n         -5.5505e-02,  1.7438e-02],\n        [-5.4896e-02, -6.9920e-03,  8.0962e-02, -3.9854e-02,  1.2237e-02,\n          1.4250e-02,  2.5344e-03],\n        [ 6.1599e-02,  3.5277e-02, -3.9854e-02,  4.2806e-02, -2.5848e-05,\n         -4.0940e-02, -1.7551e-02],\n        [ 8.4433e-03,  5.1846e-03,  1.2237e-02, -2.5848e-05,  5.8565e-03,\n         -1.1245e-02, -1.4709e-02],\n        [-7.2918e-02, -5.5505e-02,  1.4250e-02, -4.0940e-02, -1.1245e-02,\n          6.5657e-02,  3.1673e-02],\n        [-6.6051e-02,  1.7438e-02,  2.5344e-03, -1.7551e-02, -1.4709e-02,\n          3.1673e-02,  9.5430e-02]])\ntensor([3.7175, 3.4720, 3.4384, 3.0652, 3.4457])\nParameter containing:\ntensor([0.9034])\nParameter containing:\ntensor([-0.3605, -0.1176,  1.3556, -0.3859,  0.9030,  0.8069,  0.2024])\nParameter containing:\ntensor([[1., 0., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 1.]])\nParameter containing:\ntensor([0.4550])\nParameter containing:\ntensor([ 0.8168, -0.4637,  1.4420, -0.4631,  0.5999,  0.8220,  1.1639])\nParameter containing:\ntensor([[1., 0., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 1.]])\nParameter containing:\ntensor(0.5253)\nParameter containing:\ntensor([0.5270, 0.5890, 0.4218, 0.3146, 0.4978, 0.2771, 0.6570])\nParameter containing:\ntensor([[ 0.0574, -0.0433,  0.0199,  0.0127, -0.0141,  0.0074, -0.0554],\n        [-0.0433,  0.0869,  0.0376, -0.0164, -0.0323, -0.0164,  0.0525],\n        [ 0.0199,  0.0376,  0.0760,  0.0010, -0.0477, -0.0280,  0.0143],\n        [ 0.0127, -0.0164,  0.0010,  0.0049, -0.0007, -0.0031, -0.0091],\n        [-0.0141, -0.0323, -0.0477, -0.0007,  0.0504,  0.0192,  0.0022],\n        [ 0.0074, -0.0164, -0.0280, -0.0031,  0.0192,  0.0352, -0.0361],\n        [-0.0554,  0.0525,  0.0143, -0.0091,  0.0022, -0.0361,  0.0850]])\nParameter containing:\ntensor(0.3280)\nParameter containing:\ntensor([0.6238, 0.5541, 0.5052, 0.3334, 0.4436, 0.2682, 0.5876])\nParameter containing:\ntensor([[ 0.0560, -0.0267,  0.0388,  0.0133, -0.0355, -0.0087, -0.0443],\n        [-0.0267,  0.0643,  0.0377, -0.0114, -0.0253, -0.0140,  0.0395],\n        [ 0.0388,  0.0377,  0.1056,  0.0072, -0.0740, -0.0471,  0.0115],\n        [ 0.0133, -0.0114,  0.0072,  0.0047, -0.0062, -0.0059, -0.0075],\n        [-0.0355, -0.0253, -0.0740, -0.0062,  0.0638,  0.0299,  0.0080],\n        [-0.0087, -0.0140, -0.0471, -0.0059,  0.0299,  0.0384, -0.0274],\n        [-0.0443,  0.0395,  0.0115, -0.0075,  0.0080, -0.0274,  0.0703]])\ntensor([-19.5026, -19.1311, -15.4511, -19.7436, -17.4924, -13.6871, -19.1674,\n        -18.3117, -19.6546, -19.6115, -17.6791, -19.6145, -19.4324, -19.7339,\n        -19.7362, -18.5180, -19.2537, -19.7105, -19.4335, -18.2015, -18.9533,\n        -19.4472, -19.6290, -19.0085, -19.1265,  -9.4599, -19.7251, -19.1549,\n        -19.7356, -16.5076, -19.8239, -19.4926, -19.2655, -18.8533, -19.7347,\n        -19.3880, -18.7335, -19.3065, -19.1170, -16.9937, -19.0663, -19.6239,\n        -19.6500, -19.1579, -19.3029, -19.3814, -19.7336, -18.8124, -19.0777,\n        -18.8215, -19.1454, -19.7366, -19.3840, -19.1816, -19.7272, -18.9582,\n        -16.8062, -19.6826, -19.1869, -18.6895, -19.4682, -19.3119, -18.8285,\n        -19.5117, -17.0720, -19.7547, -19.7140, -19.6903, -19.6524, -18.7575,\n        -19.0982, -17.5131, -19.6465, -19.1622, -19.4159, -19.3752, -18.2179,\n        -19.2397, -18.9359, -19.6803, -18.6477, -19.3046, -19.7210, -19.4017,\n        -19.2959,  -9.8601, -19.6446, -19.6826, -10.5180, -16.7048, -19.6643,\n        -19.7117, -19.2369, -18.5596, -19.4586, -19.7307, -19.3842, -19.0825,\n        -16.6544, -16.7186, -19.2260, -19.0992, -10.2704, -19.1574, -19.1618,\n        -18.9176, -19.3279, -19.6681, -15.4541, -19.6822, -19.4135, -19.7001,\n        -19.2352, -14.4917, -19.7603, -18.3979, -18.5396, -19.0940, -19.7824,\n        -19.6034, -17.7673, -19.7196, -18.9724, -19.6424, -19.3523, -17.9666,\n        -19.1049, -19.7154, -19.3834, -19.7272, -18.7712, -19.1632, -19.7359,\n        -19.4223, -19.7391, -19.0849, -18.5695, -19.7043, -19.6978, -19.4092,\n        -19.7101,  -4.3304, -19.6312, -19.3987, -19.6237, -19.7214, -19.2987,\n        -18.6274, -19.6830, -19.6581, -19.4998, -19.2523, -19.3628, -19.6237,\n        -19.0074, -18.8759, -19.6159, -19.4210, -19.2049, -19.6161, -19.6752,\n        -19.2403, -18.2315, -19.3941, -19.5076, -19.0893, -18.9660, -19.5706,\n        -19.7320, -19.6533, -19.0225, -19.5621, -19.2321, -19.1876, -14.9579,\n        -18.9153, -19.6468, -19.6712, -19.3662, -16.0974, -19.4715, -19.3004,\n        -19.5661, -17.5087, -19.5868, -19.5471, -19.0763, -16.8535, -19.0262,\n        -15.5701, -18.4086, -19.5765, -18.4037, -15.6707, -19.5065, -19.7361,\n        -19.6369, -18.0475, -19.6807, -18.3490, -19.1606, -19.1579,  -6.3516,\n        -19.1366,  -9.2250, -18.7873, -19.7307,  -9.7964, -16.6339, -19.1340,\n        -18.0679, -19.6090, -19.7345, -17.4739, -19.6375, -18.9947, -19.3503,\n        -15.7222, -17.7943,  -4.5842, -19.7045, -19.3169, -19.7343, -15.0845,\n        -19.4411, -19.1588, -19.6566, -19.7094, -19.4590, -19.6005, -19.6999,\n        -19.0920, -19.1566, -19.7371, -19.7377, -16.8372, -19.4610, -19.4391,\n        -19.6991, -17.3714, -19.7116, -14.3030, -18.9355, -17.4655, -19.7178,\n        -19.2435, -19.5914, -18.8451, -18.6810, -19.0849, -17.7758, -19.4321,\n        -11.5096, -10.6011, -19.3260, -19.3973, -16.1421, -16.0987, -19.7205,\n        -17.8553, -16.9757, -19.1508, -18.7668, -19.6041, -19.6394, -19.7301,\n        -19.6291, -15.7672, -19.6565, -18.8211, -19.7301, -18.0546, -19.7374,\n        -19.1855, -19.5449, -19.4971, -18.9530, -18.5887, -19.7390, -19.6641,\n        -19.1398, -18.5924, -19.6828, -19.1322, -13.9965, -13.5888, -19.7380,\n        -19.4953, -18.7203, -18.9737, -19.7005, -18.5053, -19.2002, -19.1531,\n        -18.7043, -18.2418, -19.2523,  -2.2377, -19.2895, -19.5974, -14.6503,\n        -19.1526, -17.2831, -18.8560, -19.5058, -19.7265, -16.6380, -18.7745,\n        -17.6224, -19.7313, -18.8340, -18.8071, -17.1641, -19.7196, -19.7010,\n        -19.5848,  -5.3390, -19.7363, -19.7363, -15.1967, -19.4600, -19.7356,\n        -19.2811, -16.5067, -19.7275, -19.7067, -19.5172, -19.1857, -18.4997,\n        -19.4242, -19.0073, -19.6371, -17.3801, -19.7340, -19.7147, -18.6967,\n        -19.3666, -19.7239, -19.2901, -19.3499, -19.6405, -19.5876, -19.5438,\n        -17.8957, -19.0762, -19.2313, -19.2679, -19.1881, -15.2225, -19.7153,\n        -19.5997, -17.5994, -19.0846, -18.9562, -17.7410, -18.0002, -11.2037,\n        -19.5320, -19.7342, -10.0244, -19.2669, -17.4340, -19.1757, -19.1159,\n        -18.9787, -19.1271, -15.8403, -18.7626, -17.5634, -15.3350, -19.3837,\n        -19.4827, -19.6001, -18.6723, -19.5074, -19.5938, -17.7955, -19.7325,\n        -19.3777, -18.3361, -17.4740, -17.4209, -19.7343, -19.1707, -19.4328,\n        -18.4305, -19.3422, -19.4325, -13.3652, -15.7532, -19.5760, -19.2135,\n        -19.6947, -14.9608, -18.8463,  -9.9281, -19.5996, -18.6886, -11.2510,\n        -19.5269, -18.3625, -17.3355, -19.5176, -19.7038, -19.7382, -18.6627,\n        -19.6908, -19.2764, -17.8652, -19.1923, -19.2671, -19.4794, -19.7253,\n        -19.7203, -17.8132, -19.6679, -19.1041, -17.2302, -19.4307, -18.6271,\n         -4.5470, -18.3180, -19.4077, -19.7263,  -9.3689, -19.7181, -19.1405,\n        -15.7144, -19.2191, -19.3417, -15.6202, -19.6679, -19.7134, -12.3178,\n        -18.7627, -19.7387, -19.2627, -19.3750, -19.5145, -19.7211, -18.6665,\n        -19.1720, -19.0021, -19.5962, -19.5919, -19.1159, -18.9987, -19.2013,\n        -19.5948, -15.8153, -18.9237, -19.7405])\n\n\nC:\\Users\\UOS\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217: UserWarning:\n\nImplicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n\n\n\n- ref: (https://openreview.net/forum?id=BJJLHbb0-) (Zong et al. 2018)\n\n\n\nZong, Bo, Qi Song, Martin Renqiang Min, Wei Cheng, Cristian Lumezanu, Dae-ki Cho, and Haifeng Chen. 2018. “Deep Autoencoding Gaussian Mixture Model for Unsupervised Anomaly Detection.” In International Conference on Learning Representations. https://api.semanticscholar.org/CorpusID:51805340."
  },
  {
    "objectID": "posts/DAGMM/2023-10-15-arrhythmia.html#deep-autoencoding-gaussian-mixture-model-for-arrhythmia-dataset",
    "href": "posts/DAGMM/2023-10-15-arrhythmia.html#deep-autoencoding-gaussian-mixture-model-for-arrhythmia-dataset",
    "title": "[DAGMM] DAGMM implementation of arrhythmia data set",
    "section": "",
    "text": "import torch\nfrom torch import nn\nimport numpy as np\nimport pandas as pd\nimport argparse\nimport sys\n\n\n\n\n\nfile_path = 'C:\\\\Users\\\\UOS\\\\Desktop\\\\연구\\\\5. 데이터\\\\data\\\\arrhythmia\\\\arrhythmia.data'\n\ndf = pd.read_csv(file_path, header=None)\ndf = df.replace('?', 0)\ndf = df.astype('float64')\n\ndata_array = df.values\ndata_array = torch.autograd.Variable(torch.from_numpy(data_array).float())\ndata_array.shape\n\ntorch.Size([452, 280])\n\n\n\n\n\n\nparser = argparse.ArgumentParser(description='parser for argparse test')\n\nparser.add_argument('--input_dim', type=int, default=data_array.shape[-1])\nparser.add_argument('--enc_hidden_dim', type=str, default='10,2')\nparser.add_argument('--dec_hidden_dim', type=str, default='10')\nparser.add_argument('--est_hidden_dim', type=str, default='4, 10, 2')\nparser.add_argument('--dropout', action='store_true', default=0.5)\nparser.add_argument('--learning_rate', type=float, default=0.001)\nparser.add_argument('--num_epoch', type=int, default=10)\n\nif 'ipykernel_launcher' in sys.argv[0]:\n    sys.argv = [sys.argv[0]]  \n\nargs = parser.parse_args()\n\nenc_hidden_dim = args.enc_hidden_dim.split(',')\ndec_hidden_dim = args.dec_hidden_dim.split(',')\nest_hidden_dim = args.est_hidden_dim.split(',')\n\nargs.enc_hidden_dim_list = []\nargs.dec_hidden_dim_list = []\nargs.est_hidden_dim_list = []\n\nargs.enc_hidden_dim_list.append(args.input_dim)\n\nfor i in enc_hidden_dim:\n    args.enc_hidden_dim_list.append(int(i))\n\nargs.enc_hidden_dim_list\n\nargs.dec_hidden_dim_list.append(args.enc_hidden_dim_list[-1])\n\nfor i in dec_hidden_dim:\n    args.dec_hidden_dim_list.append(int(i))\n\nargs.dec_hidden_dim_list.append(args.input_dim)\n\nargs.dec_hidden_dim_list\n\nfor i in est_hidden_dim:\n    args.est_hidden_dim_list.append(int(i))\n\nargs.est_hidden_dim_list\n\nargs\n\nNamespace(input_dim=280, enc_hidden_dim='10,2', dec_hidden_dim='10', est_hidden_dim='4, 10, 2', dropout=0.5, learning_rate=0.001, num_epoch=10, enc_hidden_dim_list=[280, 10, 2], dec_hidden_dim_list=[2, 10, 280], est_hidden_dim_list=[4, 10, 2])\n\n\n\n\n\n- midlayer\n\nclass midlayer(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(midlayer, self).__init__()\n        self.fc_layer   = nn.Linear(input_dim, hidden_dim)\n        self.activation = nn.Tanh()\n    \n    def forward(self, input):\n        out = self.fc_layer(input)        \n        out = self.activation(out)\n        return out\n\n- Encoder of Autoencoder\n\nclass Encoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super(Encoder, self).__init__()\n        \n        layer_list = []\n        for i in range(len(hidden_dim_list)-2):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n        \n        layer_list.append(nn.Linear(hidden_dim_list[i+1], hidden_dim_list[i+2]))\n        self.layer = nn.Sequential(*layer_list)\n\n    def forward(self, input):\n        out = self.layer(input)\n        return out\n\n- Decoder of Autoencoder\n\nclass Decoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super(Decoder, self).__init__()\n\n        layer_list = []\n        for i in range(len(hidden_dim_list)-2):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n        \n        layer_list.append(midlayer(hidden_dim_list[i+1], hidden_dim_list[i+2]))\n        self.layer = nn.Sequential(*layer_list)\n    \n    def forward(self, input):\n        out = self.layer(input)\n        return out\n\n- CompressionNet(Autoencoder)\n\nclass CompressionNet(nn.Module):\n    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list):\n        super().__init__()\n        self.encoder = Encoder(enc_hidden_dim_list)\n        self.decoder = Decoder(dec_hidden_dim_list)\n\n        self._reconstruction_loss = nn.MSELoss()\n\n    def forward(self, input):\n        out = self.encoder(input)\n        out = self.decoder(out)\n        return out\n\n    def encode(self, input):\n        return self.encoder(input)\n\n    def decode(self, input):\n        return self.decoder(input)\n\n    def reconstuction_loss(self, input, input_target):\n        target_hat = self(input)\n        return self._reconstruction_loss(target_hat, input_target)\n\n\n\n\n\neps = torch.autograd.Variable(torch.FloatTensor([1.e-8]), requires_grad=False)\n\ndef relative_euclidean_distance(x1, x2, eps=eps):\n    num   = torch.norm(x1 - x2, p=2, dim=1)\n    denom = torch.norm(x1, p=2, dim=1)\n    return num / torch.max(denom, eps)\n\ndef cosine_similarity(x1, x2, eps=eps):\n    dot_prod = torch.sum(x1 * x2, dim=1)\n    dist_x1  = torch.norm(x1, p=2, dim=1)\n    dist_x2  = torch.norm(x2, p=2, dim=1)\n    return dot_prod / torch.max(dist_x1*dist_x2, eps)\n\n\n\n\n\nclass Estimation(nn.Module):\n    def __init__(self, est_hidden_dim_list):\n        super().__init__()\n        \n        layer_list = []\n        for i in range(len(est_hidden_dim_list)-2):\n            layer_list.append(midlayer(est_hidden_dim_list[i], est_hidden_dim_list[i+1]))\n        \n        layer_list.append(nn.Dropout(p=0.5))\n        layer_list.append(nn.Linear(est_hidden_dim_list[-2], est_hidden_dim_list[-1]))\n        layer_list.append(nn.Softmax())\n        self.net   = nn.Sequential(*layer_list)\n        \n    def forward(self, input):\n        out = self.net(input)\n        return out\n\n\n\n\n\nclass Mixture(nn.Module):\n    def __init__(self, latent_dimension):\n        super().__init__()\n        self.latent_dimension = latent_dimension\n\n        self.Phi    = np.random.random([1])\n        self.Phi    = torch.from_numpy(self.Phi).float()\n        self.Phi    = nn.Parameter(self.Phi, requires_grad = False)\n\n        self.mu     = 2.*np.random.random([latent_dimension]) - 0.5\n        self.mu     = torch.from_numpy(self.mu).float()\n        self.mu     = nn.Parameter(self.mu, requires_grad = False)\n\n        self.Sigma  = np.eye(latent_dimension, latent_dimension)\n        self.Sigma  = torch.from_numpy(self.Sigma).float()\n        self.Sigma  = nn.Parameter(self.Sigma, requires_grad = False)\n        \n        self.eps_Sigma  = torch.FloatTensor(np.diag([1.e-8 for _ in range(latent_dimension)]))\n\n    def forward(self, est_inputs, with_log = True):\n        batch_size, _   = est_inputs.shape\n        out_values  = []\n        inv_sigma   = torch.inverse(self.Sigma)\n        det_sigma   = np.linalg.det(self.Sigma.data.cpu().numpy())\n        det_sigma   = torch.from_numpy(det_sigma.reshape([1])).float()\n        det_sigma   = torch.autograd.Variable(det_sigma)\n        for est_input in est_inputs:\n            diff    = (est_input - self.mu).view(-1,1)\n            out     = -0.5 * torch.mm(torch.mm(diff.view(1,-1), inv_sigma), diff)\n            out     = (self.Phi * torch.exp(out)) / torch.sqrt(2. * np.pi * det_sigma)\n            if with_log:\n                out = -torch.log(out)\n            out_values.append(float(out.data.cpu().numpy()))\n\n        out = torch.autograd.Variable(torch.FloatTensor(out_values))\n        return out\n    \n    def _update_parameters(self, samples, affiliations):\n        if not self.training:\n            return\n\n        batch_size, _ = samples.shape\n\n        # Updating phi.\n        phi = torch.mean(affiliations)\n        self.Phi.data = phi.data\n\n        # Updating mu.\n        num = 0.\n        for i in range(batch_size):\n            z_i      = samples[i, :]\n            gamma_i  = affiliations[i]\n            num     += gamma_i * z_i\n        \n        denom        = torch.sum(affiliations)\n        self.mu.data = (num / denom).data\n\n        # Updating Sigma.\n        mu  = self.mu\n        num = None\n        for i in range(batch_size):\n            z_i      = samples[i, :]\n            gamma_i  = affiliations[i]\n            diff     = (z_i - mu).view(-1, 1)\n            to_add   = gamma_i * torch.mm(diff, diff.view(1, -1))\n            if num is None:\n                num  = to_add\n            else:\n                num += to_add\n\n        denom           = torch.sum(affiliations)\n        self.Sigma.data = (num / denom).data + self.eps_Sigma\n\n\n\n\n\nclass GMM(nn.Module):\n    def __init__(self, num_mixtures, latent_dimension):\n        super().__init__()\n        self.num_mixtures       = num_mixtures\n        self.latent_dimension   = latent_dimension\n\n        mixtures        = [Mixture(latent_dimension) for _ in range(num_mixtures)]\n        self.mixtures   = nn.ModuleList(mixtures)\n    \n    def forward(self, est_inputs):\n        out = None\n        for mixture in self.mixtures:\n            to_add   = mixture(est_inputs, with_log = False)\n            if out is None:\n                out  = to_add\n            else:\n                out += to_add\n        return -torch.log(out)\n    \n    def _update_mixtures_parameters(self, samples, mixtures_affiliations):\n        if not self.training:\n            return\n\n        for i, mixture in enumerate(self.mixtures):\n            affiliations = mixtures_affiliations[:, i]\n            mixture._update_parameters(samples, affiliations)\n\n\n\n\n\nclass DAGMM(nn.Module):\n    def __init__(self, compression_module, estimation_module, gmm_module):\n        super().__init__()\n\n        self.compressor = compression_module\n        self.estimator  = estimation_module\n        self.gmm        = gmm_module\n\n    def forward(self, input):\n        encoded = self.compressor.encode(input)\n        decoded = self.compressor.decode(encoded)\n\n        relative_ed     = relative_euclidean_distance(input, decoded)\n        cosine_sim      = cosine_similarity(input, decoded)\n\n        relative_ed     = relative_ed.view(-1, 1)\n        cosine_sim      = relative_ed.view(-1, 1)\n        latent_vectors  = torch.cat([encoded, relative_ed, cosine_sim], dim=1)\n\n        if self.training:\n            mixtures_affiliations = self.estimator(latent_vectors)\n            self.gmm._update_mixtures_parameters(latent_vectors,\n                                                 mixtures_affiliations)\n        return self.gmm(latent_vectors)\n\n- model for Arrhythmia\n\nclass DAGMMArrhythmia(DAGMM):\n    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list, est_hidden_dim_list):\n        compressor  = CompressionNet(enc_hidden_dim_list, dec_hidden_dim_list)\n        estimator   = Estimation(est_hidden_dim_list)\n        gmm = GMM(num_mixtures = est_hidden_dim_list[-1], latent_dimension = enc_hidden_dim_list[-1] + 2)\n\n        super().__init__(compression_module = compressor,\n                         estimation_module  = estimator,\n                         gmm_module         = gmm)\n\n\n\n\n\ndef test_dagmm():\n    net = DAGMMArrhythmia(args.enc_hidden_dim_list, args.dec_hidden_dim_list, args.est_hidden_dim_list)\n    out = net(data_array)\n    print(out)\n\ndef convert_to_var(input):\n    out = torch.from_numpy(input).float()\n    out = torch.autograd.Variable(out)\n    return out\n\ndef test_update_mixture():\n    batch_size       = 5\n    latent_dimension = 7\n    mix              = Mixture(latent_dimension)\n    latent_vectors   = np.random.random([batch_size, latent_dimension])\n    affiliations     = np.random.random([batch_size])\n    latent_vectors   = convert_to_var(latent_vectors)\n    affiliations     = convert_to_var(affiliations)\n\n    for param in mix.parameters():\n        print(param)\n\n    mix.train()\n    mix._update_parameters(latent_vectors, affiliations)\n\n    for param in mix.parameters():\n        print(param)\n\n\ndef test_forward_mixture():\n    batch_size       = 5\n    latent_dimension = 7\n\n    mix = Mixture(latent_dimension)\n    latent_vectors   = np.random.random([batch_size, latent_dimension])\n    latent_vectors   = convert_to_var(latent_vectors)\n\n    mix.train()\n    out = mix(latent_vectors)\n    print(out)\n\n\ndef test_update_gmm():\n    batch_size       = int(5)\n    latent_dimension = 7\n    num_mixtures     = 2\n\n    gmm = GMM(num_mixtures, latent_dimension)\n\n    latent_vectors   = np.random.random([batch_size, latent_dimension])\n    latent_vectors   = convert_to_var(latent_vectors)\n\n    affiliations     = np.random.random([batch_size, num_mixtures])\n    affiliations     = convert_to_var(affiliations)\n\n    for param in gmm.parameters():\n        print(param)\n\n    gmm.train()\n    gmm._update_mixtures_parameters(latent_vectors, affiliations)\n\n    for param in gmm.parameters():\n        print(param)\n\n\nif __name__ == '__main__':\n    test_update_mixture()\n    test_forward_mixture()\n    test_update_gmm()\n    test_dagmm()\n\nParameter containing:\ntensor([0.9576])\nParameter containing:\ntensor([ 0.0729,  0.1068,  0.8933,  1.0980, -0.1885, -0.0942,  0.3771])\nParameter containing:\ntensor([[1., 0., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 1.]])\nParameter containing:\ntensor(0.5896)\nParameter containing:\ntensor([0.5026, 0.6028, 0.5872, 0.6446, 0.6301, 0.6866, 0.6834])\nParameter containing:\ntensor([[ 1.1438e-01,  4.1086e-02, -5.4896e-02,  6.1599e-02,  8.4433e-03,\n         -7.2918e-02, -6.6051e-02],\n        [ 4.1086e-02,  7.3201e-02, -6.9920e-03,  3.5277e-02,  5.1846e-03,\n         -5.5505e-02,  1.7438e-02],\n        [-5.4896e-02, -6.9920e-03,  8.0962e-02, -3.9854e-02,  1.2237e-02,\n          1.4250e-02,  2.5344e-03],\n        [ 6.1599e-02,  3.5277e-02, -3.9854e-02,  4.2806e-02, -2.5848e-05,\n         -4.0940e-02, -1.7551e-02],\n        [ 8.4433e-03,  5.1846e-03,  1.2237e-02, -2.5848e-05,  5.8565e-03,\n         -1.1245e-02, -1.4709e-02],\n        [-7.2918e-02, -5.5505e-02,  1.4250e-02, -4.0940e-02, -1.1245e-02,\n          6.5657e-02,  3.1673e-02],\n        [-6.6051e-02,  1.7438e-02,  2.5344e-03, -1.7551e-02, -1.4709e-02,\n          3.1673e-02,  9.5430e-02]])\ntensor([3.7175, 3.4720, 3.4384, 3.0652, 3.4457])\nParameter containing:\ntensor([0.9034])\nParameter containing:\ntensor([-0.3605, -0.1176,  1.3556, -0.3859,  0.9030,  0.8069,  0.2024])\nParameter containing:\ntensor([[1., 0., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 1.]])\nParameter containing:\ntensor([0.4550])\nParameter containing:\ntensor([ 0.8168, -0.4637,  1.4420, -0.4631,  0.5999,  0.8220,  1.1639])\nParameter containing:\ntensor([[1., 0., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 1.]])\nParameter containing:\ntensor(0.5253)\nParameter containing:\ntensor([0.5270, 0.5890, 0.4218, 0.3146, 0.4978, 0.2771, 0.6570])\nParameter containing:\ntensor([[ 0.0574, -0.0433,  0.0199,  0.0127, -0.0141,  0.0074, -0.0554],\n        [-0.0433,  0.0869,  0.0376, -0.0164, -0.0323, -0.0164,  0.0525],\n        [ 0.0199,  0.0376,  0.0760,  0.0010, -0.0477, -0.0280,  0.0143],\n        [ 0.0127, -0.0164,  0.0010,  0.0049, -0.0007, -0.0031, -0.0091],\n        [-0.0141, -0.0323, -0.0477, -0.0007,  0.0504,  0.0192,  0.0022],\n        [ 0.0074, -0.0164, -0.0280, -0.0031,  0.0192,  0.0352, -0.0361],\n        [-0.0554,  0.0525,  0.0143, -0.0091,  0.0022, -0.0361,  0.0850]])\nParameter containing:\ntensor(0.3280)\nParameter containing:\ntensor([0.6238, 0.5541, 0.5052, 0.3334, 0.4436, 0.2682, 0.5876])\nParameter containing:\ntensor([[ 0.0560, -0.0267,  0.0388,  0.0133, -0.0355, -0.0087, -0.0443],\n        [-0.0267,  0.0643,  0.0377, -0.0114, -0.0253, -0.0140,  0.0395],\n        [ 0.0388,  0.0377,  0.1056,  0.0072, -0.0740, -0.0471,  0.0115],\n        [ 0.0133, -0.0114,  0.0072,  0.0047, -0.0062, -0.0059, -0.0075],\n        [-0.0355, -0.0253, -0.0740, -0.0062,  0.0638,  0.0299,  0.0080],\n        [-0.0087, -0.0140, -0.0471, -0.0059,  0.0299,  0.0384, -0.0274],\n        [-0.0443,  0.0395,  0.0115, -0.0075,  0.0080, -0.0274,  0.0703]])\ntensor([-19.5026, -19.1311, -15.4511, -19.7436, -17.4924, -13.6871, -19.1674,\n        -18.3117, -19.6546, -19.6115, -17.6791, -19.6145, -19.4324, -19.7339,\n        -19.7362, -18.5180, -19.2537, -19.7105, -19.4335, -18.2015, -18.9533,\n        -19.4472, -19.6290, -19.0085, -19.1265,  -9.4599, -19.7251, -19.1549,\n        -19.7356, -16.5076, -19.8239, -19.4926, -19.2655, -18.8533, -19.7347,\n        -19.3880, -18.7335, -19.3065, -19.1170, -16.9937, -19.0663, -19.6239,\n        -19.6500, -19.1579, -19.3029, -19.3814, -19.7336, -18.8124, -19.0777,\n        -18.8215, -19.1454, -19.7366, -19.3840, -19.1816, -19.7272, -18.9582,\n        -16.8062, -19.6826, -19.1869, -18.6895, -19.4682, -19.3119, -18.8285,\n        -19.5117, -17.0720, -19.7547, -19.7140, -19.6903, -19.6524, -18.7575,\n        -19.0982, -17.5131, -19.6465, -19.1622, -19.4159, -19.3752, -18.2179,\n        -19.2397, -18.9359, -19.6803, -18.6477, -19.3046, -19.7210, -19.4017,\n        -19.2959,  -9.8601, -19.6446, -19.6826, -10.5180, -16.7048, -19.6643,\n        -19.7117, -19.2369, -18.5596, -19.4586, -19.7307, -19.3842, -19.0825,\n        -16.6544, -16.7186, -19.2260, -19.0992, -10.2704, -19.1574, -19.1618,\n        -18.9176, -19.3279, -19.6681, -15.4541, -19.6822, -19.4135, -19.7001,\n        -19.2352, -14.4917, -19.7603, -18.3979, -18.5396, -19.0940, -19.7824,\n        -19.6034, -17.7673, -19.7196, -18.9724, -19.6424, -19.3523, -17.9666,\n        -19.1049, -19.7154, -19.3834, -19.7272, -18.7712, -19.1632, -19.7359,\n        -19.4223, -19.7391, -19.0849, -18.5695, -19.7043, -19.6978, -19.4092,\n        -19.7101,  -4.3304, -19.6312, -19.3987, -19.6237, -19.7214, -19.2987,\n        -18.6274, -19.6830, -19.6581, -19.4998, -19.2523, -19.3628, -19.6237,\n        -19.0074, -18.8759, -19.6159, -19.4210, -19.2049, -19.6161, -19.6752,\n        -19.2403, -18.2315, -19.3941, -19.5076, -19.0893, -18.9660, -19.5706,\n        -19.7320, -19.6533, -19.0225, -19.5621, -19.2321, -19.1876, -14.9579,\n        -18.9153, -19.6468, -19.6712, -19.3662, -16.0974, -19.4715, -19.3004,\n        -19.5661, -17.5087, -19.5868, -19.5471, -19.0763, -16.8535, -19.0262,\n        -15.5701, -18.4086, -19.5765, -18.4037, -15.6707, -19.5065, -19.7361,\n        -19.6369, -18.0475, -19.6807, -18.3490, -19.1606, -19.1579,  -6.3516,\n        -19.1366,  -9.2250, -18.7873, -19.7307,  -9.7964, -16.6339, -19.1340,\n        -18.0679, -19.6090, -19.7345, -17.4739, -19.6375, -18.9947, -19.3503,\n        -15.7222, -17.7943,  -4.5842, -19.7045, -19.3169, -19.7343, -15.0845,\n        -19.4411, -19.1588, -19.6566, -19.7094, -19.4590, -19.6005, -19.6999,\n        -19.0920, -19.1566, -19.7371, -19.7377, -16.8372, -19.4610, -19.4391,\n        -19.6991, -17.3714, -19.7116, -14.3030, -18.9355, -17.4655, -19.7178,\n        -19.2435, -19.5914, -18.8451, -18.6810, -19.0849, -17.7758, -19.4321,\n        -11.5096, -10.6011, -19.3260, -19.3973, -16.1421, -16.0987, -19.7205,\n        -17.8553, -16.9757, -19.1508, -18.7668, -19.6041, -19.6394, -19.7301,\n        -19.6291, -15.7672, -19.6565, -18.8211, -19.7301, -18.0546, -19.7374,\n        -19.1855, -19.5449, -19.4971, -18.9530, -18.5887, -19.7390, -19.6641,\n        -19.1398, -18.5924, -19.6828, -19.1322, -13.9965, -13.5888, -19.7380,\n        -19.4953, -18.7203, -18.9737, -19.7005, -18.5053, -19.2002, -19.1531,\n        -18.7043, -18.2418, -19.2523,  -2.2377, -19.2895, -19.5974, -14.6503,\n        -19.1526, -17.2831, -18.8560, -19.5058, -19.7265, -16.6380, -18.7745,\n        -17.6224, -19.7313, -18.8340, -18.8071, -17.1641, -19.7196, -19.7010,\n        -19.5848,  -5.3390, -19.7363, -19.7363, -15.1967, -19.4600, -19.7356,\n        -19.2811, -16.5067, -19.7275, -19.7067, -19.5172, -19.1857, -18.4997,\n        -19.4242, -19.0073, -19.6371, -17.3801, -19.7340, -19.7147, -18.6967,\n        -19.3666, -19.7239, -19.2901, -19.3499, -19.6405, -19.5876, -19.5438,\n        -17.8957, -19.0762, -19.2313, -19.2679, -19.1881, -15.2225, -19.7153,\n        -19.5997, -17.5994, -19.0846, -18.9562, -17.7410, -18.0002, -11.2037,\n        -19.5320, -19.7342, -10.0244, -19.2669, -17.4340, -19.1757, -19.1159,\n        -18.9787, -19.1271, -15.8403, -18.7626, -17.5634, -15.3350, -19.3837,\n        -19.4827, -19.6001, -18.6723, -19.5074, -19.5938, -17.7955, -19.7325,\n        -19.3777, -18.3361, -17.4740, -17.4209, -19.7343, -19.1707, -19.4328,\n        -18.4305, -19.3422, -19.4325, -13.3652, -15.7532, -19.5760, -19.2135,\n        -19.6947, -14.9608, -18.8463,  -9.9281, -19.5996, -18.6886, -11.2510,\n        -19.5269, -18.3625, -17.3355, -19.5176, -19.7038, -19.7382, -18.6627,\n        -19.6908, -19.2764, -17.8652, -19.1923, -19.2671, -19.4794, -19.7253,\n        -19.7203, -17.8132, -19.6679, -19.1041, -17.2302, -19.4307, -18.6271,\n         -4.5470, -18.3180, -19.4077, -19.7263,  -9.3689, -19.7181, -19.1405,\n        -15.7144, -19.2191, -19.3417, -15.6202, -19.6679, -19.7134, -12.3178,\n        -18.7627, -19.7387, -19.2627, -19.3750, -19.5145, -19.7211, -18.6665,\n        -19.1720, -19.0021, -19.5962, -19.5919, -19.1159, -18.9987, -19.2013,\n        -19.5948, -15.8153, -18.9237, -19.7405])\n\n\nC:\\Users\\UOS\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217: UserWarning:\n\nImplicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n\n\n\n- ref: (https://openreview.net/forum?id=BJJLHbb0-) (Zong et al. 2018)\n\n\n\nZong, Bo, Qi Song, Martin Renqiang Min, Wei Cheng, Cristian Lumezanu, Dae-ki Cho, and Haifeng Chen. 2018. “Deep Autoencoding Gaussian Mixture Model for Unsupervised Anomaly Detection.” In International Conference on Learning Representations. https://api.semanticscholar.org/CorpusID:51805340."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "irumae",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nOct 19, 2023\n\n\n[DAGMM] DAGMM implementation of arrhythmia data set\n\n\nkione kim\n\n\n\n\nOct 6, 2023\n\n\n[Autoencoder] Autoencoder implementation of MNIST data set\n\n\nkione kim\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog\nThis blog was created for my personal research, study.\n\nTip\n\npreview: To render and preview, execute the Quarto: Render command. You can alternatively use the Ctrl+Shift+K keyboard shortcut, or the Render button at the top right of the editor\nupload: To upload posts on a blog, enter “quarto publish gh-pages” in the terminal."
  },
  {
    "objectID": "posts/Autoencoder/2023-10-11-autoencoder.html",
    "href": "posts/Autoencoder/2023-10-11-autoencoder.html",
    "title": "[Autoencoder] Autoencoder implementation of MNIST data set",
    "section": "",
    "text": "- imports\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport argparse\nimport sys\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torchinfo import summary\nfrom mpl_toolkits.mplot3d import Axes3D\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\n- data set\n\ndata_root = './data'\n\nbatch_size = 32\n\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(0.5, 0.5),\n    transforms.Lambda(lambda x: x.view(-1)),\n])\n\ntrainset = datasets.MNIST(\n    root        = data_root, \n    train       = True, \n    download    = True,\n    transform   = transform\n)\n\ntestset = datasets.MNIST(\n    root        = data_root, \n    train       = False, \n    download    = False,\n    transform   = transform\n)\n\ntrain_loader = torch.utils.data.DataLoader(\n    dataset     = trainset,\n    batch_size  = batch_size,\n    shuffle     = True\n)\n\ntest_loader = torch.utils.data.DataLoader(\n    dataset     = testset,\n    batch_size  = batch_size,\n    shuffle     = False\n)\n\n- argparse\n\nparser = argparse.ArgumentParser(description='parser for argparse test')\n\nparser.add_argument('--input_dim', type=int, default=28*28)\nparser.add_argument('--learning_rate', type=float, default=0.001)\nparser.add_argument('--num_epoch', type=int, default=10)\nparser.add_argument('--enc_hidden_dim', type=str, default='256,128,64,32,3')\nparser.add_argument('--dec_hidden_dim', type=str, default='32,64,128,256')\n\n\nif 'ipykernel_launcher' in sys.argv[0]:\n    sys.argv = [sys.argv[0]]\n\nargs = parser.parse_args()\n\nenc_hidden_dim = args.enc_hidden_dim.split(',')\ndec_hidden_dim = args.dec_hidden_dim.split(',')\nargs.enc_hidden_dim_list = []\nargs.dec_hidden_dim_list = []\n\nargs.enc_hidden_dim_list.append(args.input_dim)\n\nfor i in enc_hidden_dim:\n    args.enc_hidden_dim_list.append(int(i))\n\nargs.enc_hidden_dim_list\n\nargs.dec_hidden_dim_list.append(args.enc_hidden_dim_list[-1])\n\nfor i in dec_hidden_dim:\n    args.dec_hidden_dim_list.append(int(i))\n\nargs.dec_hidden_dim_list.append(args.input_dim)\n\nargs.dec_hidden_dim_list\n\nargs\n\n- model\n\nclass midlayer(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(midlayer, self).__init__()\n        self.fc_layer   = nn.Linear(input_dim, hidden_dim)\n        self.activation = nn.LeakyReLU()\n    \n    def forward(self, x):\n        out = self.fc_layer(x)\n        out = self.activation(out)\n        return out\n\n\nclass Encoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super(Encoder, self).__init__()\n        \n        layer_list = []\n        for i in range(len(hidden_dim_list)-1):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n        \n        self.fc_layer = nn.Sequential(*layer_list)\n        \n    def forward(self, x):\n        out = self.fc_layer(x)\n\n        return out\n\n\nclass Decoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super().__init__()\n        \n        layer_list = []\n        for i in range(len(hidden_dim_list)-2):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n        \n        layer_list.append(nn.Sequential(nn.Linear(hidden_dim_list[i+1], hidden_dim_list[i+2]), nn.Sigmoid()))\n        self.fc_layer = nn.Sequential(*layer_list)\n    \n    def forward(self, x):\n        out = self.fc_layer(x)\n\n        return out\n\n\nclass Autoencoder(nn.Module):\n    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list):\n        super().__init__()\n\n        self.encoder = Encoder(enc_hidden_dim_list)\n        self.decoder = Decoder(dec_hidden_dim_list)\n\n    def forward(self, x):\n        out = self.encoder(x)\n        out = self.decoder(out)\n\n        return out\n\n\nautoencoder = Autoencoder(args.enc_hidden_dim_list, args.dec_hidden_dim_list)\nautoencoder = autoencoder.to(device)\n\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n\n- train & visualization function\n\ndef train_autoencoder(autoencoder, criterion, optimizer, num_epochs):\n    train_loss_arr  = []\n    test_loss_arr   = []\n\n    best_test_loss  = 99999999\n    early_stop, early_stop_max = 0., 3.\n    for epoch in range(num_epochs):\n        autoencoder.train()\n        epoch_loss  = 0.\n        for data in train_loader:\n            inputs, _   = data\n            inputs      = inputs.to(device)\n            optimizer.zero_grad()\n            outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n            train_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n            epoch_loss += train_loss.data\n            train_loss.backward()\n            optimizer.step()\n\n        train_loss_arr.append(epoch_loss / len(train_loader.dataset))\n        \n        if epoch != 99:\n            autoencoder.eval()\n\n            test_loss   = 0.\n\n            for data in test_loader:\n                inputs, _   = data\n                inputs      = inputs.to(device)\n\n                outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n                batch_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n                test_loss  += batch_loss.data\n\n            test_loss   = test_loss\n            test_loss_arr.append(test_loss)\n\n            if best_test_loss   &gt; test_loss:\n                best_test_loss  = test_loss\n                early_stop      = 0\n\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f} *')\n            else:\n                early_stop      += 1\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f}') \n\n        if early_stop   &gt;= early_stop_max:\n            break\n\ndef visualize_images(original, reconstructed, n=10):\n    plt.figure(figsize=(20, 4))\n    for i in range(n):\n        ax = plt.subplot(2, n, i + 1)\n        plt.imshow(original[i].reshape(28, 28), cmap='gray')\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n\n        ax = plt.subplot(2, n, i + 1 + n)\n        plt.imshow(reconstructed[i].reshape(28, 28), cmap='gray')\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n    plt.show()\n\n- train & visualization\n\ntrain_autoencoder(autoencoder, criterion, optimizer, num_epochs=args.num_epoch)\n\ndata_iter = iter(test_loader)\nimages, _ = next(data_iter)\nreconstructed = autoencoder(images)\nvisualize_images(images, reconstructed.detach().numpy())\n\n\n\n\n\nparser = argparse.ArgumentParser(description='parser for argparse test')\n\nparser.add_argument('--input_dim', type=int, default=28*28)\nparser.add_argument('--enc_hidden_dim', type=str, default='128,32')\nparser.add_argument('--dec_hidden_dim', type=str, default='128')\nparser.add_argument('--lr_rate', type=float, default=0.001)\nparser.add_argument('--num_epoch', type=int, default=10)\n\nif 'ipykernel_launcher' in sys.argv[0]:\n    sys.argv = [sys.argv[0]]  \n\nargs = parser.parse_args()\n\nenc_hidden_dim = args.enc_hidden_dim.split(',')\ndec_hidden_dim = args.dec_hidden_dim.split(',')\n\nargs.enc_hidden_dim_list = []\nargs.dec_hidden_dim_list = []\n\nargs.enc_hidden_dim_list.append(args.input_dim)\n\nfor i in enc_hidden_dim:\n    args.enc_hidden_dim_list.append(int(i))\n\nargs.dec_hidden_dim_list.append(args.enc_hidden_dim_list[-1])\n\nfor i in dec_hidden_dim:\n    args.dec_hidden_dim_list.append(int(i))\n\nargs.dec_hidden_dim_list.append(args.input_dim)\n\nargs\n\n\nclass midlayer(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(midlayer, self).__init__()\n        self.fc_layer   = nn.Linear(input_dim, hidden_dim)\n        self.activation = nn.LeakyReLU()\n   \n    def forward(self, x):\n        out = self.fc_layer(x)\n        out = self.activation(out)\n        return out\n\n\nclass Encoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super(Encoder, self).__init__()\n       \n        layer_list      = []\n        for i in range(len(hidden_dim_list)-1):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n        \n        self.fc_layer   = nn.Sequential(*layer_list)\n        \n    def forward(self, x):\n        out = self.fc_layer(x)\n        return out\n\n\nclass Decoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super().__init__()\n        \n        layer_list = []\n        for i in range(len(hidden_dim_list)-2):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n    \n        layer_list.append(nn.Sequential(nn.Linear(hidden_dim_list[i+1], hidden_dim_list[i+2])))\n        self.fc_layer = nn.Sequential(*layer_list)\n    \n    def forward(self, x):\n        out = self.fc_layer(x)\n        return out\n\n\nclass Autoencoder(nn.Module):\n    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list):\n        super().__init__()\n        self.encoder = Encoder(enc_hidden_dim_list)\n        self.decoder = Decoder(dec_hidden_dim_list)\n\n    def forward(self, x):\n        out = self.encoder(x)\n        out = self.decoder(out)\n        return out\n\n\nautoencoder = Autoencoder(args.enc_hidden_dim_list, args.dec_hidden_dim_list)\nautoencoder = autoencoder.to(device)\n\ncriterion = nn.MSELoss() \noptimizer = optim.Adam(autoencoder.parameters(), lr=args.lr_rate)\n\n\ndef train_autoencoder(autoencoder, criterion, optimizer, num_epochs):\n    train_loss_arr  = []\n    test_loss_arr   = []\n\n    best_test_loss  = 99999999\n    early_stop, early_stop_max = 0., 3.\n    for epoch in range(num_epochs):\n        autoencoder.train()\n        epoch_loss  = 0.\n        for data in train_loader:\n            inputs, _   = data\n            inputs      = inputs.to(device)\n            optimizer.zero_grad()\n            outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n            train_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n            epoch_loss += train_loss.data\n            train_loss.backward()\n            optimizer.step()\n\n        train_loss_arr.append(epoch_loss / len(train_loader.dataset))\n        \n        if epoch != -1:\n            autoencoder.eval()\n\n            test_loss = 0.\n\n            for data in test_loader:\n                inputs, _   = data\n                inputs      = inputs.to(device)\n\n                outputs = autoencoder(inputs.view(inputs.size(0), -1))\n                batch_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n                test_loss  += batch_loss.data\n\n            test_loss = test_loss\n            test_loss_arr.append(test_loss)\n\n            if best_test_loss   &gt; test_loss:\n                best_test_loss  = test_loss\n                early_stop      = 0\n\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f} *')\n            else:\n                early_stop += 1\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f}') \n\n        if early_stop &gt;= early_stop_max:\n            break\n\n\ntrain_autoencoder(autoencoder, criterion, optimizer, num_epochs=args.num_epoch)\n\ndata_iter       = iter(test_loader)\nimages, _       = next(data_iter)\nreconstructed   = autoencoder(images)\nvisualize_images(images, reconstructed.detach().numpy())\n\n\n\n\n\nparser = argparse.ArgumentParser(description='parser for argparse test')\n\nparser.add_argument('--enc_hidden_dim', type=str, default='784,128,32')\nparser.add_argument('--dec_hidden_dim', type=str, default='128,784')\nparser.add_argument('--lr_rate', type=float, default=0.001)\nparser.add_argument('--num_epoch', type=int, default=10)\n\nif 'ipykernel_launcher' in sys.argv[0]:\n    sys.argv = [sys.argv[0]]  \n\nargs = parser.parse_args()\n\nenc_hidden_dim = args.enc_hidden_dim.split(',')\ndec_hidden_dim = args.dec_hidden_dim.split(',')\n\nargs.enc_hidden_dim_list = []\nargs.dec_hidden_dim_list = []\n\nfor i in enc_hidden_dim:\n    args.enc_hidden_dim_list.append(int(i))\n\nargs.enc_hidden_dim_list\n\nargs.dec_hidden_dim_list.append(args.enc_hidden_dim_list[-1])\n\nfor i in dec_hidden_dim:\n    args.dec_hidden_dim_list.append(int(i))\n\nargs.dec_hidden_dim_list\n\nargs\n\n\nclass midlayer(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(midlayer, self).__init__()\n        self.fc_layer   = nn.Linear(input_dim, hidden_dim)\n        self.activation = nn.LeakyReLU()\n   \n    def forward(self, x):\n        out = self.fc_layer(x)\n        out = self.activation(out)\n        return out\n\n\nclass Encoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super(Encoder, self).__init__()\n       \n        layer_list      = []\n        for i in range(len(hidden_dim_list)-1):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n        \n        self.fc_layer   = nn.Sequential(*layer_list)\n        \n    def forward(self, x):\n        out = self.fc_layer(x)\n        return out\n\n\nclass Decoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super().__init__()\n        \n        layer_list      = []\n        for i in range(len(hidden_dim_list)-2):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n    \n        layer_list.append(nn.Sequential(nn.Linear(hidden_dim_list[i+1], hidden_dim_list[i+2])))\n        self.fc_layer   = nn.Sequential(*layer_list)\n    \n    def forward(self, x):\n        out = self.fc_layer(x)\n        return out\n\n\nclass Autoencoder(nn.Module):\n    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list):\n        super().__init__()\n        self.encoder = Encoder(enc_hidden_dim_list)\n        self.decoder = Decoder(dec_hidden_dim_list)\n\n    def forward(self, x):\n        out = self.encoder(x)\n        out = self.decoder(out)\n        return out\n\n\nautoencoder = Autoencoder(args.enc_hidden_dim_list, args.dec_hidden_dim_list)\nautoencoder = autoencoder.to(device)\n\ncriterion = nn.MSELoss() \noptimizer = optim.Adam(autoencoder.parameters(), lr=args.lr_rate)\n\n\ndef train_autoencoder(autoencoder, criterion, optimizer, num_epochs):\n    train_loss_arr  = []\n    test_loss_arr   = []\n\n    best_test_loss  = 99999999\n    early_stop, early_stop_max = 0., 3.\n    for epoch in range(num_epochs):\n        autoencoder.train()\n        epoch_loss  = 0.\n        for data in train_loader:\n            inputs, _   = data\n            inputs      = inputs.to(device)\n            optimizer.zero_grad()\n            outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n            train_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n            epoch_loss += train_loss.data\n            train_loss.backward()\n            optimizer.step()\n\n        train_loss_arr.append(epoch_loss / len(train_loader.dataset))\n        \n        if epoch != -1:\n            autoencoder.eval()\n\n            test_loss = 0.\n\n            for data in test_loader:\n                inputs, _   = data\n                inputs      = inputs.to(device)\n\n                outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n                batch_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n                test_loss  += batch_loss.data\n\n            test_loss = test_loss\n            test_loss_arr.append(test_loss)\n\n            if best_test_loss   &gt; test_loss:\n                best_test_loss  = test_loss\n                early_stop      = 0\n\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f} *')\n            else:\n                early_stop += 1\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f}') \n\n        if early_stop &gt;= early_stop_max:\n            break\n\n\ntrain_autoencoder(autoencoder, criterion, optimizer, num_epochs=args.num_epoch)\n\ndata_iter       = iter(test_loader)\nimages, _       = next(data_iter)\nreconstructed   = autoencoder(images)\nvisualize_images(images, reconstructed.detach().numpy())\n\n\n\n\n\narser = argparse.ArgumentParser(description='parser for argparse test')\n\nparser.add_argument('--enc_hidden_dim', type=str, default='784,128,32')\nparser.add_argument('--lr_rate', type=float, default=0.001)\nparser.add_argument('--num_epoch', type=int, default=10)\n\nif 'ipykernel_launcher' in sys.argv[0]:\n    sys.argv = [sys.argv[0]]  \n\nargs = parser.parse_args()\n\nenc_hidden_dim = args.enc_hidden_dim.split(',') ### key point\ndec_hidden_dim = args.enc_hidden_dim.split(',')\n\nargs.enc_hidden_dim_list = []\nargs.dec_hidden_dim_list = []\n\nfor i in enc_hidden_dim:\n    args.enc_hidden_dim_list.append(int(i))\n\nargs.enc_hidden_dim_list\n\nfor i in enc_hidden_dim[::-1]:\n    args.dec_hidden_dim_list.append(int(i))\n\nargs.dec_hidden_dim_list\n\nargs\n\n\nclass midlayer(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(midlayer, self).__init__()\n        self.fc_layer   = nn.Linear(input_dim, hidden_dim)\n        self.activation = nn.LeakyReLU()\n   \n    def forward(self, x):\n        out = self.fc_layer(x)\n        out = self.activation(out)\n        return out\n\nclass Encoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super(Encoder, self).__init__()\n       \n        layer_list      = []\n        for i in range(len(hidden_dim_list)-1):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n        \n        self.fc_layer   = nn.Sequential(*layer_list)\n        \n    def forward(self, x):\n        out = self.fc_layer(x)\n        return out\n\nclass Decoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super().__init__()\n        \n        layer_list      = []\n        for i in range(len(hidden_dim_list)-2):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n    \n        layer_list.append(nn.Sequential(nn.Linear(hidden_dim_list[i+1], hidden_dim_list[i+2])))\n        self.fc_layer   = nn.Sequential(*layer_list)\n    \n    def forward(self, x):\n        out = self.fc_layer(x)\n        return out\n\nclass Autoencoder(nn.Module):\n    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list):\n        super().__init__()\n        self.encoder = Encoder(enc_hidden_dim_list)\n        self.decoder = Decoder(dec_hidden_dim_list)\n\n    def forward(self, x):\n        out = self.encoder(x)\n        out = self.decoder(out)\n        return out\n\n\nautoencoder = Autoencoder(args.enc_hidden_dim_list, args.dec_hidden_dim_list)\nautoencoder = autoencoder.to(device)\n\ncriterion = nn.MSELoss() \noptimizer = optim.Adam(autoencoder.parameters(), lr=args.lr_rate)\n\n\ndef train_autoencoder(autoencoder, criterion, optimizer, num_epochs):\n    train_loss_arr  = []\n    test_loss_arr   = []\n\n    best_test_loss  = 99999999\n    early_stop, early_stop_max = 0., 3.\n    for epoch in range(num_epochs):\n        autoencoder.train()\n        epoch_loss  = 0.\n        for data in train_loader:\n            inputs, _   = data\n            inputs      = inputs.to(device)\n            optimizer.zero_grad()\n            outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n            train_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n            epoch_loss += train_loss.data\n            train_loss.backward()\n            optimizer.step()\n\n        train_loss_arr.append(epoch_loss / len(train_loader.dataset))\n        \n        if epoch != -1:\n            autoencoder.eval()\n\n            test_loss = 0.\n\n            for data in test_loader:\n                inputs, _   = data\n                inputs      = inputs.to(device)\n\n                outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n                batch_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n                test_loss  += batch_loss.data\n\n            test_loss = test_loss\n            test_loss_arr.append(test_loss)\n\n            if best_test_loss   &gt; test_loss:\n                best_test_loss  = test_loss\n                early_stop      = 0\n\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f} *')\n            else:\n                early_stop += 1\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f}') \n\n        if early_stop &gt;= early_stop_max:\n            break\n\n\ntrain_autoencoder(autoencoder, criterion, optimizer, num_epochs=args.num_epoch)\n\ndata_iter       = iter(test_loader)\nimages, _       = next(data_iter)\nreconstructed   = autoencoder(images)\nvisualize_images(images, reconstructed.detach().numpy())\n\n\n\n\n\nparser = argparse.ArgumentParser(description='parser for argparse test')\n\nparser.add_argument('--enc_hidden_dim', type=str, default='784,256,128,64,32')\nparser.add_argument('--lr_rate', type=float, default=0.001)\nparser.add_argument('--num_epoch', type=int, default=10)\n\nif 'ipykernel_launcher' in sys.argv[0]:\n    sys.argv = [sys.argv[0]]  \n\nargs = parser.parse_args()\n\nenc_hidden_dim = args.enc_hidden_dim.split(',') ### key point(dec_hidden_dim을 따로 정의하지 않았음)\n\nargs.enc_hidden_dim_list = []\n\nfor i in enc_hidden_dim:\n    args.enc_hidden_dim_list.append(int(i))\n\nargs.enc_hidden_dim_list\n\nargs.enc_hidden_dim_list[::-1]\n\nargs\n\n\nclass midlayer(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(midlayer, self).__init__()\n        self.fc_layer   = nn.Linear(input_dim, hidden_dim)\n        self.activation = nn.LeakyReLU()\n   \n    def forward(self, x):\n        out = self.fc_layer(x)\n        out = self.activation(out)\n        return out\n\nclass Encoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super(Encoder, self).__init__()\n       \n        layer_list      = []\n        for i in range(len(hidden_dim_list)-1):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n        \n        self.fc_layer   = nn.Sequential(*layer_list)\n        \n    def forward(self, x):\n        out = self.fc_layer(x)\n        return out\n\nclass Decoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super().__init__()\n        \n        layer_list = []\n        for i in range(len(hidden_dim_list)-2):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n    \n        layer_list.append(nn.Sequential(nn.Linear(hidden_dim_list[i+1], hidden_dim_list[i+2])))\n        self.fc_layer = nn.Sequential(*layer_list)\n    \n    def forward(self, x):\n        out = self.fc_layer(x)\n        return out\n\nclass Autoencoder(nn.Module):\n    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list):\n        super().__init__()\n        self.encoder = Encoder(enc_hidden_dim_list)\n        self.decoder = Decoder(dec_hidden_dim_list)\n\n    def forward(self, x):\n        out = self.encoder(x)\n        out = self.decoder(out)\n        return out\n\n\nautoencoder = Autoencoder(args.enc_hidden_dim_list, args.enc_hidden_dim_list[::-1]) ### key point(dec_hidden_dim_list를 enc_hiffen_dim_list[::-1]을 이용해서 정의함)\nautoencoder = autoencoder.to(device)\n\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(autoencoder.parameters(), lr=args.lr_rate)\n\n\ndef train_autoencoder(autoencoder, criterion, optimizer, num_epochs):\n    train_loss_arr  = []\n    test_loss_arr   = []\n\n    best_test_loss  = 99999999\n    early_stop, early_stop_max = 0., 3.\n    for epoch in range(num_epochs):\n        autoencoder.train()\n        epoch_loss  = 0.\n        for data in train_loader:\n            inputs, _   = data\n            inputs      = inputs.to(device)\n            optimizer.zero_grad()\n            outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n            train_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n            epoch_loss += train_loss.data\n            train_loss.backward()\n            optimizer.step()\n\n        train_loss_arr.append(epoch_loss / len(train_loader.dataset))\n        \n        if epoch != -1:\n            autoencoder.eval()\n\n            test_loss = 0.\n\n            for data in test_loader:\n                inputs, _   = data\n                inputs      = inputs.to(device)\n\n                outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n                batch_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n                test_loss  += batch_loss.data\n\n            test_loss = test_loss\n            test_loss_arr.append(test_loss)\n\n            if best_test_loss   &gt; test_loss:\n                best_test_loss  = test_loss\n                early_stop      = 0\n\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f} *')\n            else:\n                early_stop += 1\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f}') \n\n        if early_stop &gt;= early_stop_max:\n            break\n\n\ntrain_autoencoder(autoencoder, criterion, optimizer, num_epochs=args.num_epoch)\n\ndata_iter       = iter(test_loader)\nimages, _       = next(data_iter)\nreconstructed   = autoencoder(images)\nvisualize_images(images, reconstructed.detach().numpy())"
  },
  {
    "objectID": "posts/Autoencoder/2023-10-11-autoencoder.html#autoencoder-for-mnist-data-set",
    "href": "posts/Autoencoder/2023-10-11-autoencoder.html#autoencoder-for-mnist-data-set",
    "title": "[Autoencoder] Autoencoder implementation of MNIST data set",
    "section": "",
    "text": "- imports\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport argparse\nimport sys\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torchinfo import summary\nfrom mpl_toolkits.mplot3d import Axes3D\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\n- data set\n\ndata_root = './data'\n\nbatch_size = 32\n\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(0.5, 0.5),\n    transforms.Lambda(lambda x: x.view(-1)),\n])\n\ntrainset = datasets.MNIST(\n    root        = data_root, \n    train       = True, \n    download    = True,\n    transform   = transform\n)\n\ntestset = datasets.MNIST(\n    root        = data_root, \n    train       = False, \n    download    = False,\n    transform   = transform\n)\n\ntrain_loader = torch.utils.data.DataLoader(\n    dataset     = trainset,\n    batch_size  = batch_size,\n    shuffle     = True\n)\n\ntest_loader = torch.utils.data.DataLoader(\n    dataset     = testset,\n    batch_size  = batch_size,\n    shuffle     = False\n)\n\n- argparse\n\nparser = argparse.ArgumentParser(description='parser for argparse test')\n\nparser.add_argument('--input_dim', type=int, default=28*28)\nparser.add_argument('--learning_rate', type=float, default=0.001)\nparser.add_argument('--num_epoch', type=int, default=10)\nparser.add_argument('--enc_hidden_dim', type=str, default='256,128,64,32,3')\nparser.add_argument('--dec_hidden_dim', type=str, default='32,64,128,256')\n\n\nif 'ipykernel_launcher' in sys.argv[0]:\n    sys.argv = [sys.argv[0]]\n\nargs = parser.parse_args()\n\nenc_hidden_dim = args.enc_hidden_dim.split(',')\ndec_hidden_dim = args.dec_hidden_dim.split(',')\nargs.enc_hidden_dim_list = []\nargs.dec_hidden_dim_list = []\n\nargs.enc_hidden_dim_list.append(args.input_dim)\n\nfor i in enc_hidden_dim:\n    args.enc_hidden_dim_list.append(int(i))\n\nargs.enc_hidden_dim_list\n\nargs.dec_hidden_dim_list.append(args.enc_hidden_dim_list[-1])\n\nfor i in dec_hidden_dim:\n    args.dec_hidden_dim_list.append(int(i))\n\nargs.dec_hidden_dim_list.append(args.input_dim)\n\nargs.dec_hidden_dim_list\n\nargs\n\n- model\n\nclass midlayer(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(midlayer, self).__init__()\n        self.fc_layer   = nn.Linear(input_dim, hidden_dim)\n        self.activation = nn.LeakyReLU()\n    \n    def forward(self, x):\n        out = self.fc_layer(x)\n        out = self.activation(out)\n        return out\n\n\nclass Encoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super(Encoder, self).__init__()\n        \n        layer_list = []\n        for i in range(len(hidden_dim_list)-1):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n        \n        self.fc_layer = nn.Sequential(*layer_list)\n        \n    def forward(self, x):\n        out = self.fc_layer(x)\n\n        return out\n\n\nclass Decoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super().__init__()\n        \n        layer_list = []\n        for i in range(len(hidden_dim_list)-2):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n        \n        layer_list.append(nn.Sequential(nn.Linear(hidden_dim_list[i+1], hidden_dim_list[i+2]), nn.Sigmoid()))\n        self.fc_layer = nn.Sequential(*layer_list)\n    \n    def forward(self, x):\n        out = self.fc_layer(x)\n\n        return out\n\n\nclass Autoencoder(nn.Module):\n    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list):\n        super().__init__()\n\n        self.encoder = Encoder(enc_hidden_dim_list)\n        self.decoder = Decoder(dec_hidden_dim_list)\n\n    def forward(self, x):\n        out = self.encoder(x)\n        out = self.decoder(out)\n\n        return out\n\n\nautoencoder = Autoencoder(args.enc_hidden_dim_list, args.dec_hidden_dim_list)\nautoencoder = autoencoder.to(device)\n\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n\n- train & visualization function\n\ndef train_autoencoder(autoencoder, criterion, optimizer, num_epochs):\n    train_loss_arr  = []\n    test_loss_arr   = []\n\n    best_test_loss  = 99999999\n    early_stop, early_stop_max = 0., 3.\n    for epoch in range(num_epochs):\n        autoencoder.train()\n        epoch_loss  = 0.\n        for data in train_loader:\n            inputs, _   = data\n            inputs      = inputs.to(device)\n            optimizer.zero_grad()\n            outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n            train_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n            epoch_loss += train_loss.data\n            train_loss.backward()\n            optimizer.step()\n\n        train_loss_arr.append(epoch_loss / len(train_loader.dataset))\n        \n        if epoch != 99:\n            autoencoder.eval()\n\n            test_loss   = 0.\n\n            for data in test_loader:\n                inputs, _   = data\n                inputs      = inputs.to(device)\n\n                outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n                batch_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n                test_loss  += batch_loss.data\n\n            test_loss   = test_loss\n            test_loss_arr.append(test_loss)\n\n            if best_test_loss   &gt; test_loss:\n                best_test_loss  = test_loss\n                early_stop      = 0\n\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f} *')\n            else:\n                early_stop      += 1\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f}') \n\n        if early_stop   &gt;= early_stop_max:\n            break\n\ndef visualize_images(original, reconstructed, n=10):\n    plt.figure(figsize=(20, 4))\n    for i in range(n):\n        ax = plt.subplot(2, n, i + 1)\n        plt.imshow(original[i].reshape(28, 28), cmap='gray')\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n\n        ax = plt.subplot(2, n, i + 1 + n)\n        plt.imshow(reconstructed[i].reshape(28, 28), cmap='gray')\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n    plt.show()\n\n- train & visualization\n\ntrain_autoencoder(autoencoder, criterion, optimizer, num_epochs=args.num_epoch)\n\ndata_iter = iter(test_loader)\nimages, _ = next(data_iter)\nreconstructed = autoencoder(images)\nvisualize_images(images, reconstructed.detach().numpy())\n\n\n\n\n\nparser = argparse.ArgumentParser(description='parser for argparse test')\n\nparser.add_argument('--input_dim', type=int, default=28*28)\nparser.add_argument('--enc_hidden_dim', type=str, default='128,32')\nparser.add_argument('--dec_hidden_dim', type=str, default='128')\nparser.add_argument('--lr_rate', type=float, default=0.001)\nparser.add_argument('--num_epoch', type=int, default=10)\n\nif 'ipykernel_launcher' in sys.argv[0]:\n    sys.argv = [sys.argv[0]]  \n\nargs = parser.parse_args()\n\nenc_hidden_dim = args.enc_hidden_dim.split(',')\ndec_hidden_dim = args.dec_hidden_dim.split(',')\n\nargs.enc_hidden_dim_list = []\nargs.dec_hidden_dim_list = []\n\nargs.enc_hidden_dim_list.append(args.input_dim)\n\nfor i in enc_hidden_dim:\n    args.enc_hidden_dim_list.append(int(i))\n\nargs.dec_hidden_dim_list.append(args.enc_hidden_dim_list[-1])\n\nfor i in dec_hidden_dim:\n    args.dec_hidden_dim_list.append(int(i))\n\nargs.dec_hidden_dim_list.append(args.input_dim)\n\nargs\n\n\nclass midlayer(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(midlayer, self).__init__()\n        self.fc_layer   = nn.Linear(input_dim, hidden_dim)\n        self.activation = nn.LeakyReLU()\n   \n    def forward(self, x):\n        out = self.fc_layer(x)\n        out = self.activation(out)\n        return out\n\n\nclass Encoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super(Encoder, self).__init__()\n       \n        layer_list      = []\n        for i in range(len(hidden_dim_list)-1):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n        \n        self.fc_layer   = nn.Sequential(*layer_list)\n        \n    def forward(self, x):\n        out = self.fc_layer(x)\n        return out\n\n\nclass Decoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super().__init__()\n        \n        layer_list = []\n        for i in range(len(hidden_dim_list)-2):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n    \n        layer_list.append(nn.Sequential(nn.Linear(hidden_dim_list[i+1], hidden_dim_list[i+2])))\n        self.fc_layer = nn.Sequential(*layer_list)\n    \n    def forward(self, x):\n        out = self.fc_layer(x)\n        return out\n\n\nclass Autoencoder(nn.Module):\n    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list):\n        super().__init__()\n        self.encoder = Encoder(enc_hidden_dim_list)\n        self.decoder = Decoder(dec_hidden_dim_list)\n\n    def forward(self, x):\n        out = self.encoder(x)\n        out = self.decoder(out)\n        return out\n\n\nautoencoder = Autoencoder(args.enc_hidden_dim_list, args.dec_hidden_dim_list)\nautoencoder = autoencoder.to(device)\n\ncriterion = nn.MSELoss() \noptimizer = optim.Adam(autoencoder.parameters(), lr=args.lr_rate)\n\n\ndef train_autoencoder(autoencoder, criterion, optimizer, num_epochs):\n    train_loss_arr  = []\n    test_loss_arr   = []\n\n    best_test_loss  = 99999999\n    early_stop, early_stop_max = 0., 3.\n    for epoch in range(num_epochs):\n        autoencoder.train()\n        epoch_loss  = 0.\n        for data in train_loader:\n            inputs, _   = data\n            inputs      = inputs.to(device)\n            optimizer.zero_grad()\n            outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n            train_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n            epoch_loss += train_loss.data\n            train_loss.backward()\n            optimizer.step()\n\n        train_loss_arr.append(epoch_loss / len(train_loader.dataset))\n        \n        if epoch != -1:\n            autoencoder.eval()\n\n            test_loss = 0.\n\n            for data in test_loader:\n                inputs, _   = data\n                inputs      = inputs.to(device)\n\n                outputs = autoencoder(inputs.view(inputs.size(0), -1))\n                batch_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n                test_loss  += batch_loss.data\n\n            test_loss = test_loss\n            test_loss_arr.append(test_loss)\n\n            if best_test_loss   &gt; test_loss:\n                best_test_loss  = test_loss\n                early_stop      = 0\n\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f} *')\n            else:\n                early_stop += 1\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f}') \n\n        if early_stop &gt;= early_stop_max:\n            break\n\n\ntrain_autoencoder(autoencoder, criterion, optimizer, num_epochs=args.num_epoch)\n\ndata_iter       = iter(test_loader)\nimages, _       = next(data_iter)\nreconstructed   = autoencoder(images)\nvisualize_images(images, reconstructed.detach().numpy())\n\n\n\n\n\nparser = argparse.ArgumentParser(description='parser for argparse test')\n\nparser.add_argument('--enc_hidden_dim', type=str, default='784,128,32')\nparser.add_argument('--dec_hidden_dim', type=str, default='128,784')\nparser.add_argument('--lr_rate', type=float, default=0.001)\nparser.add_argument('--num_epoch', type=int, default=10)\n\nif 'ipykernel_launcher' in sys.argv[0]:\n    sys.argv = [sys.argv[0]]  \n\nargs = parser.parse_args()\n\nenc_hidden_dim = args.enc_hidden_dim.split(',')\ndec_hidden_dim = args.dec_hidden_dim.split(',')\n\nargs.enc_hidden_dim_list = []\nargs.dec_hidden_dim_list = []\n\nfor i in enc_hidden_dim:\n    args.enc_hidden_dim_list.append(int(i))\n\nargs.enc_hidden_dim_list\n\nargs.dec_hidden_dim_list.append(args.enc_hidden_dim_list[-1])\n\nfor i in dec_hidden_dim:\n    args.dec_hidden_dim_list.append(int(i))\n\nargs.dec_hidden_dim_list\n\nargs\n\n\nclass midlayer(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(midlayer, self).__init__()\n        self.fc_layer   = nn.Linear(input_dim, hidden_dim)\n        self.activation = nn.LeakyReLU()\n   \n    def forward(self, x):\n        out = self.fc_layer(x)\n        out = self.activation(out)\n        return out\n\n\nclass Encoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super(Encoder, self).__init__()\n       \n        layer_list      = []\n        for i in range(len(hidden_dim_list)-1):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n        \n        self.fc_layer   = nn.Sequential(*layer_list)\n        \n    def forward(self, x):\n        out = self.fc_layer(x)\n        return out\n\n\nclass Decoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super().__init__()\n        \n        layer_list      = []\n        for i in range(len(hidden_dim_list)-2):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n    \n        layer_list.append(nn.Sequential(nn.Linear(hidden_dim_list[i+1], hidden_dim_list[i+2])))\n        self.fc_layer   = nn.Sequential(*layer_list)\n    \n    def forward(self, x):\n        out = self.fc_layer(x)\n        return out\n\n\nclass Autoencoder(nn.Module):\n    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list):\n        super().__init__()\n        self.encoder = Encoder(enc_hidden_dim_list)\n        self.decoder = Decoder(dec_hidden_dim_list)\n\n    def forward(self, x):\n        out = self.encoder(x)\n        out = self.decoder(out)\n        return out\n\n\nautoencoder = Autoencoder(args.enc_hidden_dim_list, args.dec_hidden_dim_list)\nautoencoder = autoencoder.to(device)\n\ncriterion = nn.MSELoss() \noptimizer = optim.Adam(autoencoder.parameters(), lr=args.lr_rate)\n\n\ndef train_autoencoder(autoencoder, criterion, optimizer, num_epochs):\n    train_loss_arr  = []\n    test_loss_arr   = []\n\n    best_test_loss  = 99999999\n    early_stop, early_stop_max = 0., 3.\n    for epoch in range(num_epochs):\n        autoencoder.train()\n        epoch_loss  = 0.\n        for data in train_loader:\n            inputs, _   = data\n            inputs      = inputs.to(device)\n            optimizer.zero_grad()\n            outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n            train_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n            epoch_loss += train_loss.data\n            train_loss.backward()\n            optimizer.step()\n\n        train_loss_arr.append(epoch_loss / len(train_loader.dataset))\n        \n        if epoch != -1:\n            autoencoder.eval()\n\n            test_loss = 0.\n\n            for data in test_loader:\n                inputs, _   = data\n                inputs      = inputs.to(device)\n\n                outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n                batch_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n                test_loss  += batch_loss.data\n\n            test_loss = test_loss\n            test_loss_arr.append(test_loss)\n\n            if best_test_loss   &gt; test_loss:\n                best_test_loss  = test_loss\n                early_stop      = 0\n\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f} *')\n            else:\n                early_stop += 1\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f}') \n\n        if early_stop &gt;= early_stop_max:\n            break\n\n\ntrain_autoencoder(autoencoder, criterion, optimizer, num_epochs=args.num_epoch)\n\ndata_iter       = iter(test_loader)\nimages, _       = next(data_iter)\nreconstructed   = autoencoder(images)\nvisualize_images(images, reconstructed.detach().numpy())\n\n\n\n\n\narser = argparse.ArgumentParser(description='parser for argparse test')\n\nparser.add_argument('--enc_hidden_dim', type=str, default='784,128,32')\nparser.add_argument('--lr_rate', type=float, default=0.001)\nparser.add_argument('--num_epoch', type=int, default=10)\n\nif 'ipykernel_launcher' in sys.argv[0]:\n    sys.argv = [sys.argv[0]]  \n\nargs = parser.parse_args()\n\nenc_hidden_dim = args.enc_hidden_dim.split(',') ### key point\ndec_hidden_dim = args.enc_hidden_dim.split(',')\n\nargs.enc_hidden_dim_list = []\nargs.dec_hidden_dim_list = []\n\nfor i in enc_hidden_dim:\n    args.enc_hidden_dim_list.append(int(i))\n\nargs.enc_hidden_dim_list\n\nfor i in enc_hidden_dim[::-1]:\n    args.dec_hidden_dim_list.append(int(i))\n\nargs.dec_hidden_dim_list\n\nargs\n\n\nclass midlayer(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(midlayer, self).__init__()\n        self.fc_layer   = nn.Linear(input_dim, hidden_dim)\n        self.activation = nn.LeakyReLU()\n   \n    def forward(self, x):\n        out = self.fc_layer(x)\n        out = self.activation(out)\n        return out\n\nclass Encoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super(Encoder, self).__init__()\n       \n        layer_list      = []\n        for i in range(len(hidden_dim_list)-1):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n        \n        self.fc_layer   = nn.Sequential(*layer_list)\n        \n    def forward(self, x):\n        out = self.fc_layer(x)\n        return out\n\nclass Decoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super().__init__()\n        \n        layer_list      = []\n        for i in range(len(hidden_dim_list)-2):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n    \n        layer_list.append(nn.Sequential(nn.Linear(hidden_dim_list[i+1], hidden_dim_list[i+2])))\n        self.fc_layer   = nn.Sequential(*layer_list)\n    \n    def forward(self, x):\n        out = self.fc_layer(x)\n        return out\n\nclass Autoencoder(nn.Module):\n    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list):\n        super().__init__()\n        self.encoder = Encoder(enc_hidden_dim_list)\n        self.decoder = Decoder(dec_hidden_dim_list)\n\n    def forward(self, x):\n        out = self.encoder(x)\n        out = self.decoder(out)\n        return out\n\n\nautoencoder = Autoencoder(args.enc_hidden_dim_list, args.dec_hidden_dim_list)\nautoencoder = autoencoder.to(device)\n\ncriterion = nn.MSELoss() \noptimizer = optim.Adam(autoencoder.parameters(), lr=args.lr_rate)\n\n\ndef train_autoencoder(autoencoder, criterion, optimizer, num_epochs):\n    train_loss_arr  = []\n    test_loss_arr   = []\n\n    best_test_loss  = 99999999\n    early_stop, early_stop_max = 0., 3.\n    for epoch in range(num_epochs):\n        autoencoder.train()\n        epoch_loss  = 0.\n        for data in train_loader:\n            inputs, _   = data\n            inputs      = inputs.to(device)\n            optimizer.zero_grad()\n            outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n            train_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n            epoch_loss += train_loss.data\n            train_loss.backward()\n            optimizer.step()\n\n        train_loss_arr.append(epoch_loss / len(train_loader.dataset))\n        \n        if epoch != -1:\n            autoencoder.eval()\n\n            test_loss = 0.\n\n            for data in test_loader:\n                inputs, _   = data\n                inputs      = inputs.to(device)\n\n                outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n                batch_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n                test_loss  += batch_loss.data\n\n            test_loss = test_loss\n            test_loss_arr.append(test_loss)\n\n            if best_test_loss   &gt; test_loss:\n                best_test_loss  = test_loss\n                early_stop      = 0\n\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f} *')\n            else:\n                early_stop += 1\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f}') \n\n        if early_stop &gt;= early_stop_max:\n            break\n\n\ntrain_autoencoder(autoencoder, criterion, optimizer, num_epochs=args.num_epoch)\n\ndata_iter       = iter(test_loader)\nimages, _       = next(data_iter)\nreconstructed   = autoencoder(images)\nvisualize_images(images, reconstructed.detach().numpy())\n\n\n\n\n\nparser = argparse.ArgumentParser(description='parser for argparse test')\n\nparser.add_argument('--enc_hidden_dim', type=str, default='784,256,128,64,32')\nparser.add_argument('--lr_rate', type=float, default=0.001)\nparser.add_argument('--num_epoch', type=int, default=10)\n\nif 'ipykernel_launcher' in sys.argv[0]:\n    sys.argv = [sys.argv[0]]  \n\nargs = parser.parse_args()\n\nenc_hidden_dim = args.enc_hidden_dim.split(',') ### key point(dec_hidden_dim을 따로 정의하지 않았음)\n\nargs.enc_hidden_dim_list = []\n\nfor i in enc_hidden_dim:\n    args.enc_hidden_dim_list.append(int(i))\n\nargs.enc_hidden_dim_list\n\nargs.enc_hidden_dim_list[::-1]\n\nargs\n\n\nclass midlayer(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(midlayer, self).__init__()\n        self.fc_layer   = nn.Linear(input_dim, hidden_dim)\n        self.activation = nn.LeakyReLU()\n   \n    def forward(self, x):\n        out = self.fc_layer(x)\n        out = self.activation(out)\n        return out\n\nclass Encoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super(Encoder, self).__init__()\n       \n        layer_list      = []\n        for i in range(len(hidden_dim_list)-1):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n        \n        self.fc_layer   = nn.Sequential(*layer_list)\n        \n    def forward(self, x):\n        out = self.fc_layer(x)\n        return out\n\nclass Decoder(nn.Module):\n    def __init__(self, hidden_dim_list):\n        super().__init__()\n        \n        layer_list = []\n        for i in range(len(hidden_dim_list)-2):\n            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n    \n        layer_list.append(nn.Sequential(nn.Linear(hidden_dim_list[i+1], hidden_dim_list[i+2])))\n        self.fc_layer = nn.Sequential(*layer_list)\n    \n    def forward(self, x):\n        out = self.fc_layer(x)\n        return out\n\nclass Autoencoder(nn.Module):\n    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list):\n        super().__init__()\n        self.encoder = Encoder(enc_hidden_dim_list)\n        self.decoder = Decoder(dec_hidden_dim_list)\n\n    def forward(self, x):\n        out = self.encoder(x)\n        out = self.decoder(out)\n        return out\n\n\nautoencoder = Autoencoder(args.enc_hidden_dim_list, args.enc_hidden_dim_list[::-1]) ### key point(dec_hidden_dim_list를 enc_hiffen_dim_list[::-1]을 이용해서 정의함)\nautoencoder = autoencoder.to(device)\n\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(autoencoder.parameters(), lr=args.lr_rate)\n\n\ndef train_autoencoder(autoencoder, criterion, optimizer, num_epochs):\n    train_loss_arr  = []\n    test_loss_arr   = []\n\n    best_test_loss  = 99999999\n    early_stop, early_stop_max = 0., 3.\n    for epoch in range(num_epochs):\n        autoencoder.train()\n        epoch_loss  = 0.\n        for data in train_loader:\n            inputs, _   = data\n            inputs      = inputs.to(device)\n            optimizer.zero_grad()\n            outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n            train_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n            epoch_loss += train_loss.data\n            train_loss.backward()\n            optimizer.step()\n\n        train_loss_arr.append(epoch_loss / len(train_loader.dataset))\n        \n        if epoch != -1:\n            autoencoder.eval()\n\n            test_loss = 0.\n\n            for data in test_loader:\n                inputs, _   = data\n                inputs      = inputs.to(device)\n\n                outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n                batch_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n                test_loss  += batch_loss.data\n\n            test_loss = test_loss\n            test_loss_arr.append(test_loss)\n\n            if best_test_loss   &gt; test_loss:\n                best_test_loss  = test_loss\n                early_stop      = 0\n\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f} *')\n            else:\n                early_stop += 1\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f}') \n\n        if early_stop &gt;= early_stop_max:\n            break\n\n\ntrain_autoencoder(autoencoder, criterion, optimizer, num_epochs=args.num_epoch)\n\ndata_iter       = iter(test_loader)\nimages, _       = next(data_iter)\nreconstructed   = autoencoder(images)\nvisualize_images(images, reconstructed.detach().numpy())"
  }
]