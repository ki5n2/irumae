{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"**[DAGMM]** DAGMM: for arrhythmia data set\"\n",
        "author: \"kione kim\"\n",
        "date: \"10/19/2023\"\n",
        "bibliography: dagmm.bib\n",
        "---"
      ],
      "id": "3e9e06f9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deep Autoencoding Gaussian Mixture Model for Arrhythmia dataset\n"
      ],
      "id": "66196dcb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### imports\n",
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import argparse\n",
        "import sys"
      ],
      "id": "442bcb64",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### data 파일\n",
        "file_path = 'C:\\\\Users\\\\UOS\\\\Desktop\\\\연구\\\\5. 데이터\\\\data\\\\arrhythmia\\\\arrhythmia.data'\n",
        "\n",
        "df = pd.read_csv(file_path, header=None)\n",
        "df = df.replace('?', 0)\n",
        "df = df.astype('float64')\n",
        "\n",
        "data_array = df.values\n",
        "data_array = torch.autograd.Variable(torch.from_numpy(data_array).float())\n",
        "data_array.shape"
      ],
      "id": "faf89830",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "parser = argparse.ArgumentParser(description='parser for argparse test')\n",
        "\n",
        "parser.add_argument('--input_dim', type=int, default=data_array.shape[-1])\n",
        "parser.add_argument('--enc_hidden_dim', type=str, default='10,2')\n",
        "parser.add_argument('--dec_hidden_dim', type=str, default='10')\n",
        "parser.add_argument('--est_hidden_dim', type=str, default='4, 10, 2')\n",
        "parser.add_argument('--dropout', action='store_true', default=0.5)\n",
        "parser.add_argument('--learning_rate', type=float, default=0.001)\n",
        "parser.add_argument('--num_epoch', type=int, default=10)\n",
        "\n",
        "if 'ipykernel_launcher' in sys.argv[0]:\n",
        "    sys.argv = [sys.argv[0]]  \n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "enc_hidden_dim = args.enc_hidden_dim.split(',')\n",
        "dec_hidden_dim = args.dec_hidden_dim.split(',')\n",
        "est_hidden_dim = args.est_hidden_dim.split(',')\n",
        "\n",
        "args.enc_hidden_dim_list = []\n",
        "args.dec_hidden_dim_list = []\n",
        "args.est_hidden_dim_list = []\n",
        "\n",
        "args.enc_hidden_dim_list.append(args.input_dim)\n",
        "\n",
        "for i in enc_hidden_dim:\n",
        "    args.enc_hidden_dim_list.append(int(i))\n",
        "\n",
        "args.enc_hidden_dim_list\n",
        "\n",
        "args.dec_hidden_dim_list.append(args.enc_hidden_dim_list[-1])\n",
        "\n",
        "for i in dec_hidden_dim:\n",
        "    args.dec_hidden_dim_list.append(int(i))\n",
        "\n",
        "args.dec_hidden_dim_list.append(args.input_dim)\n",
        "\n",
        "args.dec_hidden_dim_list\n",
        "\n",
        "for i in est_hidden_dim:\n",
        "    args.est_hidden_dim_list.append(int(i))\n",
        "\n",
        "args.est_hidden_dim_list\n",
        "\n",
        "args"
      ],
      "id": "cab64970",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### compresssion network\n",
        "class midlayer(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(midlayer, self).__init__()\n",
        "        self.fc_layer   = nn.Linear(input_dim, hidden_dim)\n",
        "        self.activation = nn.Tanh()\n",
        "    \n",
        "    def forward(self, input):\n",
        "        out = self.fc_layer(input)        \n",
        "        out = self.activation(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, hidden_dim_list):\n",
        "        super(Encoder, self).__init__()\n",
        "        \n",
        "        layer_list = []\n",
        "        for i in range(len(hidden_dim_list)-2):\n",
        "            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n",
        "        \n",
        "        layer_list.append(nn.Linear(hidden_dim_list[i+1], hidden_dim_list[i+2]))\n",
        "        self.layer = nn.Sequential(*layer_list)\n",
        "\n",
        "    def forward(self, input):\n",
        "        out = self.layer(input)\n",
        "        return out\n",
        "    \n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_dim_list):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        layer_list = []\n",
        "        for i in range(len(hidden_dim_list)-2):\n",
        "            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n",
        "        \n",
        "        layer_list.append(midlayer(hidden_dim_list[i+1], hidden_dim_list[i+2]))\n",
        "        self.layer = nn.Sequential(*layer_list)\n",
        "    \n",
        "    def forward(self, input):\n",
        "        out = self.layer(input)\n",
        "        return out\n",
        "\n",
        "class CompressionNet(nn.Module):\n",
        "    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(enc_hidden_dim_list)\n",
        "        self.decoder = Decoder(dec_hidden_dim_list)\n",
        "\n",
        "        self._reconstruction_loss = nn.MSELoss()\n",
        "\n",
        "    def forward(self, input):\n",
        "        out = self.encoder(input)\n",
        "        out = self.decoder(out)\n",
        "        return out\n",
        "\n",
        "    def encode(self, input):\n",
        "        return self.encoder(input)\n",
        "\n",
        "    def decode(self, input):\n",
        "        return self.decoder(input)\n",
        "\n",
        "    def reconstuction_loss(self, input, input_target):\n",
        "        target_hat = self(input)\n",
        "        return self._reconstruction_loss(target_hat, input_target)"
      ],
      "id": "ffa59fa8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### reconstructed error\n",
        "eps = torch.autograd.Variable(torch.FloatTensor([1.e-8]), requires_grad=False)\n",
        "\n",
        "def relative_euclidean_distance(x1, x2, eps=eps):\n",
        "    num = torch.norm(x1 - x2, p=2, dim=1)\n",
        "    denom = torch.norm(x1, p=2, dim=1)\n",
        "    return num / torch.max(denom, eps)\n",
        "\n",
        "def cosine_similarity(x1, x2, eps=eps):\n",
        "    dot_prod = torch.sum(x1 * x2, dim=1)\n",
        "    dist_x1 = torch.norm(x1, p=2, dim=1)\n",
        "    dist_x2 = torch.norm(x2, p=2, dim=1)\n",
        "    return dot_prod / torch.max(dist_x1*dist_x2, eps)"
      ],
      "id": "cbc854b4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### estimation network\n",
        "class Estimation(nn.Module):\n",
        "    def __init__(self, est_hidden_dim_list):\n",
        "        super().__init__()\n",
        "        \n",
        "        layer_list = []\n",
        "        for i in range(len(est_hidden_dim_list)-2):\n",
        "            layer_list.append(midlayer(est_hidden_dim_list[i], est_hidden_dim_list[i+1]))\n",
        "        \n",
        "        layer_list.append(nn.Dropout(p=0.5))\n",
        "        layer_list.append(nn.Linear(est_hidden_dim_list[-2], est_hidden_dim_list[-1]))\n",
        "        layer_list.append(nn.Softmax())\n",
        "        self.net = nn.Sequential(*layer_list)\n",
        "        \n",
        "    def forward(self, input):\n",
        "        out = self.net(input)\n",
        "        return out"
      ],
      "id": "67df0a6d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### Mixture\n",
        "class Mixture(nn.Module):\n",
        "    def __init__(self, latent_dimension):\n",
        "        super().__init__()\n",
        "        self.latent_dimension = latent_dimension\n",
        "\n",
        "        self.Phi    = np.random.random([1])\n",
        "        self.Phi    = torch.from_numpy(self.Phi).float()\n",
        "        self.Phi    = nn.Parameter(self.Phi, requires_grad = False)\n",
        "\n",
        "        self.mu     = 2.*np.random.random([latent_dimension]) - 0.5\n",
        "        self.mu     = torch.from_numpy(self.mu).float()\n",
        "        self.mu     = nn.Parameter(self.mu, requires_grad = False)\n",
        "\n",
        "        self.Sigma  = np.eye(latent_dimension, latent_dimension)\n",
        "        self.Sigma  = torch.from_numpy(self.Sigma).float()\n",
        "        self.Sigma  = nn.Parameter(self.Sigma, requires_grad = False)\n",
        "        \n",
        "        self.eps_Sigma  = torch.FloatTensor(np.diag([1.e-8 for _ in range(latent_dimension)]))\n",
        "\n",
        "    def forward(self, est_inputs, with_log = True):\n",
        "        batch_size, _   = est_inputs.shape\n",
        "        out_values  = []\n",
        "        inv_sigma   = torch.inverse(self.Sigma)\n",
        "        det_sigma   = np.linalg.det(self.Sigma.data.cpu().numpy())\n",
        "        det_sigma   = torch.from_numpy(det_sigma.reshape([1])).float()\n",
        "        det_sigma   = torch.autograd.Variable(det_sigma)\n",
        "        for est_input in est_inputs:\n",
        "            diff    = (est_input - self.mu).view(-1,1)\n",
        "            out     = -0.5 * torch.mm(torch.mm(diff.view(1,-1), inv_sigma), diff)\n",
        "            out     = (self.Phi * torch.exp(out)) / torch.sqrt(2. * np.pi * det_sigma)\n",
        "            if with_log:\n",
        "                out = -torch.log(out)\n",
        "            out_values.append(float(out.data.cpu().numpy()))\n",
        "\n",
        "        out = torch.autograd.Variable(torch.FloatTensor(out_values))\n",
        "        return out\n",
        "    \n",
        "    def _update_parameters(self, samples, affiliations):\n",
        "        if not self.training:\n",
        "            return\n",
        "\n",
        "        batch_size, _ = samples.shape\n",
        "\n",
        "        # Updating phi.\n",
        "        phi = torch.mean(affiliations)\n",
        "        self.Phi.data = phi.data\n",
        "\n",
        "        # Updating mu.\n",
        "        num = 0.\n",
        "        for i in range(batch_size):\n",
        "            z_i     = samples[i, :]\n",
        "            gamma_i = affiliations[i]\n",
        "            num     += gamma_i * z_i\n",
        "        \n",
        "        denom        = torch.sum(affiliations)\n",
        "        self.mu.data = (num / denom).data\n",
        "\n",
        "        # Updating Sigma.\n",
        "        mu  = self.mu\n",
        "        num = None\n",
        "        for i in range(batch_size):\n",
        "            z_i     = samples[i, :]\n",
        "            gamma_i = affiliations[i]\n",
        "            diff    = (z_i - mu).view(-1, 1)\n",
        "            to_add  = gamma_i * torch.mm(diff, diff.view(1, -1))\n",
        "            if num is None:\n",
        "                num = to_add\n",
        "            else:\n",
        "                num += to_add\n",
        "\n",
        "        denom           = torch.sum(affiliations)\n",
        "        self.Sigma.data = (num / denom).data + self.eps_Sigma\n",
        "\n",
        "\n",
        "class GMM(nn.Module):\n",
        "    def __init__(self, num_mixtures, latent_dimension):\n",
        "        super().__init__()\n",
        "        self.num_mixtures       = num_mixtures\n",
        "        self.latent_dimension   = latent_dimension\n",
        "\n",
        "        mixtures        = [Mixture(latent_dimension) for _ in range(num_mixtures)]\n",
        "        self.mixtures   = nn.ModuleList(mixtures)\n",
        "    \n",
        "    def forward(self, est_inputs):\n",
        "        out = None\n",
        "        for mixture in self.mixtures:\n",
        "            to_add  = mixture(est_inputs, with_log = False)\n",
        "            if out is None:\n",
        "                out = to_add\n",
        "            else:\n",
        "                out += to_add\n",
        "        return -torch.log(out)\n",
        "    \n",
        "    def _update_mixtures_parameters(self, samples, mixtures_affiliations):\n",
        "        if not self.training:\n",
        "            return\n",
        "\n",
        "        for i, mixture in enumerate(self.mixtures):\n",
        "            affiliations = mixtures_affiliations[:, i]\n",
        "            mixture._update_parameters(samples, affiliations)"
      ],
      "id": "f01ee752",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### model\n",
        "class DAGMM(nn.Module):\n",
        "    def __init__(self, compression_module, estimation_module, gmm_module):\n",
        "        super().__init__()\n",
        "\n",
        "        self.compressor = compression_module\n",
        "        self.estimator  = estimation_module\n",
        "        self.gmm        = gmm_module\n",
        "\n",
        "    def forward(self, input):\n",
        "        encoded = self.compressor.encode(input)\n",
        "        decoded = self.compressor.decode(encoded)\n",
        "\n",
        "        relative_ed     = relative_euclidean_distance(input, decoded)\n",
        "        cosine_sim      = cosine_similarity(input, decoded)\n",
        "\n",
        "        relative_ed     = relative_ed.view(-1, 1)\n",
        "        cosine_sim      = relative_ed.view(-1, 1)\n",
        "        latent_vectors  = torch.cat([encoded, relative_ed, cosine_sim], dim=1)\n",
        "\n",
        "        if self.training:\n",
        "            mixtures_affiliations = self.estimator(latent_vectors)\n",
        "            self.gmm._update_mixtures_parameters(latent_vectors,\n",
        "                                                 mixtures_affiliations)\n",
        "        return self.gmm(latent_vectors)\n",
        "\n",
        "\n",
        "class DAGMMArrhythmia(DAGMM):\n",
        "    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list, est_hidden_dim_list):\n",
        "        compressor  = CompressionNet(enc_hidden_dim_list, dec_hidden_dim_list)\n",
        "        estimator   = Estimation(est_hidden_dim_list)\n",
        "        gmm = GMM(num_mixtures=2, latent_dimension=4)\n",
        "\n",
        "        super().__init__(compression_module = compressor,\n",
        "                         estimation_module  = estimator,\n",
        "                         gmm_module         = gmm)"
      ],
      "id": "84a8de0d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### tests\n",
        "def test_dagmm():\n",
        "    net = DAGMMArrhythmia(args.enc_hidden_dim_list, args.dec_hidden_dim_list, args.est_hidden_dim_list)\n",
        "    out = net(data_array)\n",
        "    print(out)\n",
        "\n",
        "def convert_to_var(input):\n",
        "    out = torch.from_numpy(input).float()\n",
        "    out = torch.autograd.Variable(out)\n",
        "    return out\n",
        "\n",
        "def test_update_mixture():\n",
        "    batch_size       = 5\n",
        "    latent_dimension = 7\n",
        "    mix              = Mixture(latent_dimension)\n",
        "    latent_vectors   = np.random.random([batch_size, latent_dimension])\n",
        "    affiliations     = np.random.random([batch_size])\n",
        "    latent_vectors   = convert_to_var(latent_vectors)\n",
        "    affiliations     = convert_to_var(affiliations)\n",
        "\n",
        "    for param in mix.parameters():\n",
        "        print(param)\n",
        "\n",
        "    mix.train()\n",
        "    mix._update_parameters(latent_vectors, affiliations)\n",
        "\n",
        "    for param in mix.parameters():\n",
        "        print(param)\n",
        "\n",
        "\n",
        "def test_forward_mixture():\n",
        "    batch_size       = 5\n",
        "    latent_dimension = 7\n",
        "\n",
        "    mix = Mixture(latent_dimension)\n",
        "    latent_vectors   = np.random.random([batch_size, latent_dimension])\n",
        "    latent_vectors   = convert_to_var(latent_vectors)\n",
        "\n",
        "    mix.train()\n",
        "    out = mix(latent_vectors)\n",
        "    print(out)\n",
        "\n",
        "\n",
        "def test_update_gmm():\n",
        "    batch_size      = int(5)\n",
        "    latent_dimension= 7\n",
        "    num_mixtures    = 2\n",
        "\n",
        "    gmm = GMM(num_mixtures, latent_dimension)\n",
        "\n",
        "    latent_vectors  = np.random.random([batch_size, latent_dimension])\n",
        "    latent_vectors  = convert_to_var(latent_vectors)\n",
        "\n",
        "    affiliations    = np.random.random([batch_size, num_mixtures])\n",
        "    affiliations    = convert_to_var(affiliations)\n",
        "\n",
        "    for param in gmm.parameters():\n",
        "        print(param)\n",
        "\n",
        "    gmm.train()\n",
        "    gmm._update_mixtures_parameters(latent_vectors, affiliations)\n",
        "\n",
        "    for param in gmm.parameters():\n",
        "        print(param)"
      ],
      "id": "84773bc7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if __name__ == '__main__':\n",
        "    test_update_mixture()\n",
        "    test_forward_mixture()\n",
        "    test_update_gmm()\n",
        "    test_dagmm()"
      ],
      "id": "2ba94542",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ref\n",
        "- https://openreview.net/forum?id=BJJLHbb0-"
      ],
      "id": "3089b7e2"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}