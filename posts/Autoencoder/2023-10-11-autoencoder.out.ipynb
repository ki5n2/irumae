{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **\\[Autoencoder\\]** Autoencoder implementation of MNIST data set\n",
        "\n",
        "kione kim  \n",
        "2023-10-06\n",
        "\n",
        "## Autoencoder for MNIST data set\n",
        "\n",
        "### first model\n",
        "\n",
        "`-` imports"
      ],
      "id": "7324a8e9-c5e9-4b48-8d50-5f34af15ea87"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchinfo import summary\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "id": "4a7c722a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` data set"
      ],
      "id": "d94a9fc7-644c-4763-b78c-a04b89d7e218"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "data_root = './data'\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0.5, 0.5),\n",
        "    transforms.Lambda(lambda x: x.view(-1)),\n",
        "])\n",
        "\n",
        "trainset = datasets.MNIST(\n",
        "    root        = data_root, \n",
        "    train       = True, \n",
        "    download    = True,\n",
        "    transform   = transform\n",
        ")\n",
        "\n",
        "testset = datasets.MNIST(\n",
        "    root        = data_root, \n",
        "    train       = False, \n",
        "    download    = False,\n",
        "    transform   = transform\n",
        ")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = trainset,\n",
        "    batch_size  = batch_size,\n",
        "    shuffle     = True\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = testset,\n",
        "    batch_size  = batch_size,\n",
        "    shuffle     = False\n",
        ")"
      ],
      "id": "f46d0f14"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` argparse"
      ],
      "id": "24a67c77-b7c1-4f3e-9417-11400d6cac85"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "parser = argparse.ArgumentParser(description='parser for argparse test')\n",
        "\n",
        "parser.add_argument('--input_dim', type=int, default=28*28)\n",
        "parser.add_argument('--learning_rate', type=float, default=0.001)\n",
        "parser.add_argument('--num_epoch', type=int, default=10)\n",
        "parser.add_argument('--enc_hidden_dim', type=str, default='256,128,64,32,3')\n",
        "parser.add_argument('--dec_hidden_dim', type=str, default='32,64,128,256')\n",
        "\n",
        "\n",
        "if 'ipykernel_launcher' in sys.argv[0]:\n",
        "    sys.argv = [sys.argv[0]]\n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "enc_hidden_dim = args.enc_hidden_dim.split(',')\n",
        "dec_hidden_dim = args.dec_hidden_dim.split(',')\n",
        "args.enc_hidden_dim_list = []\n",
        "args.dec_hidden_dim_list = []\n",
        "\n",
        "args.enc_hidden_dim_list.append(args.input_dim)\n",
        "\n",
        "for i in enc_hidden_dim:\n",
        "    args.enc_hidden_dim_list.append(int(i))\n",
        "\n",
        "args.enc_hidden_dim_list\n",
        "\n",
        "args.dec_hidden_dim_list.append(args.enc_hidden_dim_list[-1])\n",
        "\n",
        "for i in dec_hidden_dim:\n",
        "    args.dec_hidden_dim_list.append(int(i))\n",
        "\n",
        "args.dec_hidden_dim_list.append(args.input_dim)\n",
        "\n",
        "args.dec_hidden_dim_list\n",
        "\n",
        "args"
      ],
      "id": "3ba92f58"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` model"
      ],
      "id": "49ed6ffd-8fc6-41a3-851a-8948919b68ae"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "class midlayer(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(midlayer, self).__init__()\n",
        "        self.fc_layer   = nn.Linear(input_dim, hidden_dim)\n",
        "        self.activation = nn.LeakyReLU()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.fc_layer(x)\n",
        "        out = self.activation(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, hidden_dim_list):\n",
        "        super(Encoder, self).__init__()\n",
        "        \n",
        "        layer_list = []\n",
        "        for i in range(len(hidden_dim_list)-1):\n",
        "            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n",
        "        \n",
        "        self.fc_layer = nn.Sequential(*layer_list)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.fc_layer(x)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_dim_list):\n",
        "        super().__init__()\n",
        "        \n",
        "        layer_list = []\n",
        "        for i in range(len(hidden_dim_list)-2):\n",
        "            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n",
        "        \n",
        "        layer_list.append(nn.Sequential(nn.Linear(hidden_dim_list[i+1], hidden_dim_list[i+2]), nn.Sigmoid()))\n",
        "        self.fc_layer = nn.Sequential(*layer_list)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.fc_layer(x)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = Encoder(enc_hidden_dim_list)\n",
        "        self.decoder = Decoder(dec_hidden_dim_list)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.encoder(x)\n",
        "        out = self.decoder(out)\n",
        "\n",
        "        return out"
      ],
      "id": "1ef96f94"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "autoencoder = Autoencoder(args.enc_hidden_dim_list, args.dec_hidden_dim_list)\n",
        "autoencoder = autoencoder.to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)"
      ],
      "id": "cacc4c4a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` train & visualization function"
      ],
      "id": "47475a13-15f0-4fc4-95c0-21eaf87639a1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def train_autoencoder(autoencoder, criterion, optimizer, num_epochs):\n",
        "    train_loss_arr  = []\n",
        "    test_loss_arr   = []\n",
        "\n",
        "    best_test_loss  = 99999999\n",
        "    early_stop, early_stop_max = 0., 3.\n",
        "    for epoch in range(num_epochs):\n",
        "        autoencoder.train()\n",
        "        epoch_loss  = 0.\n",
        "        for data in train_loader:\n",
        "            inputs, _   = data\n",
        "            inputs      = inputs.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n",
        "            train_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n",
        "            epoch_loss += train_loss.data\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        train_loss_arr.append(epoch_loss / len(train_loader.dataset))\n",
        "        \n",
        "        if epoch != 99:\n",
        "            autoencoder.eval()\n",
        "\n",
        "            test_loss   = 0.\n",
        "\n",
        "            for data in test_loader:\n",
        "                inputs, _   = data\n",
        "                inputs      = inputs.to(device)\n",
        "\n",
        "                outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n",
        "                batch_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n",
        "                test_loss  += batch_loss.data\n",
        "\n",
        "            test_loss   = test_loss\n",
        "            test_loss_arr.append(test_loss)\n",
        "\n",
        "            if best_test_loss   > test_loss:\n",
        "                best_test_loss  = test_loss\n",
        "                early_stop      = 0\n",
        "\n",
        "                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f} *')\n",
        "            else:\n",
        "                early_stop      += 1\n",
        "                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f}') \n",
        "\n",
        "        if early_stop   >= early_stop_max:\n",
        "            break\n",
        "\n",
        "def visualize_images(original, reconstructed, n=10):\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i in range(n):\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        plt.imshow(original[i].reshape(28, 28), cmap='gray')\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "        ax = plt.subplot(2, n, i + 1 + n)\n",
        "        plt.imshow(reconstructed[i].reshape(28, 28), cmap='gray')\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "    plt.show()"
      ],
      "id": "239cf15d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` train & visualization"
      ],
      "id": "f505298b-9b61-4f44-95d1-250b80110b7a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "train_autoencoder(autoencoder, criterion, optimizer, num_epochs=args.num_epoch)\n",
        "\n",
        "data_iter = iter(test_loader)\n",
        "images, _ = next(data_iter)\n",
        "reconstructed = autoencoder(images)\n",
        "visualize_images(images, reconstructed.detach().numpy())"
      ],
      "id": "03c31409"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### second model"
      ],
      "id": "294fa506-c579-4c01-af31-42757d9683bd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "parser = argparse.ArgumentParser(description='parser for argparse test')\n",
        "\n",
        "parser.add_argument('--input_dim', type=int, default=28*28)\n",
        "parser.add_argument('--enc_hidden_dim', type=str, default='128,32')\n",
        "parser.add_argument('--dec_hidden_dim', type=str, default='128')\n",
        "parser.add_argument('--lr_rate', type=float, default=0.001)\n",
        "parser.add_argument('--num_epoch', type=int, default=10)\n",
        "\n",
        "if 'ipykernel_launcher' in sys.argv[0]:\n",
        "    sys.argv = [sys.argv[0]]  \n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "enc_hidden_dim = args.enc_hidden_dim.split(',')\n",
        "dec_hidden_dim = args.dec_hidden_dim.split(',')\n",
        "\n",
        "args.enc_hidden_dim_list = []\n",
        "args.dec_hidden_dim_list = []\n",
        "\n",
        "args.enc_hidden_dim_list.append(args.input_dim)\n",
        "\n",
        "for i in enc_hidden_dim:\n",
        "    args.enc_hidden_dim_list.append(int(i))\n",
        "\n",
        "args.dec_hidden_dim_list.append(args.enc_hidden_dim_list[-1])\n",
        "\n",
        "for i in dec_hidden_dim:\n",
        "    args.dec_hidden_dim_list.append(int(i))\n",
        "\n",
        "args.dec_hidden_dim_list.append(args.input_dim)\n",
        "\n",
        "args"
      ],
      "id": "0070f4dd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "class midlayer(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(midlayer, self).__init__()\n",
        "        self.fc_layer   = nn.Linear(input_dim, hidden_dim)\n",
        "        self.activation = nn.LeakyReLU()\n",
        "   \n",
        "    def forward(self, x):\n",
        "        out = self.fc_layer(x)\n",
        "        out = self.activation(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, hidden_dim_list):\n",
        "        super(Encoder, self).__init__()\n",
        "       \n",
        "        layer_list      = []\n",
        "        for i in range(len(hidden_dim_list)-1):\n",
        "            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n",
        "        \n",
        "        self.fc_layer   = nn.Sequential(*layer_list)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.fc_layer(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_dim_list):\n",
        "        super().__init__()\n",
        "        \n",
        "        layer_list = []\n",
        "        for i in range(len(hidden_dim_list)-2):\n",
        "            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n",
        "    \n",
        "        layer_list.append(nn.Sequential(nn.Linear(hidden_dim_list[i+1], hidden_dim_list[i+2])))\n",
        "        self.fc_layer = nn.Sequential(*layer_list)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.fc_layer(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(enc_hidden_dim_list)\n",
        "        self.decoder = Decoder(dec_hidden_dim_list)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.encoder(x)\n",
        "        out = self.decoder(out)\n",
        "        return out"
      ],
      "id": "0a7bb73d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "autoencoder = Autoencoder(args.enc_hidden_dim_list, args.dec_hidden_dim_list)\n",
        "autoencoder = autoencoder.to(device)\n",
        "\n",
        "criterion = nn.MSELoss() \n",
        "optimizer = optim.Adam(autoencoder.parameters(), lr=args.lr_rate)"
      ],
      "id": "5daa388d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def train_autoencoder(autoencoder, criterion, optimizer, num_epochs):\n",
        "    train_loss_arr  = []\n",
        "    test_loss_arr   = []\n",
        "\n",
        "    best_test_loss  = 99999999\n",
        "    early_stop, early_stop_max = 0., 3.\n",
        "    for epoch in range(num_epochs):\n",
        "        autoencoder.train()\n",
        "        epoch_loss  = 0.\n",
        "        for data in train_loader:\n",
        "            inputs, _   = data\n",
        "            inputs      = inputs.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n",
        "            train_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n",
        "            epoch_loss += train_loss.data\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        train_loss_arr.append(epoch_loss / len(train_loader.dataset))\n",
        "        \n",
        "        if epoch != -1:\n",
        "            autoencoder.eval()\n",
        "\n",
        "            test_loss = 0.\n",
        "\n",
        "            for data in test_loader:\n",
        "                inputs, _   = data\n",
        "                inputs      = inputs.to(device)\n",
        "\n",
        "                outputs = autoencoder(inputs.view(inputs.size(0), -1))\n",
        "                batch_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n",
        "                test_loss  += batch_loss.data\n",
        "\n",
        "            test_loss = test_loss\n",
        "            test_loss_arr.append(test_loss)\n",
        "\n",
        "            if best_test_loss   > test_loss:\n",
        "                best_test_loss  = test_loss\n",
        "                early_stop      = 0\n",
        "\n",
        "                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f} *')\n",
        "            else:\n",
        "                early_stop += 1\n",
        "                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f}') \n",
        "\n",
        "        if early_stop >= early_stop_max:\n",
        "            break"
      ],
      "id": "0be4b37e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "train_autoencoder(autoencoder, criterion, optimizer, num_epochs=args.num_epoch)\n",
        "\n",
        "data_iter       = iter(test_loader)\n",
        "images, _       = next(data_iter)\n",
        "reconstructed   = autoencoder(images)\n",
        "visualize_images(images, reconstructed.detach().numpy())"
      ],
      "id": "b5897a03"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model without input_dim"
      ],
      "id": "b6698cce-8f44-430a-b6da-4a0f1f1e5e92"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "parser = argparse.ArgumentParser(description='parser for argparse test')\n",
        "\n",
        "parser.add_argument('--enc_hidden_dim', type=str, default='784,128,32')\n",
        "parser.add_argument('--dec_hidden_dim', type=str, default='128,784')\n",
        "parser.add_argument('--lr_rate', type=float, default=0.001)\n",
        "parser.add_argument('--num_epoch', type=int, default=10)\n",
        "\n",
        "if 'ipykernel_launcher' in sys.argv[0]:\n",
        "    sys.argv = [sys.argv[0]]  \n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "enc_hidden_dim = args.enc_hidden_dim.split(',')\n",
        "dec_hidden_dim = args.dec_hidden_dim.split(',')\n",
        "\n",
        "args.enc_hidden_dim_list = []\n",
        "args.dec_hidden_dim_list = []\n",
        "\n",
        "for i in enc_hidden_dim:\n",
        "    args.enc_hidden_dim_list.append(int(i))\n",
        "\n",
        "args.enc_hidden_dim_list\n",
        "\n",
        "args.dec_hidden_dim_list.append(args.enc_hidden_dim_list[-1])\n",
        "\n",
        "for i in dec_hidden_dim:\n",
        "    args.dec_hidden_dim_list.append(int(i))\n",
        "\n",
        "args.dec_hidden_dim_list\n",
        "\n",
        "args"
      ],
      "id": "7ea5e7ca"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "class midlayer(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(midlayer, self).__init__()\n",
        "        self.fc_layer   = nn.Linear(input_dim, hidden_dim)\n",
        "        self.activation = nn.LeakyReLU()\n",
        "   \n",
        "    def forward(self, x):\n",
        "        out = self.fc_layer(x)\n",
        "        out = self.activation(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, hidden_dim_list):\n",
        "        super(Encoder, self).__init__()\n",
        "       \n",
        "        layer_list      = []\n",
        "        for i in range(len(hidden_dim_list)-1):\n",
        "            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n",
        "        \n",
        "        self.fc_layer   = nn.Sequential(*layer_list)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.fc_layer(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_dim_list):\n",
        "        super().__init__()\n",
        "        \n",
        "        layer_list      = []\n",
        "        for i in range(len(hidden_dim_list)-2):\n",
        "            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n",
        "    \n",
        "        layer_list.append(nn.Sequential(nn.Linear(hidden_dim_list[i+1], hidden_dim_list[i+2])))\n",
        "        self.fc_layer   = nn.Sequential(*layer_list)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.fc_layer(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(enc_hidden_dim_list)\n",
        "        self.decoder = Decoder(dec_hidden_dim_list)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.encoder(x)\n",
        "        out = self.decoder(out)\n",
        "        return out"
      ],
      "id": "ac7289e8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "autoencoder = Autoencoder(args.enc_hidden_dim_list, args.dec_hidden_dim_list)\n",
        "autoencoder = autoencoder.to(device)\n",
        "\n",
        "criterion = nn.MSELoss() \n",
        "optimizer = optim.Adam(autoencoder.parameters(), lr=args.lr_rate)"
      ],
      "id": "c51896f8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def train_autoencoder(autoencoder, criterion, optimizer, num_epochs):\n",
        "    train_loss_arr  = []\n",
        "    test_loss_arr   = []\n",
        "\n",
        "    best_test_loss  = 99999999\n",
        "    early_stop, early_stop_max = 0., 3.\n",
        "    for epoch in range(num_epochs):\n",
        "        autoencoder.train()\n",
        "        epoch_loss  = 0.\n",
        "        for data in train_loader:\n",
        "            inputs, _   = data\n",
        "            inputs      = inputs.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n",
        "            train_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n",
        "            epoch_loss += train_loss.data\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        train_loss_arr.append(epoch_loss / len(train_loader.dataset))\n",
        "        \n",
        "        if epoch != -1:\n",
        "            autoencoder.eval()\n",
        "\n",
        "            test_loss = 0.\n",
        "\n",
        "            for data in test_loader:\n",
        "                inputs, _   = data\n",
        "                inputs      = inputs.to(device)\n",
        "\n",
        "                outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n",
        "                batch_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n",
        "                test_loss  += batch_loss.data\n",
        "\n",
        "            test_loss = test_loss\n",
        "            test_loss_arr.append(test_loss)\n",
        "\n",
        "            if best_test_loss   > test_loss:\n",
        "                best_test_loss  = test_loss\n",
        "                early_stop      = 0\n",
        "\n",
        "                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f} *')\n",
        "            else:\n",
        "                early_stop += 1\n",
        "                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f}') \n",
        "\n",
        "        if early_stop >= early_stop_max:\n",
        "            break"
      ],
      "id": "4c7cabba"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "train_autoencoder(autoencoder, criterion, optimizer, num_epochs=args.num_epoch)\n",
        "\n",
        "data_iter       = iter(test_loader)\n",
        "images, _       = next(data_iter)\n",
        "reconstructed   = autoencoder(images)\n",
        "visualize_images(images, reconstructed.detach().numpy())"
      ],
      "id": "1c93d14f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model without input_dim & dec_hidden_dim(1)"
      ],
      "id": "10f2cb23-831e-4e53-af6d-a7897dcc0168"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "arser = argparse.ArgumentParser(description='parser for argparse test')\n",
        "\n",
        "parser.add_argument('--enc_hidden_dim', type=str, default='784,128,32')\n",
        "parser.add_argument('--lr_rate', type=float, default=0.001)\n",
        "parser.add_argument('--num_epoch', type=int, default=10)\n",
        "\n",
        "if 'ipykernel_launcher' in sys.argv[0]:\n",
        "    sys.argv = [sys.argv[0]]  \n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "enc_hidden_dim = args.enc_hidden_dim.split(',') ### key point\n",
        "dec_hidden_dim = args.enc_hidden_dim.split(',')\n",
        "\n",
        "args.enc_hidden_dim_list = []\n",
        "args.dec_hidden_dim_list = []\n",
        "\n",
        "for i in enc_hidden_dim:\n",
        "    args.enc_hidden_dim_list.append(int(i))\n",
        "\n",
        "args.enc_hidden_dim_list\n",
        "\n",
        "for i in enc_hidden_dim[::-1]:\n",
        "    args.dec_hidden_dim_list.append(int(i))\n",
        "\n",
        "args.dec_hidden_dim_list\n",
        "\n",
        "args"
      ],
      "id": "d59a3942"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "class midlayer(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(midlayer, self).__init__()\n",
        "        self.fc_layer   = nn.Linear(input_dim, hidden_dim)\n",
        "        self.activation = nn.LeakyReLU()\n",
        "   \n",
        "    def forward(self, x):\n",
        "        out = self.fc_layer(x)\n",
        "        out = self.activation(out)\n",
        "        return out\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, hidden_dim_list):\n",
        "        super(Encoder, self).__init__()\n",
        "       \n",
        "        layer_list      = []\n",
        "        for i in range(len(hidden_dim_list)-1):\n",
        "            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n",
        "        \n",
        "        self.fc_layer   = nn.Sequential(*layer_list)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.fc_layer(x)\n",
        "        return out\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_dim_list):\n",
        "        super().__init__()\n",
        "        \n",
        "        layer_list      = []\n",
        "        for i in range(len(hidden_dim_list)-2):\n",
        "            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n",
        "    \n",
        "        layer_list.append(nn.Sequential(nn.Linear(hidden_dim_list[i+1], hidden_dim_list[i+2])))\n",
        "        self.fc_layer   = nn.Sequential(*layer_list)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.fc_layer(x)\n",
        "        return out\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(enc_hidden_dim_list)\n",
        "        self.decoder = Decoder(dec_hidden_dim_list)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.encoder(x)\n",
        "        out = self.decoder(out)\n",
        "        return out"
      ],
      "id": "117e2217"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "autoencoder = Autoencoder(args.enc_hidden_dim_list, args.dec_hidden_dim_list)\n",
        "autoencoder = autoencoder.to(device)\n",
        "\n",
        "criterion = nn.MSELoss() \n",
        "optimizer = optim.Adam(autoencoder.parameters(), lr=args.lr_rate)"
      ],
      "id": "086cf28b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def train_autoencoder(autoencoder, criterion, optimizer, num_epochs):\n",
        "    train_loss_arr  = []\n",
        "    test_loss_arr   = []\n",
        "\n",
        "    best_test_loss  = 99999999\n",
        "    early_stop, early_stop_max = 0., 3.\n",
        "    for epoch in range(num_epochs):\n",
        "        autoencoder.train()\n",
        "        epoch_loss  = 0.\n",
        "        for data in train_loader:\n",
        "            inputs, _   = data\n",
        "            inputs      = inputs.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n",
        "            train_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n",
        "            epoch_loss += train_loss.data\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        train_loss_arr.append(epoch_loss / len(train_loader.dataset))\n",
        "        \n",
        "        if epoch != -1:\n",
        "            autoencoder.eval()\n",
        "\n",
        "            test_loss = 0.\n",
        "\n",
        "            for data in test_loader:\n",
        "                inputs, _   = data\n",
        "                inputs      = inputs.to(device)\n",
        "\n",
        "                outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n",
        "                batch_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n",
        "                test_loss  += batch_loss.data\n",
        "\n",
        "            test_loss = test_loss\n",
        "            test_loss_arr.append(test_loss)\n",
        "\n",
        "            if best_test_loss   > test_loss:\n",
        "                best_test_loss  = test_loss\n",
        "                early_stop      = 0\n",
        "\n",
        "                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f} *')\n",
        "            else:\n",
        "                early_stop += 1\n",
        "                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f}') \n",
        "\n",
        "        if early_stop >= early_stop_max:\n",
        "            break"
      ],
      "id": "56dcd9dc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "train_autoencoder(autoencoder, criterion, optimizer, num_epochs=args.num_epoch)\n",
        "\n",
        "data_iter       = iter(test_loader)\n",
        "images, _       = next(data_iter)\n",
        "reconstructed   = autoencoder(images)\n",
        "visualize_images(images, reconstructed.detach().numpy())"
      ],
      "id": "3bd1987b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model without input_dim & dec_hidden_dim(2)"
      ],
      "id": "2172bc7e-27f5-47ad-b7e2-e2ecadfceca5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "parser = argparse.ArgumentParser(description='parser for argparse test')\n",
        "\n",
        "parser.add_argument('--enc_hidden_dim', type=str, default='784,256,128,64,32')\n",
        "parser.add_argument('--lr_rate', type=float, default=0.001)\n",
        "parser.add_argument('--num_epoch', type=int, default=10)\n",
        "\n",
        "if 'ipykernel_launcher' in sys.argv[0]:\n",
        "    sys.argv = [sys.argv[0]]  \n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "enc_hidden_dim = args.enc_hidden_dim.split(',') ### key point(dec_hidden_dim을 따로 정의하지 않았음)\n",
        "\n",
        "args.enc_hidden_dim_list = []\n",
        "\n",
        "for i in enc_hidden_dim:\n",
        "    args.enc_hidden_dim_list.append(int(i))\n",
        "\n",
        "args.enc_hidden_dim_list\n",
        "\n",
        "args.enc_hidden_dim_list[::-1]\n",
        "\n",
        "args"
      ],
      "id": "91297886"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "class midlayer(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(midlayer, self).__init__()\n",
        "        self.fc_layer   = nn.Linear(input_dim, hidden_dim)\n",
        "        self.activation = nn.LeakyReLU()\n",
        "   \n",
        "    def forward(self, x):\n",
        "        out = self.fc_layer(x)\n",
        "        out = self.activation(out)\n",
        "        return out\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, hidden_dim_list):\n",
        "        super(Encoder, self).__init__()\n",
        "       \n",
        "        layer_list      = []\n",
        "        for i in range(len(hidden_dim_list)-1):\n",
        "            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n",
        "        \n",
        "        self.fc_layer   = nn.Sequential(*layer_list)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.fc_layer(x)\n",
        "        return out\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_dim_list):\n",
        "        super().__init__()\n",
        "        \n",
        "        layer_list = []\n",
        "        for i in range(len(hidden_dim_list)-2):\n",
        "            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n",
        "    \n",
        "        layer_list.append(nn.Sequential(nn.Linear(hidden_dim_list[i+1], hidden_dim_list[i+2])))\n",
        "        self.fc_layer = nn.Sequential(*layer_list)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.fc_layer(x)\n",
        "        return out\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(enc_hidden_dim_list)\n",
        "        self.decoder = Decoder(dec_hidden_dim_list)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.encoder(x)\n",
        "        out = self.decoder(out)\n",
        "        return out"
      ],
      "id": "58b16b8b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "autoencoder = Autoencoder(args.enc_hidden_dim_list, args.enc_hidden_dim_list[::-1]) ### key point(dec_hidden_dim_list를 enc_hiffen_dim_list[::-1]을 이용해서 정의함)\n",
        "autoencoder = autoencoder.to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(autoencoder.parameters(), lr=args.lr_rate)"
      ],
      "id": "53274857"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def train_autoencoder(autoencoder, criterion, optimizer, num_epochs):\n",
        "    train_loss_arr  = []\n",
        "    test_loss_arr   = []\n",
        "\n",
        "    best_test_loss  = 99999999\n",
        "    early_stop, early_stop_max = 0., 3.\n",
        "    for epoch in range(num_epochs):\n",
        "        autoencoder.train()\n",
        "        epoch_loss  = 0.\n",
        "        for data in train_loader:\n",
        "            inputs, _   = data\n",
        "            inputs      = inputs.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n",
        "            train_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n",
        "            epoch_loss += train_loss.data\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        train_loss_arr.append(epoch_loss / len(train_loader.dataset))\n",
        "        \n",
        "        if epoch != -1:\n",
        "            autoencoder.eval()\n",
        "\n",
        "            test_loss = 0.\n",
        "\n",
        "            for data in test_loader:\n",
        "                inputs, _   = data\n",
        "                inputs      = inputs.to(device)\n",
        "\n",
        "                outputs     = autoencoder(inputs.view(inputs.size(0), -1))\n",
        "                batch_loss  = criterion(outputs, inputs.view(inputs.size(0), -1))\n",
        "                test_loss  += batch_loss.data\n",
        "\n",
        "            test_loss = test_loss\n",
        "            test_loss_arr.append(test_loss)\n",
        "\n",
        "            if best_test_loss   > test_loss:\n",
        "                best_test_loss  = test_loss\n",
        "                early_stop      = 0\n",
        "\n",
        "                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f} *')\n",
        "            else:\n",
        "                early_stop += 1\n",
        "                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f}') \n",
        "\n",
        "        if early_stop >= early_stop_max:\n",
        "            break"
      ],
      "id": "cdb064f3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "train_autoencoder(autoencoder, criterion, optimizer, num_epochs=args.num_epoch)\n",
        "\n",
        "data_iter       = iter(test_loader)\n",
        "images, _       = next(data_iter)\n",
        "reconstructed   = autoencoder(images)\n",
        "visualize_images(images, reconstructed.detach().numpy())"
      ],
      "id": "4e2c005e"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    }
  }
}